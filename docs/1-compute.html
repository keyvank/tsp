<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Compute! - The Super Programmer</title>


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="0-preface.html">Intro</a></li><li class="chapter-item expanded "><a href="1-compute.html" class="active"><strong aria-hidden="true">1.</strong> Compute!</a></li><li class="chapter-item expanded "><a href="2-hear.html"><strong aria-hidden="true">2.</strong> Hear!</a></li><li class="chapter-item expanded "><a href="3-see.html"><strong aria-hidden="true">3.</strong> See!</a></li><li class="chapter-item expanded "><a href="4-think.html"><strong aria-hidden="true">4.</strong> Think!</a></li><li class="chapter-item expanded "><a href="5-trust.html"><strong aria-hidden="true">5.</strong> Trust!</a></li><li class="chapter-item expanded "><a href="6-fly.html"><strong aria-hidden="true">6.</strong> Fly!</a></li><li class="chapter-item expanded "><a href="7-unorganized.html"><strong aria-hidden="true">7.</strong> Unorganized</a></li><li class="chapter-item expanded "><a href="8-appendix-a.html"><strong aria-hidden="true">8.</strong> Appendix A</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Super Programmer</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="compute"><a class="header" href="#compute">Compute!</a></h1>
<p><strong>Music of the chapter:</strong> <em>Computer Love - By Kraftwerk</em></p>
<h2 id="which-came-first-the-chicken-or-the-egg"><a class="header" href="#which-came-first-the-chicken-or-the-egg">Which came first? The chicken or the egg?</a></h2>
<p>Imagine, for a moment, that a catastrophic event occurs, causing us to lose all the technology we once had. All that remains is ashes, and our situation is similar to humanity's early days millions of years ago. But there's one key difference: we still have the ability to read, and fortunately, many books are available that explain how our modern technology once worked. Now, here's an interesting question: How long would it take for us to reach the level of advancement we have today?</p>
<p>My prediction is that we would get back on track within a few decades. The only reason it might take longer than expected is that we would need tools to build other tools. For example, we can't just start building a modern CPU, even if we have the specifications and detailed design. First, we would need to rebuild the tools required to create complex electronic circuits. If we are starting from scratch, as we've assumed, we would also need to relearn how to find and extract the materials we need from the Earth, and then use those materials to make simpler tools. These simpler tools would then allow us to create more advanced ones. Here's the key point that makes all of our technological progress possible: <em><strong>technology can accelerate the creation of more technology!</strong></em></p>
<p>Just like the chicken-and-egg paradox, I’ve often wondered how people built the very first compilers and assemblers. What language did they use to describe the first assembly languages? Did they have to write early assembler programs directly in 0s and 1s? After some research, I discovered that the answer is yes. In fact, as an example, the process of building a C compiler for the first time goes like this:</p>
<ol>
<li>First, you write a C compiler directly in machine code or assembly (or some other lower-level language).</li>
<li>Next, you rewrite the same C compiler in C.</li>
<li>Then, you compile the new C source code using the compiler written in assembly.</li>
<li>At this point, you can completely discard the assembly implementation and treat the C compiler as if it were originally written in C.</li>
</ol>
<p>See this beautiful loop? Technology sustains and reproduces itself, which essentially means <em><strong>technology is a form of life</strong></em>! The simpler computer language (in this case, machine-assembly) helped the C compiler emerge, but once the compiler was created, it could stand on its own. We no longer need the machine-assembly version, since there’s nothing stopping us from describing a C compiler in C itself! This phenomenon isn’t limited to software—just like a hammer can be used to build new hammers!</p>
<p>Now, let's return to our original question: Which came first, the chicken or the egg? If we look at the history of evolution, we can see that creatures millions of years ago didn’t reproduce by laying eggs. For example, basic living cells didn’t reproduce by laying eggs; they simply split in two. As living organisms evolved and became more complex, processes like egg-laying gradually emerged. The very first chicken-like animal that started laying eggs didn’t necessarily hatch from an egg. It could have been a mutation that introduced egg-laying behavior in a new generation, much like how a C compiler could come to life without depending on an assembly implementation.</p>
<h2 id="when-the-dominos-fall"><a class="header" href="#when-the-dominos-fall">When the dominos fall</a></h2>
<p>If you ask someone deeply knowledgeable about computers how a computer works at the most fundamental level, they’ll probably start by talking about electronic switches, transistors, and logic gates. Well, I’m going to take a similar approach, but with a slight twist! While transistors are the basic building blocks of nearly all modern computers, the real magic behind what makes computers &quot;do their thing&quot; is something I like to call &quot;Cause &amp; Effect&quot; chains.</p>
<p>Let’s begin by looking at some everyday examples of cause-and-effect scenarios. Here’s my list (feel free to add yours as you think of them):</p>
<ul>
<li>You press a key on your computer → A character appears on the screen → <em><strong>END</strong></em></li>
<li>You push the first domino → The next domino falls → The next domino falls → ...</li>
<li>You ask someone to open the window → He opens the window → <em><strong>END</strong></em></li>
<li>You tell a rumor to your friend → He tells the rumor to his friend → ...</li>
<li>You toggle the switch → The light bulb turns on → <em><strong>END</strong></em></li>
<li>A neuron fires in your brain → Another neuron gets excited and fires → ...</li>
</ul>
<p>Now, let’s explore why some of these cause-and-effect chains keep going, setting off a series of events that lead to significant changes in their environment, while others stop after just a few steps. Why do some things trigger a cascade of actions, while others don’t?</p>
<p>There's an important pattern here: The long-lasting (i.e., interesting) effects emerge from cause-and-effect chains where <em><strong>the effects are of the same type as the causes</strong></em>. This means that these chains become particularly interesting when they can form cycles. For example, when a &quot;mechanical&quot; cause leads to another &quot;mechanical&quot; effect (like falling dominos), or when an &quot;electrical&quot; cause triggers another electrical effect (like in electronic circuits or the firing of neurons in your brain).</p>
<p>The most complex thing you can create with components that transform a <em><strong>single cause into a single effect</strong></em> is essentially no different from a chain of falling dominoes (or when rumors circulate within a company). While it’s still impressive and has its own interesting aspects, we don’t want to stop there. The real magic happens when you start transforming <em><strong>multiple causes into a single effect</strong></em>—especially when all the causes are of the same type. That’s when Cause &amp; Effect chains truly come to life!</p>
<p>A simple example of a multi-input/single-output component is a switch. A switch controls the flow of an input to an output through a third, controlling input. Light switches, push buttons, and faucets (which control the flow of water through a pipe) are all examples of switches. However, in these cases, the type of the controlling input is different from the other inputs and outputs. For instance, the controlling input of a push button is mechanical, while the others are electrical. You still need a finger to push the button, and the output of the push button cannot be used as the mechanical input of another button. As a result, you can't build domino-like structures or long-lasting cause-and-effect chains using faucets or push buttons in the same way you would with purely similar types of inputs and outputs!</p>
<p><img src="assets/pushbutton.png" alt="A push-button converts an electrical and a mechanical cause, to an electrical effect" />{ width=350px }</p>
<p>A push-button becomes more interesting when its controlling input is electrical rather than mechanical. In this case, all of its inputs and outputs are of the same type, allowing you to connect the output of one push-button to the controlling input of another.</p>
<p>Similarly, in the faucet example, you could design a special kind of faucet that opens with the force of water, rather than requiring a person to open it manually with their hands. In the picture below, when no water is present in the controlling pipe (the pipe in the middle), the spring will push the block down, preventing water from flowing from the left pipe to the right pipe. However, when water enters the controlling pipe, its pressure will push the block up, creating space for the water to flow from the left pipe to the right pipe.</p>
<p><img src="assets/faucet.png" alt="The flow of water coming from the controller input, opens up the gate and allows the water to flow from left to right" />{ width=350px }</p>
<p>The controlling input doesn't have to sharply switch the flow between no-flow and maximum-flow. Instead, the controller can adjust the flow to any level, depending on how much the controlling input is pushed. Additionally, the controlling input doesn't need to be as large or powerful as the other inputs/outputs. It could be a thinner pipe that requires only a small force of water to fully open the valve. This means you can control a large and powerful water flow using a much smaller input and less force.</p>
<p>There’s also a well-known name for these unique switches: transistors. Now you can understand what &quot;transistor&quot; literally means—it’s something that can &quot;transfer&quot; or adjust &quot;resistance&quot; on demand, much like how we can control the resistance of the water flow in a larger pipe using a third input.</p>
<p>The most obvious use case for a transistor is signal amplification. Let’s explore this with an example: imagine a small pipe through which water flows in a sinusoidal pattern. Initially, there is no water, then the flow gradually increases to a certain level, and finally, it slowly decreases back to zero (a pattern similar to what you might see in a water show!). Now, we connect this pipe to the controlling input of the water transistor we designed earlier. Can you guess what comes out from the output of this transistor? Yes, the output is also a sinusoidal flow of water. The difference is that it’s much more powerful than the small pipe. We’ve just transferred the sinusoidal pattern from a small water flow to a much more powerful one! Can you imagine how important this is? This concept forms the core of how devices like electric guitars and sound amplifiers work!</p>
<p>That’s not the only use case for transistors, though. Because the cause-and-effect types of the inputs and outputs are the same, we can chain them together—and that’s all we need to start building machines that can compute things (we’ll explore the details soon!). These inputs don’t necessarily have to be electrical; they can be mechanical as well. Yes, we can build computers that operate using the force of water!</p>
<p>A typical transistor in the real world is conceptually the same as our imaginary faucet described above. Substitute water with electrons, and you have an accurate analogy for a transistor. Transistors, the building blocks of modern computers, allow you to control the flow of electrons in a wire using a third source of electrons!</p>
<p>Understanding how modern electron-based transistors work involves a fair bit of physics and chemistry. But if you insist, here’s a very simple (and admittedly silly) example of a push-button with an electrical controller: Imagine a person holding a wire in their hand. This person presses the push-button whenever they feel electricity in their hand (as long as the electricity isn’t strong enough to harm them). Together, the person and the push-button form something akin to a transistor, because now the types of all inputs and outputs in the system are the same.</p>
<p>It might sound like the strangest idea in the world, but if you had enough of these &quot;transistors&quot; connected together, you could theoretically build a computer capable of connecting to the internet and rendering webpages!</p>
<p>Why did people choose electrons to flow in the veins of our computers instead of something like water? There are several reasons:</p>
<ul>
<li>Electrons are extremely small.</li>
<li>Electrical effects propagate extremely fast!</li>
</ul>
<p>Thanks to these properties, we can create complex and dense cause-and-effect chains that produce amazing behaviors while using very little space, like in your smartphone!</p>
<h2 id="taming-the-electrons"><a class="header" href="#taming-the-electrons">Taming the electrons</a></h2>
<p>In the previous section, we explored what a transistor is. Now it’s time to see what we can do with it! To quickly experiment with transistors, we’ll simulate imaginary transistors on a computer and arrange them in the right order to perform fancy computations for us.</p>
<p>Our ultimate goal is to construct a fully functional computer using a collection of three-way switches. If you have prior experience designing hardware, you're likely familiar with software tools that allow you to describe hardware using a Hardware Description Language (HDL). These tools can generate transistor-level circuits from your designs and even simulate them for you. However, since this book focuses on the underlying concepts rather than real-world, production-ready implementations, we will skip the complexity of learning an HDL. Instead, we'll use the Python programming language to emulate these concepts as we progress. This approach will not only deepen our understanding of the transistor-level implementation of something as intricate as a computer but also shed light on how HDL languages transform high-level circuit descriptions into collections of transistors.</p>
<p>So let's begin and start building our own circuit simulator!</p>
<h2 id="everything-is-relative"><a class="header" href="#everything-is-relative">Everything is relative</a></h2>
<p>The very first term you encounter when exploring electricity is &quot;voltage,&quot; so it’s essential to grasp its meaning before studying how transistors behave under different voltages. Formally, voltage is the potential energy difference between two points in a circuit. To understand this concept, let’s set aside electricity for a moment and think about heights.</p>
<p>Imagine lifting a heavy object from the ground. The higher you lift it, the more energy you expend (and the more tired you feel, right? That energy needs to be replenished, like by eating food!). According to the law of conservation of energy, energy cannot be created or destroyed, only transformed or transferred. So where does the energy you used to lift the object go?</p>
<p>Now, release the object and let it fall. It hits the ground with a bang, possibly breaking the ground—or itself. The higher the object was lifted, the greater the damage it causes. Clearly, energy is needed to create those noises and damages. But where did that energy come from?</p>
<p>You’ve guessed it! When you lifted the object, you transferred energy to it. When you let it fall, that stored energy was released. Physicists call this stored energy &quot;potential energy.&quot; A raised object has the potential to do work (work is the result of energy being consumed), which is why it’s called potential energy!</p>
<p>If you remember high school physics, you’ll know that the potential energy of an object can be calculated using the formula: \(U=mgh\), where \(m\) is the mass of the object, \(h\) is its height above the ground, and \(g\) is the Earth's gravitational constant (approximately \(9.807 m/s^2\)).</p>
<p>According to this formula, when the object is on the ground (\(h=0\)), the potential energy is also \(U=0\). But here’s an important question: does that mean an object lying on the ground has no potential energy?</p>
<p>Actually, it does have potential energy! Imagine taking a shovel and digging a hole under the object. The object would fall into the hole, demonstrating that it still had the capacity to do work due to gravity.</p>
<p>The key point is this: the equation \(U=mgh\) represents the potential energy difference relative to a chosen reference point (in this case, the ground), not the absolute potential energy of the object. A more precise way to express this idea would be:
\(\varDelta{u}=mg\varDelta{h}\).</p>
<p>This equation shows that the potential energy difference between two points \(A\) and \(B\) depends on \(mg\), the gravitational force, and \(\varDelta{h}\), the difference in height between the two points.</p>
<p>In essence, <em><strong>potential energy is relative!</strong></em></p>
<p><img src="assets/potential.png" alt="We assume that the height on the ground is 0, although you can reach lower heights by digging the ground! Height and potential energy are relative concepts." />{ width=350px }</p>
<p>The reason it takes energy to lift an object is rooted in the fact that massive bodies attract each other, as described by the universal law of gravitation: \(F=G\frac{m_1m_2}{r^2}\).</p>
<p>Similarly, a comparable law exists in the microscopic world, where electrons attract protons, and like charges repel each other. This interaction is governed by Coulomb's law: \(F=k_e\frac{q_1q_2}{r^2}\)</p>
<p>As a result, we also have the concept of &quot;potential energy&quot; in the electromagnetic world. It takes energy to separate two electric charges of opposite types (positive and negative), as you're working against the attractive electric force. When you pull them apart and then release them, they will move back toward each other, releasing the stored potential energy.</p>
<p>That's essentially how batteries work. They create potential differences by moving electrons to higher &quot;heights&quot; of potential energy. When you connect a wire from the negative pole of the battery to the positive pole, the electrons &quot;fall&quot; through the wire, releasing energy in the process.</p>
<p>When we talk about &quot;voltage,&quot; we are referring to the difference in height or potential energy between two points. While we might not know the absolute potential energy of points A and B, we can definitely measure and understand the difference in potential (voltage) between them!</p>
<h2 id="pipes-of-electrons"><a class="header" href="#pipes-of-electrons">Pipes of electrons</a></h2>
<p>We discussed that transistors are essentially three-way switches that control the flow between two input/output paths using a third input. When building a transistor circuit simulator—whether simulating the flow of water or electrons—it makes sense to begin by simulating the &quot;pipes,&quot; the elements through which electrons will flow. In electrical circuits, these &quot;pipes&quot; are commonly referred to as <em><strong>wires</strong></em>.</p>
<p>Wires are likely to be the most fundamental and essential components of our circuit simulation software. As their name suggests, wires are conductors of electricity, typically made of metal, that allow different components to connect and communicate via the flow of electricity. We can think of wires as containers that hold electrons at specific voltage levels. If two wires with different voltage levels are connected, electrons will flow from the wire with higher voltage to the one with lower voltage.</p>
<p>In digital circuits, transistors and other electronic components operate using two specific voltage levels: &quot;zero&quot; (commonly referred to as <em><strong>ground</strong></em>) and &quot;one.&quot; It’s important to emphasize that the terms &quot;zero&quot; and &quot;one&quot; do not correspond to fixed or absolute values. Instead, &quot;zero&quot; acts as a reference point, while &quot;one&quot; represents a voltage level that is higher relative to &quot;zero.&quot;</p>
<p>At first glance, it might seem that we could model a wire using a single boolean value: <code>false</code> to represent zero and <code>true</code> to represent one. However, this approach fails to account for all the possible scenarios that can arise in a circuit simulator.</p>
<p>For example, consider a wire in your simulator that isn’t connected to either the positive or negative pole of a battery. Would it even have a voltage level? Clearly, it would be neither 0 nor 1. Now imagine a wire that connects a high-voltage (1) wire to a low-voltage (0) wire. What would the voltage of this intermediary wire be? Electrons would start flowing from the higher-voltage wire to the lower-voltage wire, and as a result, the voltage of the intermediary wire would settle somewhere between 0 and 1.</p>
<p>In a digital circuit, connecting a 0 wire to a 1 wire is not always a good idea and could indicate a mistake in your circuit design, potentially causing a short circuit. Therefore, it is useful to consider a value for a wire that is either mistakenly or intentionally left unconnected (Free state) or connected to both 0 and 1 voltage sources simultaneously (Short-circuit/Unknown state).</p>
<p>Based on this explanation, a wire can be in four different states:</p>
<ul>
<li><code>Z</code> state - The wire is free and not connected to anything.</li>
<li><code>0</code> state - The wire is connected to a ground voltage source and has 0 voltage.</li>
<li><code>1</code> state - The wire is connected to a 5.0V voltage source.</li>
<li><code>X</code> state - The wire's voltage cannot be determined because it is connected to both a 5.0V and 0.0V voltage source simultaneously.</li>
</ul>
<p><img src="assets/wires.png" alt="4 different wire states" /></p>
<p>Initially, a wire that is not connected to anything is in the <code>Z</code> state. When you connect it to a gate or wire that has a state of <code>1</code>, the wire's state will also become <code>1</code>. A wire can connect to multiple gates or wires at the same time. For example, if a wire already in the <code>1</code> state is connected to another source of <code>1</code>, it will remain 1. However, the wire will enter the <code>X</code> state if it is connected to a wire or gate with a conflicting value. For instance, if the wire is connected to both <code>0</code> and <code>1</code> voltage sources simultaneously, its state will be <code>X</code>. Similarly, connecting any wire to an <code>X</code> voltage source will also result in the wire taking on the <code>X</code> state.</p>
<p>We can summarize all the possible scenarios in a custom table that defines the arithmetic of wire states:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A + B</th></tr></thead><tbody>
<tr><td>Z</td><td>Z</td><td>Z</td></tr>
<tr><td>0</td><td>Z</td><td>0</td></tr>
<tr><td>1</td><td>Z</td><td>1</td></tr>
<tr><td>X</td><td>Z</td><td>X</td></tr>
<tr><td>Z</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>X</td></tr>
<tr><td>X</td><td>0</td><td>X</td></tr>
<tr><td>Z</td><td>1</td><td>1</td></tr>
<tr><td>0</td><td>1</td><td>X</td></tr>
<tr><td>1</td><td>1</td><td>1</td></tr>
<tr><td>X</td><td>1</td><td>X</td></tr>
<tr><td>Z</td><td>X</td><td>X</td></tr>
<tr><td>0</td><td>X</td><td>X</td></tr>
<tr><td>1</td><td>X</td><td>X</td></tr>
<tr><td>X</td><td>X</td><td>X</td></tr>
</tbody></table>
</div>
<p>A wildcard version of this table would look like this:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A + B</th></tr></thead><tbody>
<tr><td>Z</td><td><strong>x</strong></td><td><strong>x</strong></td></tr>
<tr><td><strong>x</strong></td><td>Z</td><td><strong>x</strong></td></tr>
<tr><td>X</td><td><strong>x</strong></td><td>X</td></tr>
<tr><td><strong>x</strong></td><td>X</td><td>X</td></tr>
<tr><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>1</td></tr>
<tr><td>0</td><td>1</td><td>X</td></tr>
<tr><td>1</td><td>0</td><td>X</td></tr>
</tbody></table>
</div>
<p>Based on the explanation, we can model a wire as a Python class:</p>
<pre><code class="language-python=">FREE = &quot;Z&quot;
UNK = &quot;X&quot;
ZERO = 0
ONE = 1


class Wire:
    def __init__(self):
        self._drivers = {}
        self._assume = FREE

    def assume(self, val):
        self._assume = val

    def get(self):
        curr = FREE
        for b in self._drivers.values():
            if b == UNK:
                return UNK
            elif b != FREE:
                if curr == FREE:
                    curr = b
                elif b != curr:
                    return UNK
        return curr if curr != FREE else self._assume

    def put(self, driver, value):
        is_changed = self._drivers.get(driver) != value
        self._drivers[driver] = value
        return is_changed
</code></pre>
<p>The code above models a wire as a Python class. By definition, a wire that is not connected to anything remains in the <code>Z</code> state. Using the <code>put</code> function, a driver (such as a battery or a gate) can apply a voltage to the wire. The final voltage of the wire is determined by iterating over all the voltages applied to it.</p>
<p>We store the voltage values applied to the wire in a dictionary to ensure that a single driver cannot apply two different values to the same wire.</p>
<p>The <code>put</code> function also checks whether there has been a change in the values applied to the wire. This will later help our simulator determine if the circuit has reached a stable state, where the values of all wires remain fixed.</p>
<p>In some cases—particularly in circuits containing feedback loops and recursion—it is necessary to assume that a wire already has a value in order to converge on a solution. For this purpose, we have designed the <code>assume()</code> function, which allows us to assign an assumed value to a wire if no gates have driven a value into it. If you don’t yet fully understand what the <code>assume()</code> function does, don’t worry—we’ll explore its usage in the next sections.</p>
<h2 id="magical-switches"><a class="header" href="#magical-switches">Magical switches</a></h2>
<p>Now that we've successfully modeled wires, it's time to implement the second most important component of our simulator: the transistor.</p>
<p>Transistors are electrically controlled switches with three pins: <em><strong>base</strong></em>, <em><strong>emitter</strong></em>, and <em><strong>collector</strong></em>. These pins connect to other circuit elements through wires. The <em><strong>base</strong></em> pin acts as the switch’s controller—when there is a high potential difference between the <em><strong>base</strong></em> and <em><strong>collector</strong></em> pins, the <em><strong>emitter</strong></em> connects to the <em><strong>collector</strong></em>. Otherwise, the <em><strong>emitter</strong></em> remains unconnected, behaving like a floating wire in the <code>Z</code> state.</p>
<p>This key behavior means that turning off the transistor does not set the <em><strong>emitter</strong></em> to <code>0</code> but instead leaves it in the <code>Z</code> state.</p>
<p>We can also describe the wire arithmetic of a transistor using the following table:</p>
<div class="table-wrapper"><table><thead><tr><th>B</th><th>E</th><th>C</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>Z</td></tr>
<tr><td>0</td><td>1</td><td>Z</td></tr>
<tr><td>1</td><td>0</td><td>0 (Strong)</td></tr>
<tr><td>1</td><td>1</td><td>1 (Weak)</td></tr>
</tbody></table>
</div>
<p>The transistor we have been discussing so far is a Type-N transistor. The Type-N transistor turns on when the base wire is driven with a <code>1</code>. There is also another type of transistor, known as Type-P, which turns on when the base wire is driven with a <code>0</code>. The truth table for a Type-P transistor looks like this:</p>
<div class="table-wrapper"><table><thead><tr><th>B</th><th>E</th><th>C</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0 (Weak)</td></tr>
<tr><td>0</td><td>1</td><td>1 (Strong)</td></tr>
<tr><td>1</td><td>0</td><td>Z</td></tr>
<tr><td>1</td><td>1</td><td>Z</td></tr>
</tbody></table>
</div>
<p>Assuming we define a voltage of <em><strong>5.0V</strong></em> as <code>1</code> and a voltage of <em><strong>0.0V</strong></em> as <code>0</code>, a wire is driven with a <em><strong>strong</strong></em> <code>0</code> when its voltage is very close to 0 (e.g., 0.2V), and a <em><strong>strong</strong></em> <code>1</code> when its voltage is close to 5 (e.g., 4.8V). The truth is, the transistors we build in the real world aren't ideal, so they won't always provide strong signals. A signal is considered <em><strong>weak</strong></em> when it's far from 0.0V or 5.0V. For example, a voltage of 4.0V could be considered a <em><strong>weak</strong></em> <code>1</code>, and a voltage of 1.0V would be considered a <em><strong>weak</strong></em> <code>0</code>, whereas 4.7V could be considered a <em><strong>strong</strong></em> <code>1</code> and 0.3V a <em><strong>strong</strong></em> <code>0</code>. Type-P transistors, when built in the real world, are very good at producing strong <code>0</code> signals, but their <code>1</code> signals tend to be weak. On the other hand, Type-N transistors produce strong <code>1</code> signals, but their <code>0</code> signals are weak. By using both types of transistors together, we can build logic gates that provide strong outputs in all cases.</p>
<h2 id="the-transistor"><a class="header" href="#the-transistor">The Transistor</a></h2>
<p>In our digital circuit simulator, we’ll have two different types of components: primitive components and components that are made of primitives. We’ll define components as primitives when they can’t be described as a group of smaller primitives.</p>
<p>For example, we can simulate Type-N and Type-P transistors as primitive components, since everything else can be constructed by combining Type-N and Type-P transistors together.</p>
<pre><code class="language-python=">class NTransistor:
    def __init__(self, in_base, in_collector, out_emitter):
        self.in_base = in_base
        self.in_collector = in_collector
        self.out_emitter = out_emitter

    def update(self):
        b = self.in_base.get()
        if b == ONE:
            return self.out_emitter.put(self, self.in_collector.get())
        elif b == ZERO:
            return self.out_emitter.put(self, FREE)
        elif b == UNK:
            return self.out_emitter.put(self, UNK)
        else:
            return True  # Trigger re-update


class PTransistor:
    def __init__(self, in_base, in_collector, out_emitter):
        self.in_base = in_base
        self.in_collector = in_collector
        self.out_emitter = out_emitter

    def update(self):
        b = self.in_base.get()
        if b == ZERO:
            return self.out_emitter.put(self, self.in_collector.get())
        elif b == ONE:
            return self.out_emitter.put(self, FREE)
        elif b == UNK:
            return self.out_emitter.put(self, UNK)
        else:
            return True  # Trigger re-update
</code></pre>
<p>Our primitive components are classes with an <code>update()</code> function. The <code>update()</code> function is called whenever we want to calculate the output of the primitive based on its inputs. As a convention, we will prefix the input and output wires of our components with <code>in_</code> and <code>out_</code>, respectively.</p>
<p>The <code>update()</code> function of our primitive components will also return a boolean value, which indicates whether the element needs to be updated again. Sometimes, the inputs of a component might not be ready when the update() function is called. For example, in the case of transistors, if the <code>base</code> wire is in the <code>Z</code> state, we assume there is another transistor that needs to be updated before the current transistor can calculate its output. By returning this boolean value, we inform our circuit emulator that the transistor is not &quot;finalized&quot; yet, and the <code>update()</code> function needs to be called again before determining that all component outputs have been correctly calculated and the circuit is stabilized.</p>
<p>Additionally, remember that the <code>put()</code> function of the <code>Wire</code> class also returns a boolean value. This value indicates whether the driver of that wire has placed a new value on the wire. A new value on a wire means there has been a change in the circuit, and the entire circuit needs to be updated again.</p>
<h2 id="the-circuit"><a class="header" href="#the-circuit">The Circuit</a></h2>
<p>Now, it would be useful to have a data structure for keeping track of the wires and transistors allocated in a circuit. We will call this class <code>Circuit</code>. It will provide methods for creating wires and adding transistors. The <code>Circuit</code> class is responsible for calling the <code>update()</code> function of the primitive components and will allow you to calculate the values of all the wires in the network.</p>
<pre><code class="language-python=">class Circuit:
    def __init__(self):
        self._wires = []
        self._comps = []

        self._zero = self.new_wire()
        self._zero.put(self, ZERO)
        self._one = self.new_wire()
        self._one.put(self, ONE)

    def one(self):
        return self._one

    def zero(self):
        return self._zero

    def new_wire(self):
        w = Wire()
        self._wires.append(w)
        return w

    def add_component(self, comp):
        self._comps.append(comp)

    def num_components(self):
        return len(self._comps)

    def update(self):
        has_changes = False
        for t in self._comps:
            has_changes = has_changes | t.update()
        return has_changes

    def stabilize(self):
        while self.update():
            pass
</code></pre>
<p>The <code>update()</code> method of the <code>Circuit</code> class calculates the values of the wires by iterating through the transistors and calling their update method. In circuits with feedback loops, a single iteration of updates may not be sufficient, and multiple iterations may be needed before the circuit reaches a stable state. To address this, we introduce an additional method specifically designed for this purpose: <code>stabilize()</code>. This method repeatedly performs updates until no changes are observed in the wire values, meaning the circuit has stabilized.</p>
<p>Our <code>Circuit</code> class also provides global <code>zero()</code> and <code>one()</code> wires, which can be used by components requiring fixed <code>0</code> and <code>1</code> signals. These wires function like battery poles in our circuits.</p>
<p>Electronic components can be defined as functions that take a circuit as input and add wires and transistors to it. Let’s explore the implementation details of some of them!</p>
<h2 id="life-in-a-non-ideal-world"><a class="header" href="#life-in-a-non-ideal-world">Life in a non-ideal world</a></h2>
<p>Digital circuits are essentially logical expressions that are automatically evaluated by the flow of electrons through what we refer to as gates. Logical expressions are defined using zeros and ones, but as we have seen, wires in an electronic circuit are not always guaranteed to be either 0 or 1. Therefore, we must redefine our gates and determine their output in cases where the inputs are faulty.</p>
<p>Consider a NOT gate as an example. In an ideal world, its truth table would be as follows:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>NOT A</th></tr></thead><tbody>
<tr><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td></tr>
</tbody></table>
</div>
<p>However, the real world is not ideal, and wires connected to electronic logic gates can have unexpected voltages. Since a wire in our emulation can have four different states, our logic gates must be able to handle all four. The following is the definition of a NOT gate using our wire arithmetic. If the input to the NOT gate is <code>Z</code> or <code>X</code>, the output will be the faulty state <code>X</code>.</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>NOT A</th></tr></thead><tbody>
<tr><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td></tr>
<tr><td>Z</td><td>X</td></tr>
<tr><td>X</td><td>X</td></tr>
</tbody></table>
</div>
<p>There are two ways to simulate gates in our software. We can either implement them using plain Python code as primitive components, similar to transistors, or we can construct them as a circuit of transistors. The following is an example of a NOT gate implemented using the first approach:</p>
<pre><code class="language-python=">class Not:
    def __init__(self, wire_in, wire_out):
        self.wire_in = wire_in
        self.wire_out = wire_out

    def update(self):
        v = self.wire_in.get()
        if v == FREE:
            self.wire_out.put(self, UNK)
        elif v == UNK:
            self.wire_out.put(self, UNK)
        elif v == ZERO:
            self.wire_out.put(self, ONE)
        elif v == ONE:
            self.wire_out.put(self, ZERO)
</code></pre>
<p>We can also test out implementation:</p>
<pre><code class="language-python=">if __name__ == '__main__':
    inp = Wire.zero()
    out = Wire()
    gate = Not(inp, out)
    gate.update()
    print(out.get())
</code></pre>
<p>The NOT gate modeled as a primitive component is accurate and functions as expected. However, we know that a NOT gate is actually built from transistors, and it might be more interesting to model it using a pair of transistors rather than <em><strong>cheating</strong></em> by emulating its high-level behavior with Python code.</p>
<p>The following is an example of a NOT gate constructed using a P-type and an N-type transistor:</p>
<pre><code class="language-python=">def Not(circuit, inp, out):
    circuit.add_component(PTransistor(inp, circuit.one(), out))
    circuit.add_component(NTransistor(inp, circuit.zero(), out))
</code></pre>
<p><img src="assets/not.png" alt="NOT gate with a pair of transistors" /></p>
<p>As you know, an N-type transistor connects its source pin to its drain pin when the voltage on its gate is higher than the voltage on its drain. So, when the <code>inp</code> wire is driven with <code>1</code>, the output gets connected to the <code>circuit.zero()</code> wire, causing <code>out</code> to hold a <code>0</code> signal. Notice that the P-type transistor is off when <code>inp</code> is <code>1</code>, so the <code>circuit.one()</code> wire will <em><strong>not</strong></em> get connected to the output pin. If that were the case, we would get a short circuit, causing the out signal to become a faulty (<code>X</code>)`.</p>
<p>Likewise, when <code>inp</code> is <code>0</code>, the P-type transistor turns on and connects the output to <code>circuit.one()</code>, while the N-type transistor turns off, leaving the output unconnected to the ground.</p>
<p>NOT gates are probably the simplest components you can build using the current primitive elements provided by our simulator. Now that we’re familiar with transistors, it’s time to expand our component set and build some of the most fundamental logic gates. In addition to NOT gates, you’ve likely heard of AND and OR gates, which are a bit more complex—mainly because they take more than one input. Here’s their definition:</p>
<p><em><strong>AND gate:</strong></em> outputs <code>0</code> when at least one of the inputs is <code>0</code>, and gets <code>1</code> when all of the inputs are <code>1</code>. Otherwise the output is faulty (<code>X</code>).</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A AND B</th></tr></thead><tbody>
<tr><td>0</td><td>*</td><td>0</td></tr>
<tr><td>*</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>1</td></tr>
<tr><td></td><td></td><td>X</td></tr>
</tbody></table>
</div>
<p><em><strong>OR gate:</strong></em> outputs <code>1</code> when at least one of the inputs is <code>1</code>, and gets <code>0</code> only when all of the inputs are <code>0</code>. Otherwise the output is unknown (<code>X</code>).</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A OR B</th></tr></thead><tbody>
<tr><td>1</td><td>*</td><td>1</td></tr>
<tr><td>*</td><td>1</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td></tr>
<tr><td></td><td></td><td>X</td></tr>
</tbody></table>
</div>
<h2 id="mother-of-the-gates"><a class="header" href="#mother-of-the-gates">Mother of the gates</a></h2>
<p>A NAND gate is a logic gate that outputs 0 if and only if both of its inputs are 1. It is essentially an AND gate with its output inverted. It can be proven that all the basic logic gates (AND, OR, NOT) can be built using different combinations of this single gate:</p>
<ul>
<li>\(NOT(x) = NAND(x, x)\)</li>
<li>\(AND(x, y) = NOT(NAND(x, y)) = NAND(NAND(x, y), NAND(x, y))\)</li>
<li>\(OR(x, y) = NAND(NOT(x), NOT(y)) = NAND(NAND(x, x), NAND(y, y))\)</li>
</ul>
<p>It is the &quot;mother gate&quot; of all logic circuits. Although building everything with NAND gates would be very inefficient in practice, for the sake of simplicity, we'll stick to NAND gates and try to construct other gates by connecting them together.</p>
<p><img src="assets/nand.png" alt="NAND gate with transistors" /></p>
<p>It turns out that we can build NAND gates with strong and accurate output signals using 4 transistors (2 Type-N and 2 Type-P). Let's prototype a NAND gate using our simulated N/P transistors!</p>
<pre><code class="language-python=">def Nand(circuit, in_a, in_b, out):
    inter = circuit.new_wire()
    circuit.add_component(PTransistor(in_a, circuit.one(), out))
    circuit.add_component(PTransistor(in_b, circuit.one(), out))
    circuit.add_component(NTransistor(in_a, circuit.zero(), inter))
    circuit.add_component(NTransistor(in_b, inter, out))
</code></pre>
<p>Now, other primitive gates can be defined as combinations of NAND gates. Take the NOT gate as an example. Here is a third way we can implement a NOT gate (So far, we have implemented a NOT gate in two ways: 1. Describing its behavior through plain Python code, and 2. By connecting a pair of Type-N and Type-P transistors):</p>
<pre><code class="language-python=">def Not(circuit, inp, out):
    Nand(circuit, inp, inp, out)
</code></pre>
<p>Go ahead and implement the other primitive gates using the NAND gate we just defined. After that, we can start creating useful circuits from these gates!</p>
<pre><code class="language-python=">def And(circuit, in_a, in_b, out):
    not_out = circuit.new_wire()
    Nand(circuit, in_a, in_b, not_out)
    Not(circuit, not_out, out)


def Or(circuit, in_a, in_b, out):
    not_out = circuit.new_wire()
    Nor(circuit, in_a, in_b, not_out)
    Not(circuit, not_out, out)


def Nor(circuit, in_a, in_b, out):
    inter = circuit.new_wire()
    circuit.add_component(PTransistor(in_a, circuit.one(), inter))
    circuit.add_component(PTransistor(in_b, inter, out))
    circuit.add_component(NTransistor(in_a, circuit.zero(), out))
    circuit.add_component(NTransistor(in_b, circuit.zero(), out))
</code></pre>
<p>An XOR gate is another incredibly useful gate that comes in handy when building circuits that can perform numerical additions. The XOR gate outputs 1 only when the inputs are unequal, and outputs 0 when they are equal. XOR gates can be built from AND, OR, and NOT gates: \(Xor(x,y) = Or(And(x, Not(y)), And(Not(x), y))\). However, since XOR gates will be used frequently in our future circuits, it makes more sense to provide a transistor-level implementation for them, as this will require fewer transistors!</p>
<pre><code class="language-python=">def Xor(circuit, in_a, in_b, out):
    a_not = circuit.new_wire()
    b_not = circuit.new_wire()
    Not(circuit, in_a, a_not)
    Not(circuit, in_b, b_not)

    inter1 = circuit.new_wire()
    circuit.add_component(PTransistor(b_not, circuit.one(), inter1))
    circuit.add_component(PTransistor(in_a, inter1, out))
    inter2 = circuit.new_wire()
    circuit.add_component(PTransistor(in_b, circuit.one(), inter2))
    circuit.add_component(PTransistor(a_not, inter2, out))

    inter3 = circuit.new_wire()
    circuit.add_component(NTransistor(in_b, circuit.zero(), inter3))
    circuit.add_component(NTransistor(in_a, inter3, out))
    inter4 = circuit.new_wire()
    circuit.add_component(NTransistor(b_not, circuit.zero(), inter4))
    circuit.add_component(NTransistor(a_not, inter4, out))
</code></pre>
<p>Sometimes, we simply need to connect two different wires. Instead of creating a new primitive component for that purpose, we can use two consecutive NOT gates. This will act like a simple jumper! We'll call this gate a <code>Forward</code> gate:</p>
<pre><code class="language-python=">def Forward(circuit, inp, out):
    tmp = circuit.new_wire()
    Not(circuit, inp, tmp)
    Not(circuit, tmp, out)
</code></pre>
<h2 id="hello-world-circuit"><a class="header" href="#hello-world-circuit">Hello World circuit!</a></h2>
<p>The simplest digital circuit we might consider a &quot;computer&quot; is one that can perform basic arithmetic, like adding two numbers together. In digital circuits, information is represented using binary signals—0s and 1s. So, when we talk about adding numbers in a digital circuit, we're working with binary numbers.</p>
<p>To start with, let's focus on a very basic example: a circuit that can add two one-bit binary numbers. A one-bit number can only be either a 0 or a 1, so adding them together can yield one of three possible results: 0 + 0 = 0, 0 + 1 = 1, and 1 + 1 = 10 (which is 2 in decimal). Notice that the result of adding two one-bit numbers is always a two-bit number, because 1 + 1 produces a carry, which means we need two bits to store the result.</p>
<p>To design such a circuit, one of the most effective approaches is to start by figuring out what the output should be for each possible combination of inputs. Since there are two inputs (each one-bit numbers), there are four possible input combinations: 00, 01, 10, and 11. For each of these combinations, we can determine what the output should be. Since the result is always a two-bit number, we can break the circuit into two smaller subcircuits: one that calculates the sum bit (the least significant bit) and one that calculates the carry bit (the more significant bit). Each subcircuit works independently to compute its corresponding part of the result.</p>
<p>In this way, we approach building the circuit step by step, using logic gates to implement the required operations for each input combination.</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>First digit</th><th>Second digit</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>0</td><td>1</td></tr>
</tbody></table>
</div>
<p>The relation of the second digit with A and B is very familiar; it's essentially an AND gate! Try to figure out how the first digit can be calculated by combining primitive gates. (Hint: It outputs 1 only when A is 0 AND B is 1, or A is 1 AND B is 0.)</p>
<p><em><strong>Answer:</strong></em> It's an XOR gate! (\(Xor(x, y) = Or(And(x, Not(y)), And(Not(x), y))\)), and here is the Python code for the entire thing:</p>
<pre><code class="language-python=">def HalfAdder(circuit, in_a, in_b, out_sum, out_carry):
    Xor(circuit, in_a, in_b, out_sum)
    And(circuit, in_a, in_b, out_carry)
</code></pre>
<p>What we have just built is known as a half-adder. With a half-adder, you can add 1-bit numbers together. You might think that we can build multi-bit adders by stacking multiple half-adders in a row, but that's not entirely correct. Recall that the addition algorithm we learned in primary school also applies to binary numbers. Imagine we want to add the binary numbers <code>1011001</code> (89) and <code>111101</code> (61) together. Here’s how it works:</p>
<pre><code> 1111  1
   
  1011001
+  111101
-----------
 10010110
</code></pre>
<p>By examining the algorithm, we can see that for each digit, the addition involves <em><strong>three bits</strong></em> (not just two). In addition to the original bits, there is also a third carry bit from the previous addition that must be considered. Therefore, to design a multi-bit adder, we need a circuit that can add three one-bit numbers together. Such a circuit is known as a <em><strong>full-adder</strong></em>, and the third number is often referred to as the carry bit. Here’s the truth table for a three-bit adder:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>C</th><th>D0</th><th>D1</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>
</tbody></table>
</div>
<p>Building a full-adder is not that challenging. You can use two half-adders to compute the sum bit and then take the OR of the carry outputs to obtain the final carry bit.</p>
<pre><code class="language-python=">def FullAdder(circuit, in_a, in_b, in_carry, out_sum, out_carry):
    sum_ab = circuit.new_wire()
    carry1 = circuit.new_wire()
    carry2 = circuit.new_wire()
    HalfAdder(circuit, in_a, in_b, sum_ab, carry1)
    HalfAdder(circuit, sum_ab, in_carry, out_sum, carry2)
    Or(circuit, carry1, carry2, out_carry)
</code></pre>
<p>Once we have a full-adder ready, we can proceed with building multi-bit adders. For example, to create an 8-bit adder, we need to connect eight full-adders in a row. The carry output of each adder serves as the carry input for the next, mimicking the addition algorithm we discussed earlier.</p>
<pre><code class="language-python=">def Adder8(circuit, in_a, in_b, in_carry, out_sum, out_carry):
    carries = [in_carry] + [circuit.new_wire() for _ in range(7)] + [out_carry]
    for i in range(8):
        FullAdder(
            circuit,
            in_a[i],
            in_b[i],
            carries[i],
            out_sum[i],
            carries[i + 1],
        )
</code></pre>
<p>Congratulations! We just added two 8-bit numbers using nothing but bare transistors. Before continuing our journey toward more complex circuits, let's ensure that our simulated model of the 8-bit adder is functioning correctly. If the 8-bit adder works properly, there is a high chance that the other gates are also functioning as expected.</p>
<pre><code class="language-python=">def num_to_wires(circuit, num):
    wires = []
    for i in range(8):
        bit = (num &gt;&gt; i) &amp; 1
        wires.append(circuit.one() if bit else circuit.zero())
    return wires


def wires_to_num(wires):
    out = 0
    for i, w in enumerate(wires):
        if w.get() == ONE:
            out += 2**i
    return out


if __name__ == &quot;__main__&quot;:
    for x in range(256):
        for y in range(256):
            circuit = Circuit()
            wires_x = num_to_wires(circuit, x)
            wires_y = num_to_wires(circuit, y)
            wires_out = [Wire() for _ in range(8)]
            Adder8(circuit, wires_x, wires_y, circuit.zero(), wires_out, circuit.zero())
            circuit.update()
            out = wires_to_num(wires_out)
            if out != (x + y) % 256:
                print(&quot;Adder is not working!&quot;)

</code></pre>
<p>Here, we are checking if the outputs are correct for all possible inputs. We have defined two auxiliary functions, <code>num_to_wires</code> and <code>wires_to_num</code>, to convert numbers into a set of wires that can connect to an electronic circuit, and vice versa.</p>
<h2 id="when-addition-is-subtraction"><a class="header" href="#when-addition-is-subtraction">When addition is subtraction</a></h2>
<p>So far, we have been able to implement the addition operation by combining N and P transistors. Our adder is limited to 8 bits, meaning that the input and output values are all in the range \([0,255]\). If you try to add two numbers whose sum exceeds 255, you will still get a result in the range \([0,255]\). This happens because a number larger than 255 cannot be represented by 8 bits, and an <em><strong>overflow</strong></em> occurs. Upon closer inspection, you’ll notice that what we have designed isn’t the typical addition operation we are used to in elementary school mathematics; instead, it’s addition in a finite field. This means the addition results are taken modulo 256.</p>
<p>\(a \oplus b = (a + b) \mod 256\)</p>
<p>It is good to know that finite-fields have interesting properties:</p>
<ol>
<li>\((a \oplus b) \oplus c = a \oplus (b \oplus c)\)</li>
<li>For every non-zero number \(x \in \mathbb{F}\), there is a number \(y\), where \(x \oplus y = 0\). \(y\) is known as the negative of \(x\).</li>
</ol>
<p>In a finite field, the negative of a number can be calculated by subtracting that number from the field size (in this case, the size of our field is \(2^8=256\)).  For example, the negative of \(10\) is \(256-10=246\), so \(10 \oplus 246 = 0\).</p>
<p>Surprisingly, the number \(246\), behaves exactly like \(-10\). Try adding \(246\) to \(15\). You will get \(246 \oplus 15 = 5\) which is the same as \(15 + (-10)\)! This has an important implication: we can perform subtraction without designing a new circuit! All we need to do is negate the number. Calculating the negative of a number is like taking the XOR of that number (Which gives \(255 - a\)), and then adding \(1\) to it (Which results in \(256 - a\), our definition of negation). This is known as the two's complement form of a number.</p>
<p>It’s incredible to see that we can build electronic machines capable of adding and subtracting numbers by simply connecting a bunch of transistors together! The good news is that we can go even further and design circuits that can perform multiplication and division, using the same approach we used for designing addition circuits. The details of multiplication and division circuits are beyond the scope of this book, but you are strongly encouraged to study them on your own!</p>
<h2 id="not-gates-can-be-fun-too"><a class="header" href="#not-gates-can-be-fun-too">Not gates can be fun too!</a></h2>
<p>If you remember, we discussed that you can't build interesting structures using only a single type of single-input/single-output component (such as NOT gates). In fact, we argued that using just them, we can only create domino-like structures, where a single cause traverses through the components until reaching the last one. However, that's not entirely true: what if we connect the last component of the chain to the first one? This creates a loop, which is definitely something new. Assuming two consecutive NOT gates cancel each other out, we can build two different kinds of NOT loops:</p>
<p><img src="assets/notloops.png" alt="Two possible kinds of NOT loops" /></p>
<p>After analyzing both possible loops, you will soon understand that the one with a single NOT gate is unstable. The voltage of the wire can be neither 0 nor 1. It creates a logical paradox, similar to the statement: <em>This sentence is not true</em>. The statement can be neither true nor false!</p>
<p>Practically, if you build such a circuit, it may oscillate rapidly between possible states, or the wire's voltage may settle at a value between the logical voltages of 0 and 1.</p>
<p>On the other hand, the loop with two NOT gates can achieve stability. The resulting circuit has two possible states: either the first wire is 1 and the second wire is 0, or the first wire is 0 and the second wire is 1. It will not switch between these states automatically. If you build such a circuit using real components, the initial state will be somewhat random. A slight difference in the transistor conditions may cause the circuit to settle into one of the states and remain there.</p>
<h2 id="try-to-remember"><a class="header" href="#try-to-remember">Try to remember</a></h2>
<p>So far, we have been experimenting with stateless circuits—circuits that do not need to store or remember anything to function. However, circuits without memory are severely limited in their capabilities. To unlock their full potential, we need to explore how to store data within a digital circuit and maintain it over time. This is one of the most critical steps before we can build a computer, as computers are essentially machines that manipulate values stored in some kind of <em><strong>memory</strong></em>. Without memory, a computer cannot perform complex tasks or execute meaningful programs.</p>
<p>As a child, you may have tried to leave a light switch in a &quot;middle&quot; position. If the switch was well-made, you probably found it frustratingly difficult to do! The concept of memory arises when a system with multiple possible states can only stabilize in a single state at a time. Once it becomes stable, it can only change through an external force. In this sense, a light switch can function as a single-bit memory cell.</p>
<p>Another silly example: imagine a piece of paper—it remains stable in its current state. If you set it on fire, it gradually changes until it is completely burned, after which it stabilizes again. Keeping the paper in a &quot;half-burned&quot; state is not easy! You could consider the paper as a crude single-bit memory cell, but it has a major flaw: once burned, it cannot return to its original state.</p>
<p>Fortunately, there are ways to build circuits with multiple possible states, where only one state remains stable at a time. The simplest example is a circuit that forms a loop by connecting two NOT gates to each other. This setup involves two wires: if the first wire is 1, the second wire will be 0, and the circuit will stabilize in that configuration (and vice versa).</p>
<p>The problem with a simple NOT gate loop is that it cannot be controlled externally—it lacks an input mechanism to change its state. To fix this, we can replace the NOT gates with logic gates that accept two inputs instead of one. For example, using NAND gates instead allows us to introduce external control. By providing voltages to the extra input pins, a user can modify the internal state of the loop. This type of circuit is known as an SR latch:</p>
<p><img src="assets/srlatch.png" alt="Set-Reset latch" /></p>
<p>Now, the user can set the latch to the first or second state by setting S=1 and R=0, or S=0 and R=1, respectively. The magic lies in the fact that <em><strong>the circuit will stably remain in the latest state</strong></em>, even after both S and R inputs are set to zero!</p>
<p>Here you can find an example of a SR latch implemented in Python:</p>
<pre><code class="language-python=">def SRLatch(circuit, in_r, in_s, out_data, initial=0):
    neg_out = circuit.new_wire()
    Nor(circuit, in_r, neg_out, out_data)
    Nor(circuit, in_s, out_data, neg_out)
    neg_out.assume(1 - initial)
    out_data.assume(initial)
</code></pre>
<p>Notice how we ingeniously feed two set/reset inputs into something that is essentially a NOT loop! Now, there’s something tricky about simulating a NOR/NOT loop: How can the first NOR gate function when <code>neg_out</code> is still not calculated? Or similarly, how can the second NOR gate calculate <code>neg_out</code> when <code>out_data</code> is still not calculated? There are two approaches we can use to resolve the chicken-and-egg problem in our simulation:</p>
<ol>
<li>Give up and attempt to simulate a memory-cell component without performing low-level transistor simulations. This would require us to define a new <em><strong>Primitive Component</strong></em> (similar to N/P transistors), which includes an <code>update()</code> function that mimics the expected behavior of a latch.</li>
<li>Hint the simulator with the initial values of wires, and let the simulator to settle in an stable state by running the update function of the transistors for a few iterations and stopping the iterations after the wire values stop changing (Meaning that the system has entered a stable state).</li>
</ol>
<p>That’s where the <code>assume</code> function we defined for our <code>Wire</code> class comes in handy. The <code>assume</code> function essentially hints to the simulator the initial value(s) of the wires in our memory cell, making it stable. In fact, if you don’t call these <code>assume</code> functions when defining the gates, the simulator won’t be able to simulate it, and the output of both NOR gates would become <code>X</code>. Assumption is only necessary when we want to initialize the circuit in a stable state for the first time. After that, the circuit will ignore the initial assumed values and will start working as expected. <em>Note: In the real world, the memory cell randomly settles into one of the set/reset states due to environmental noise and slight differences between the transistors.</em></p>
<h2 id="a-more-user-friendly-latch"><a class="header" href="#a-more-user-friendly-latch">A more user-friendly latch</a></h2>
<p>SR latches are perfect examples of memory cells since they can store a single bit of data. However, the unusual aspect of SR latches is that they require two inputs to determine whether to set them to a set (1) or reset (0) state. To set the latch to a 1 (set) state, you would feed it <code>S=1 &amp; R=0</code>, and to reset it to 0 (reset) state, you would feed it <code>S=0 &amp; R=1</code>. But what if we only had a single wire, <code>D=0/1</code>, and wanted the latch to remember the value stored in that wire? This is where the D-latch, a second type of latch, comes in handy.</p>
<p>Building a D-latch is quite straightforward: you simply need to create a circuit that decodes a single <code>D</code> bit into two <code>S</code> and <code>R</code> bits. The circuit should output <code>SR=01</code> when <code>D=0</code> and <code>SR=10</code> when <code>D=1</code>. This circuit is essentially a 1x2 decoder, which can then be connected to your existing SR-latch.</p>
<p>There’s a problem when we simply connect a 2x1 decoder to an SR latch: how can we tell the latch to stop copying whatever value is present on the <code>D</code> wire into its internal state? In an SR latch, the answer is straightforward: when both <code>S</code> and <code>R</code> are set to 0, the latch’s internal state won’t change and will simply remain in its most recent state. We would like to have the same kind of control in a D-latch, or else the D-latch would be no different than a simple wire! To achieve this, we introduce a new <em><strong>control</strong></em> wire called <code>clock</code> (or <code>clk</code>), which stops the latch from acquiring the value of <code>D</code>. The truth table for such a circuit would look something like this:</p>
<div class="table-wrapper"><table><thead><tr><th>Previous state</th><th>CLK</th><th>D</th><th>Next state</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>1</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td><td>1</td><td>1</td></tr>
<tr><td>1</td><td>1</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>1</td><td>1</td></tr>
</tbody></table>
</div>
<p>Here is how the schematic representation of a D-latch would look:</p>
<p><img src="assets/dlatch.png" alt="DLatch made of logic gates" /></p>
<p>And how it can be represented with our Python simulator:</p>
<pre><code class="language-python=">def DLatch(circuit, in_clk, in_data, out_data, initial=0):
    not_data = circuit.new_wire()
    Not(circuit, in_data, not_data)
    and_d_clk = circuit.new_wire()
    And(circuit, in_data, in_clk, and_d_clk)
    and_notd_clk = circuit.new_wire()
    And(circuit, not_data, in_clk, and_notd_clk)
    neg_out = circuit.new_wire()
    Nor(circuit, and_notd_clk, neg_out, out_data)
    Nor(circuit, and_d_clk, out_data, neg_out)

    neg_out.assume(1 - initial)
    out_data.assume(initial)
</code></pre>
<p>Later in this book, we will be building a computer with memory cells of size 8 bits (a.k.a. a byte). It might make sense to group 8 of these DLatches together as a separate component in order to build our memory cells, registers, and RAM. We'll need to arrange the latches in a row and connect their enable pins together. The resulting component will have 9 input wires (1-bit <code>in_clk</code> and 8-bit <code>in_data</code>) and 8 output wires (8-bit <code>out_data</code>):</p>
<pre><code class="language-python=">class Reg8:
    def snapshot(self):
        return wires_to_num(self.out_data)

    def __init__(self, circuit, in_clk, in_data, out_data, initial=0):
        self.out_data = out_data
        for i in range(8):
            DLatch(  # WARN: A DLatch may not be appropriate here...
                circuit,
                in_clk,
                in_data[i],
                out_data[i],
                ZERO if initial % 2 == 0 else ONE,
            )
            initial //= 2
</code></pre>
<p>There is something wrong with this register component. Let's discover the problem in action!</p>
<h2 id="make-it-count"><a class="header" href="#make-it-count">Make it count!</a></h2>
<p>Since we now know how to build memory cells, we can create circuits that maintain state/memory and behave accordingly! Let's build something useful with it!</p>
<p>A very simple yet useful <em><strong>stateful</strong></em> circuit you can build, using adders and memory cells, is a counter. An 8-bit counter can be made by taking the output of an 8-bit memory cell, incrementing it, and then feeding it back to the input of the memory cell. In this case, we expect the value of the counter to be incremented every time the clock signal rises and falls. Here’s what the Python simulator for an 8-bit counter would look like. Try running it, and you’ll see that the simulator gets stuck and is unable to stabilize!</p>
<pre><code class="language-python=">class Counter:
    def snapshot(self):
        print(&quot;Value:&quot;, self.counter.snapshot())

    def __init__(self, circuit: Circuit, in_clk: Wire):
        one = [circuit.one()] + [circuit.zero()] * 7

        counter_val = [circuit.new_wire() for _ in range(8)]
        next_counter_val = [circuit.new_wire() for _ in range(8)]

        Adder8(
            circuit,
            counter_val,
            one,
            circuit.zero(),
            next_counter_val,
            circuit.new_wire(),
        )

        self.counter = Reg8(circuit, in_clk, next_counter_val, counter_val, 0)


if __name__ == &quot;__main__&quot;:
    circ = Circuit()
    clk = circ.new_wire()

    OSCILLATOR = &quot;OSCILLATOR&quot;

    clk.put(OSCILLATOR, ZERO)

    counter = Counter(circ, clk)
    print(&quot;Num components:&quot;, circ.num_components())

    while True:
        circ.stabilize()  # WARN: Gets stuck here!
        counter.snapshot()
        clk.put(OSCILLATOR, 1 - clk.get())
</code></pre>
<p>When you think about it, the reason the circuit doesn’t stabilize becomes clear: as soon as the clock signal rises to 1, the feedback loop activates and continues to operate as long as the clock remains at 1. However, the clock signal stays at 1 for a certain period before dropping back down to 0. During that time, the circuit keeps trying to increment the value of the memory cell, which prevents it from stabilizing. We introduced the clock signal to allow us to control our stateful circuit as it iterates through different states, but it seems that a DLatch isn't giving us the control we need.</p>
<p>In fact, the enable input of the D-Latch (the clock signal) should be set to 1 for only a very short time—we just need a brief tick. Otherwise, the circuit will enter an unstable state. As soon as the input of the memory cell is captured, the output will change shortly after. If the enable signal is still 1, the circuit will continue incrementing and updating its internal state. The duration for which the enable signal is 1 should be short enough that the incrementor component doesn't have enough time to update its output, Otherwise, our circuit will be no different from connecting the output of a NOT gate to its input, in terms of instability!</p>
<p>A straightforward idea for solving the problem is to make the time the clock stays high short enough to resemble a pulse—just long enough to let the circuit transition to its next state, but not so long that it starts looping and becomes unstable. One way to create such pulses is by passing a typical clock signal through an edge detector. An edge detector is an electronic circuit that can recognize sharp changes in a signal.</p>
<p>So, how can we build an edge detector? There's an interesting twist in the real world that we can exploit: because logic gates have propagation delays, unusual behaviors—known as hazards—can occur. These are brief, unintended outputs caused by timing mismatches in signal changes.</p>
<p>Consider this example circuit:</p>
<p><img src="assets/edgedetector.png" alt="An AND gate where one of the inputs is routed through three NOTs" /></p>
<p>When the input is 0, the NOT gate outputs 1. Now, when the input switches to 1, the wire that goes directly to the AND gate receives 1 immediately. However, the wire that goes through the NOT gate takes a brief moment to reflect the change, still holding 1 for a short time before it becomes 0. During that brief moment, both inputs of the AND gate are 1, causing it to produce a short, unintended high output—a glitch or pulse.</p>
<p>By closely observing the behavior of this circuit, we can see that it effectively converts a clock signal into a train of ultra-short pulses. If we connect this component to the enable pin of a latch, the latch will update only on the rising edge of the clock signal. This configuration is known as a <em><strong>flip-flop</strong></em>.</p>
<p>The only difference between a flip-flop and a latch is in how they respond to the clock: flip-flops are edge-triggered, while latches are level-triggered. Flip-flops are preferred when designing synchronous circuits, as they provide better timing control and predictability.</p>
<p>Unfortunately, our digital circuit simulator is not a perfect representation of the real world. Since it doesn't account for gate delays, we can't build edge detectors as we discussed earlier. Even if we could, it wouldn't be a very clean solution for someone like me, who tends to be a bit paranoid. Just imagine if one of those pulses happens to be shorter or longer than expected—it could break the entire computation!</p>
<p>Fortunately, there's a cleaner and more reliable way to solve the looping problem, one that doesn’t rely on exploiting subtle physical behaviors. It starts by breaking the loop through serially connecting two D-latches: one that activates when the clock signal goes low, and the other when the clock signal goes high. This way, there is no point in time when both latches are active, so a loop can't form, even though data is still being reliably stored. Curious why it's called a flip-flop? When the clock signal rises, the first D-latch gets activated and it &quot;flips.&quot; Then, when the clock signal falls, the first latch becomes inactive, the second latch activates, and it &quot;flops!&quot; And just like that, we form a flip-flop!</p>
<p><img src="assets/dflipflop.png" alt="DFlipFlop made of two DLatches" /></p>
<p>Here's the Python implementation of the structure we just described:</p>
<pre><code class="language-python=">def DFlipFlop(circuit, in_clk, in_data, out_data, initial=0):
    neg_clk = circuit.new_wire()
    Not(circuit, in_clk, neg_clk)
    inter = circuit.new_wire()
    DLatch(circuit, in_clk, in_data, inter, initial)
    DLatch(circuit, neg_clk, inter, out_data, initial)
</code></pre>
<p>In our <code>Counter</code> circuit example, substitute the registers we built with <code>DLatch</code>es with ones built using <code>DFlipFlop</code>s, and the stabilization problem is solved!</p>
<h2 id="counters-on-steroids"><a class="header" href="#counters-on-steroids">Counters on steroids!</a></h2>
<p>A counter circuit is a perfect example of how digital circuits can remember their state and transition to a new state in a controlled fashion. It’s also a fundamental concept that inspires us to build much more complex systems, including computers.</p>
<p>A computer, in its simplest form, consists of memory, which stores all instructions and data, and a CPU, which fetches and interprets them. Looking closely at the whole system, you can see that the CPU/memory pair is not very different from the register/incrementer pair in a counter circuit. There is a state (in the counter circuit, a single byte within a register; in the computer, several billion memory cells), and there is a state manipulator (in the counter circuit, an incrementer; in the computer, a component that decodes the current instruction and executes it). On every clock pulse, the old state is processed by the manipulator, and the result is saved back into the state holder.</p>
<p>However, there is an important difference: in the case of a computer, we can't feed the entire state (all several billion 8-bit cells) into the manipulator to compute the next state—that would be enormous. It would require a giant manipulator circuit and billions of wires, which is excessive for a state change that typically affects only a small portion of the entire state.</p>
<p>We don't want to give up on having a large memory. But as previously mentioned, a single state transition typically affects only a small portion of the overall state. So, we don’t need to feed the entire memory into the manipulator—<em><strong>we only need to feed in the parts that are relevant</strong></em>.</p>
<p>But how do we specify which part of the memory we want to use?</p>
<h3 id="a-smarter-state-storage"><a class="header" href="#a-smarter-state-storage">A smarter state storage</a></h3>
<p>The solution is simple but powerful: let's assign a unique identity to each memory cell and call it its address. That way, we can reference and access only the specific parts of memory we need during each operation.</p>
<p>Yes, what we need is an <em><strong>Addressable Memory</strong></em>.</p>
<p>In this section, we're going to implement a very simple—and admittedly foolish—way to build an addressable memory. I say &quot;foolish&quot; because the memory in a typical computer is far more complex and efficient than what we're about to construct. But that's fine—the goal here isn't efficiency. It's to understand the core concept and to get creative with the tools we already have.</p>
<p>So, let’s begin by defining what we want to build. We'll assume we're designing an 8-bit computer. This computer will have a CPU capable of handling 8-bit instructions and an addressable memory (RAM) with an 8-bit address space. That means it will contain \(2^8 = 256\) memory cells, and each cell will store 8 bits of data. A 256-byte random-access memory, which is embarrassingly small by today's standards!</p>
<p>In this section, we’ll focus specifically on building the RAM component.</p>
<p>Given these specifications, our RAM will need:</p>
<ul>
<li><strong>8 address input wires</strong> — to specify the memory cell we want to read from or write to.</li>
<li><strong>1 read/write control wire</strong> — to determine whether the operation is a read or a write.</li>
<li><strong>8 data input wires</strong> — used only in write mode, to supply the value to store at the specified address.</li>
<li><strong>8 data output wires</strong> — used only in read mode, to output the value stored at the specified address.</li>
</ul>
<p>That gives us a total of <strong>17 input wires</strong> (8 for address, 8 for data-in, 1 for read/write control) and <strong>8 output wires</strong> (for data-out).</p>
<p>Now the challenging question is how to allow only a single 8-bit memory-cell to be read/written, given an address? Not too hard, let's solve the problem for read and write operations independently.</p>
<h3 id="selective-writing"><a class="header" href="#selective-writing">Selective writing</a></h3>
<p>Let's assume that the 8-bit input pins of all the memory cells within our memory are connected to the 8 input pins of the memory component. This would cause the internal value of every memory cell to be updated to the given input value on the next clock cycle. We definitely don't want that! So how can we prevent it?</p>
<p>Remember how a register only stores its input value when a full clock cycle occurs? We can use a similar idea here. Specifically, we need to prevent the clock signal from reaching all memory cells except the one whose address matches the input address. Additionally, when the memory is in read mode, the clock signal should be completely disabled for all memory cells.</p>
<p>Technically, the clock signal should only reach a memory cell if: <code>(addr == cell_index) &amp;&amp; write_mode</code>. To achieve this, simply set the input clock signal of each memory cell to: <code>(addr == cell_index) &amp;&amp; write_mode &amp;&amp; clk</code></p>
<p>If you're still unsure why this works, try analyzing the value of the equation for different input scenarios.</p>
<p>If <code>write_mode</code> is false, the entire expression evaluates to false for all memory cells, which is exactly what we want—no writes occur. If the address provided to the memory component doesn't match a given cell's index, the expression again evaluates to false, regardless of whether <code>write_mode</code> is true or whether the clock signal is high. This, too, is the intended behavior.</p>
<p>However, when the memory is in write mode and the address matches a specific memory cell’s index, the condition becomes: <code>true &amp;&amp; true &amp;&amp; clk = clk</code></p>
<p>This means the global clock signal is effectively passed through to only that memory cell, allowing it to store the input value on the next rising edge—just as intended.</p>
<p>Implementation-wise, we already have AND gates, and the only missing piece is the ability to check the equality of two 8-bit values. As always, it's best to start simple: we'll first design a circuit that can check the equality of two single bits, and then extend that solution to handle multi-bit inputs.</p>
<p>To achieve this, we'll create two modules:</p>
<ul>
<li><code>Equals</code>: This module checks the equality of two single bits. Functionally, it's just <code>Not(Xor(a, b))</code>.</li>
<li><code>MultiEquals</code>: This module checks the equality of two multi-bit values. It will be especially useful for comparing memory addresses and decoding instructions in the sections to come.</li>
</ul>
<pre><code class="language-python=">def Equals(circuit, in_a, in_b, out_eq):
    xor_out = circuit.new_wire()
    Xor(circuit, in_a, in_b, xor_out)
    Not(circuit, xor_out, out_eq)


def MultiEquals(circuit, in_a, in_b, out_eq):
    if len(in_a) != len(in_b):
        raise Exception(&quot;Expected equal num of wires!&quot;)

    count = len(in_a)
    xor_outs = []
    for i in range(count):
        xor_out = circuit.new_wire()
        Xor(circuit, in_a[i], in_b[i], xor_out)
        xor_outs.append(xor_out)

    inter = circuit.new_wire()
    Or(circuit, xor_outs[0], xor_outs[1], inter)
    for i in range(2, count):
        next_inter = circuit.new_wire()
        Or(circuit, inter, xor_outs[i], next_inter)
        inter = next_inter
    Not(circuit, inter, out_eq)
</code></pre>
<p>To keep our implementation of <code>MultiEquals</code> efficient—especially since we'll use many of them in our RAM module—we'll avoid the naive approach of using an array of <code>Equals</code> components followed by a big AND gate.</p>
<p>Instead, we'll take a more optimized route:</p>
<ul>
<li>XOR each pair of corresponding bits from the two inputs. This will produce a 1 for any position where the bits differ.</li>
<li>OR all the XOR results together. If any pair of bits is unequal, the result will be 1.</li>
<li>NOT the final result. This gives us 1 only if all bits are equal—exactly what we want.</li>
</ul>
<p>This approach reduces the depth of the logic and avoids constructing redundant gates, making it both faster and more resource-efficient.</p>
<h3 id="selective-reading"><a class="header" href="#selective-reading">Selective reading</a></h3>
<p>The read-mode scenario is even simpler. Memory cells continuously output their internal values to their output pins, regardless of the clock signal—so the clock doesn't matter at all in this case. What we do need is a way to <em><strong>select</strong></em> which register's outputs should be routed to the memory component’s output pins, based on the given address.</p>
<p>To handle this, we introduce a new and very useful component: the multiplexer. Before moving on to our final RAM implementation, let’s take a closer look at how a multiplexer works and how it can be implemented.</p>
<p>A <strong>vanilla multiplexer</strong> is a digital circuit that takes in \(2^n\) input bits—representing the options to choose from—and another \(n\) bits as a <code>selection</code> input, which tells the circuit which option to access. The output is a single bit: the value of the selected input at the specified index.</p>
<p>You can think of a multiplexer as being conceptually similar to accessing a boolean array: <code>output = data[selection]</code>, where <code>data</code> is a bit array with \(2^n\) elements and <code>selection</code> is an \(n\)-bit value indicating which array entry to output.</p>
<p>You can start by building a 2-input multiplexer and then use it to construct larger multiplexers. A 2-input multiplexer takes two data bits as available options and a single selection bit. If the selection bit is 0, the first data bit is output. If the selection bit is 1, the second data bit is output.</p>
<p>Here is a truth-table for the multiplexer described:</p>
<div class="table-wrapper"><table><thead><tr><th>data</th><th>sel</th><th>out</th></tr></thead><tbody>
<tr><td>00</td><td>0</td><td>0</td></tr>
<tr><td>00</td><td>1</td><td>0</td></tr>
<tr><td>01</td><td>0</td><td>0</td></tr>
<tr><td>01</td><td>1</td><td>1</td></tr>
<tr><td>10</td><td>0</td><td>1</td></tr>
<tr><td>10</td><td>1</td><td>0</td></tr>
<tr><td>11</td><td>0</td><td>1</td></tr>
<tr><td>11</td><td>1</td><td>1</td></tr>
</tbody></table>
</div>
<p>Which can be easily constructed using basic logic gates:</p>
<p><code>out = (!data[0] &amp; sel) | (data[1] &amp; sel)</code></p>
<p>And here is the equivalent Python component:</p>
<pre><code class="language-python=">def Mux1x2(circuit, in_sel, in_options, out):
    wire_select_not = circuit.new_wire()
    and1_out = circuit.new_wire()
    and2_out = circuit.new_wire()
    Not(circuit, in_sel[0], wire_select_not)
    And(circuit, wire_select_not, in_options[0], and1_out)
    And(circuit, in_sel[0], in_options[1], and2_out)
    Or(circuit, and1_out, and2_out, out)
</code></pre>
<p>Now given two \(2^n\) input multiplexers you can build a \(2^{n+1}\) multiplexer!</p>
<ol>
<li>A \(2^{n+1}\) input multiplexer has \(2^{n+1}=2 \times 2^n\) inputs.</li>
<li>Feed the first \(2^n\) input bits to the first multiplexer and the second \(2^n\) input bits to the second multiplexer.</li>
<li>Connect the first \(n\) bits of the \(n+1\) selection pins to both multiplexers.</li>
<li>Now you have two outputs—one from each multiplexer. The final output depends on the last (most significant) selection bit. Use a 2-input multiplexer to select between these two outputs and compute the final result.</li>
</ol>
<p>We can define a meta-function that generates multiplexer component creators, given the number of input pins and a multiplexer component with one fewer selection bit.
For example, you can build a \(2^5\)-input multiplexer using two \(2^4\)-input multiplexers like this: <code>Mux5x32 = Mux(5, Mux4x16)</code></p>
<p>Then, we’ll iteratively build a \(2^8=256\) input multiplexer, which is exactly what we need for constructing our 8-bit RAM:</p>
<pre><code class="language-python=">def Mux(bits, sub_mux):
    def f(circuit, in_sel, in_options, out):
        out_mux1 = circuit.new_wire()
        out_mux2 = circuit.new_wire()

        sub_mux(
            circuit,
            in_options[0 : bits - 1],
            in_options[0 : 2 ** (bits - 1)],
            out_mux1,
        )
        sub_mux(
            circuit,
            in_sel[0 : bits - 1],
            in_options[2 ** (bits - 1) : 2**bits],
            out_mux2,
        )
        Mux1x2(circuit, [in_sel[bits - 1]], [out_mux1, out_mux2], out)

    return f


Mux2x4 = Mux(2, Mux1x2)
Mux3x8 = Mux(3, Mux2x4)
Mux4x16 = Mux(4, Mux3x8)
Mux5x32 = Mux(5, Mux4x16)
Mux6x64 = Mux(6, Mux5x32)
Mux7x128 = Mux(7, Mux6x64)
Mux8x256 = Mux(8, Mux7x128)
</code></pre>
<p>Now we're fully ready to move forward and implement our RAM design!</p>
<h3 id="chaotic-access"><a class="header" href="#chaotic-access">Chaotic access</a></h3>
<p>First things first—what do we mean by <em><strong>random-access</strong></em> memory?</p>
<p>Because in RAM, it's very efficient to read or write a value at any address, regardless of its position. The key idea is that accessing a memory cell takes the same amount of time no matter which address is used.</p>
<p>Now, compare this to how optical disks or hard drives work. These devices have to keep track of the current read/write head position, and to reach a new location, they must seek—move to the requested position relative to where they are. This makes access efficient only when reading or writing data sequentially, like going forward or backward one byte at a time.</p>
<p>However, real-world programs don't access memory so predictably. Instead, they often jump around, requesting data from widely different memory addresses. Since these access patterns are hard to predict, we call it &quot;random access.&quot; And RAM is designed specifically to handle such patterns efficiently.</p>
<p>As discussed in the previous section, the read and write modes of our RAM work independently. For the write-mode functionality, we simply need to initialize 256 8-bit registers using a loop and condition their clock signals.</p>
<p>While tracking their outputs in the wire array <code>reg_outs</code>, we’ll use eight <code>Mux8x256</code> components to select which register's output pins should be routed to the RAM’s output. Eight multiplexers are required because each of our registers has 8 bits.</p>
<pre><code class="language-python=">class RAM:
    def snapshot(self):
        return [self.regs[i].snapshot() for i in range(256)]

    def __init__(self, circuit, in_clk, in_wr, in_addr, in_data, out_data, initial):
        self.regs = []
        reg_outs = [[circuit.new_wire() for _ in range(8)] for _ in range(256)]

        for i in range(256):
            is_sel = circuit.new_wire()
            MultiEquals(circuit, in_addr, num_to_wires(circuit, i), is_sel)
            is_wr = circuit.new_wire()
            And(circuit, is_sel, in_wr, is_wr)
            is_wr_and_clk = circuit.new_wire()
            And(circuit, is_wr, in_clk, is_wr_and_clk)
            self.regs.append(
                Reg8(circuit, is_wr_and_clk, in_data, reg_outs[i], initial[i])
            )

        for i in range(8):
            Mux8x256(
                circuit, in_addr, [reg_outs[j][i] for j in range(256)], out_data[i]
            )
</code></pre>
<p>Soon, you’ll realize that our simulator isn't efficient enough to handle transistor-level simulations of RAM, especially as memory size grows. To keep things practical, it makes sense to cheat a little and provide a secondary, faster implementation of RAM—a primitive component described directly in plain Python code, much like how we handled transistors.</p>
<pre><code class="language-python=">class FastRAM:
    def snapshot(self):
        return self.data

    def __init__(self, circuit, in_clk, in_wr, in_addr, in_data, out_data, initial):
        self.in_clk = in_clk
        self.in_wr = in_wr
        self.in_addr = in_addr
        self.in_data = in_data
        self.out_data = out_data
        self.data = initial
        self.clk_is_up = False
        circuit.add_component(self)

    def update(self):
        clk = self.in_clk.get()
        addr = wires_to_num(self.in_addr)
        data = wires_to_num(self.in_data)
        if clk == ZERO and self.clk_is_up:
            wr = self.in_wr.get()
            if wr == ONE:
                self.data[addr] = data
            self.clk_is_up = False
        elif clk == ONE:
            self.clk_is_up = True

        value = self.data[addr]
        for i in range(8):
            self.out_data[i].put(self, ONE if (value &gt;&gt; i) &amp; 1 else ZERO)

        return False
</code></pre>
<p>Alright folks—the &quot;state&quot; storage part of our magical CPU/memory duo is now up and running! Now it’s time to build the state manipulator—the CPU itself—and bring everything together to finalize our design of a computer!</p>
<h2 id="the-manipulator"><a class="header" href="#the-manipulator">The manipulator</a></h2>
<p>Our definition of a computer in this chapter is a machine that can be programmed—something on which you can deploy arbitrary algorithms. We want this program to be replaceable, meaning we may deploy one program now and later substitute it with another. Therefore, it makes perfect sense that the programs on this computer need to be stored in some form of alterable memory.</p>
<p>Our construction of memory is simply an addressable group of memory cells that can store a certain number of bits. So, the &quot;programs&quot; we're referring to must be representable in a binary format—otherwise, how could they persist in memory that only stores data as bits?</p>
<p>In this section, we will discuss how we can assign meaning to numbers and bit patterns. Essentially, we want to design a very simplistic mapping from 8-bit values to &quot;meanings.&quot; These mappings will make up the <em><strong>instruction set</strong></em> of our computer. We'll also design circuits that can fetch those values from memory, interpret them, and execute their intended operations.</p>
<p>Before diving into this book's design and implementation of a processor, there’s an important question we need to address. Computer programs need a place to store and manipulate temporary values—much like using a sheet of paper as a draft when solving a math problem. That’s actually one of the primary reasons computers have memory. But we just said that a &quot;program&quot; itself is also data stored in memory. So, <em><strong>is the memory used by the program for drafting its data the same as the memory where the program itself is stored? Or are these two separate memory spaces?</strong></em></p>
<p>For modern computers, the answer is yes—both the program and its data reside in the same memory. This concept is often summed up by the phrase: <em><strong>code is data, and data is code</strong></em>. It's one of the most brilliant and fundamental ideas that form the basis of modern computing.</p>
<p>The implications of this design—known as the Von Neumann architecture—are profound. When a computer stores both the program and the data it operates on in the same memory, several important things become possible:</p>
<ul>
<li>Since programs are stored as data, they can modify themselves during execution, enabling dynamic behavior!</li>
<li>A program may generate another program: it just needs to dump some instructions on memory and jump to it!</li>
<li>Errors like buffer overflows can overwrite program instructions, leading to vulnerabilities and exploits.</li>
</ul>
<p>To keep our computer implementation simple, we will not follow the Von Neumann architecture. Instead, we will assume that code and data are stored in separate memory components.</p>
<p>[MARKER]</p>
<p>In order to decode an instruction, we first need a component that can check equality of some bits with others:</p>
<p>In order to handle the implementation complexity of our CPU, we'll organize our implementation into 5 different modules:</p>
<ol>
<li><code>Decoder</code> module takes an instruction (A 8-bit number) as its input and gives out 6 different boolean flags as its output, specifying the type of instructions.</li>
<li><code>InstructionPointer</code> module is responsible for choosing the next instruction-pointer.</li>
<li><code>InstructionMemory</code> module is a read-only 256-byte memory, giving out the instruction given its 8-bit address.</li>
<li><code>DataPointer</code> module is responsible for choosing the next data-pointer.</li>
<li><code>DataMemory</code> module is a 256-byte memory, allowing you to read/write its cells given 8-bit addresses.</li>
</ol>
<p>The <code>Decoder</code> is composed of 5 <code>MultiEquals</code> and a single <code>Equals</code> module, outputing the type of instruction as boolean flags with this rules:</p>
<p><img src="assets/decoder.png" alt="Decoding rules of instruction" /></p>
<p>If you wonder why I designed the opcodes of the instruction-set of our CPU like this: we have only 6 instructions in our CPU, and the first thing a CPU needs to recognize after fetching an instruction is the type of that instruction. A naive way is to prefix our instructions with a prefix of size at least 3-bits. The only instruction in our instruction set that needs an argument is <code>JNZ</code>, and if we spend 3-bits only for specifying the instruction type, we'll only have 5 bits left for the extra argument (Which is the location of program memory to jump). Our memory has 256 cells, and you can point only to 32 locations using 5 bits. 224 locations will be wasted and we won't be able to jump to using this design! Since <code>JNZ</code> is the only instruction with an argument, a more clever approach would be to dedicate the first bit of the 8 bits for telling the CPU if the instruction is a JNZ, or something else. In case the instruction is not <code>JNZ</code>, the CPU may recognize the exact type by looking at the other bits. In this case, we'll have 7 bits left for the location of the jump, which means 128 memory locations. Much better than 32!</p>
<pre><code class="language-python=">def Decoder(
    circuit,
    in_inst,
    out_is_fwd,
    out_is_bwd,
    out_is_inc,
    out_is_dec,
    out_is_jnz,
    out_is_prnt,
):
    MultiEquals(
        circuit,
        in_inst[0:4],
        [circuit.zero(), circuit.zero(), circuit.zero(), circuit.zero()],
        out_is_fwd,
    )
    MultiEquals(
        circuit,
        in_inst[0:4],
        [circuit.zero(), circuit.one(), circuit.zero(), circuit.zero()],
        out_is_bwd,
    )
    MultiEquals(
        circuit,
        in_inst[0:4],
        [circuit.zero(), circuit.zero(), circuit.one(), circuit.zero()],
        out_is_inc,
    )
    MultiEquals(
        circuit,
        in_inst[0:4],
        [circuit.zero(), circuit.one(), circuit.one(), circuit.zero()],
        out_is_dec,
    )
    MultiEquals(
        circuit,
        in_inst[0:4],
        [circuit.zero(), circuit.zero(), circuit.zero(), circuit.one()],
        out_is_prnt,
    )
    Equals(circuit, in_inst[0], circuit.one(), out_is_jnz)
</code></pre>
<p><code>InstructionPointer</code> is a module that decides the next memory location from which the next instruction should be fetched. You might think that the next instruction pointer is just the result of increasing the current instruction pointer by one, and we won't need to consider a independent module for calculating something as simple as that, but that's not always the case. Even in our super simple computer, there is a command that may cause our instruction pointer to jump to a completely random location of the memory: <code>JNZ</code></p>
<p>The <code>InstructionPointer</code> module could first check if a jump is needed (Based on the current instruction) and set the instruction pointer to the new value, or just increase it:</p>
<pre><code>ShouldJump = IsJNZ &amp;&amp; (Data[DataPointer] == 0)
InstPtr = ShouldJump ? JNZ_Addr : InstPtr + 1
</code></pre>
<p>Unfortunately, since our instruction are 8-bits wide and the first bit is already being used by the decoder to detect if the instruction is a JNZ, our jumps will be limited to memory locations in the range 0-127 (Instead of 0-255), since we have 7 bits left. While we are cool with a limitation like that, there are different ways we can overcome this, like, we can make our instructions wider (E.g 16 bits), or, allow some instruction to get extra arguments by performing extra memory-reads (E.g when the current instruction is JNZ, wait for another clock cycle, and perform an extra memory-read to get the memory location to jump to).</p>
<p>Here is the implementation of our simplified <code>InstructionPointer</code> module:</p>
<pre><code class="language-python=">def Mux1x2Byte(circuit, in_sel, in_a, in_b, out):
    for i in range(8):
        Mux1x2(
            circuit,
            [in_sel],
            [in_a[i], in_b[i]],
            out[i],
        )


def InstructionPointer(circuit, in_clk, in_is_jnz, in_data, in_addr, out_inst_pointer):
    zero = [circuit.zero()] * 8
    one = [circuit.one()] + [circuit.zero()] * 7

    # should_jump = Data[DataPointer] != 0 &amp;&amp; in_is_jnz
    is_data_zero = circuit.new_wire()
    is_data_not_zero = circuit.new_wire()
    should_jump = circuit.new_wire()
    MultiEquals(circuit, in_data, zero, is_data_zero)
    Not(circuit, is_data_zero, is_data_not_zero)
    And(circuit, in_is_jnz, is_data_not_zero, should_jump)

    # InstPointer = should_jump ? in_addr : InstPointer + 1
    inst_pointer_inc = [circuit.new_wire() for _ in range(8)]
    inst_pointer_next = [circuit.new_wire() for _ in range(8)]
    Adder8(
        circuit,
        out_inst_pointer,
        one,
        circuit.zero(),
        inst_pointer_inc,
        circuit.new_wire(),
    )
    Mux1x2Byte(
        circuit,
        should_jump,
        inst_pointer_inc,
        in_addr + [circuit.zero()],
        inst_pointer_next,
    )

    return Reg8(circuit, in_clk, inst_pointer_next, out_inst_pointer, 0)
</code></pre>
<p>A very important difference of the computer we have designed and the computer you are using to read this book is that, we have considered two independent memory modules for storing the program/data. In a regular computer both the program and the data it manipulates are stored in a single memory component (This is also known as Von-Neumann architecture!).</p>
<p>The reason we didn't go in that direction is merely avoiding complexity. This has secretly made our life much easier mainly because we can now read a instruction, decode it and execute it all in a single clock cycle. If the program and the data were both stored in a single memory component, the CPU would need to at least perform 2 memory reads in order to execute an instruction, one for reading the instruction itself, and one in case the fetched instructions has something to do with the memory. (Our current RAM doesn't allow you to read two different memory locations at the same time). Not only that, your CPU would also need extra circuitry in order to know which &quot;stage&quot; it is during a cycle. Is it supposed to &quot;read&quot; an instruction, or execute an instruction that it has already read and stored in a temporary buffer? We avoided all this just by separating the memories.</p>
<p>Although having program/data in a single memory component makes your CPU much more complicated, it gives you interesting features: Imagine a program write on itself, changing its own behavior, or imagine a program generating another program, and jumping into it! It provides us whole new set of opportunities.</p>
<p>The reason you can download a compressed executable file from the internet, uncompress it, and run it right away is that the data and program are in the same place!</p>
<p>Anyway, since a multi-stage CPU is something that you can figure out and build on your own, we'll keep our implementation simple and just consider an independent RAM for storing the instructions:</p>
<pre><code class="language-python=">def InstructionMemory(circuit, in_clk, in_inst_pointer, out_inst, code=&quot;&quot;):
    return FastRAM(
        circuit,
        in_clk,
        circuit.zero(),
        in_inst_pointer,
        [circuit.zero()] * 8,
        out_inst,
        compile(code),
    )
</code></pre>
<pre><code class="language-python=">def DataPointer(circuit, in_clk, in_is_fwd, in_is_bwd, data_pointer):
    one = [circuit.one()] + [circuit.zero()] * 7
    minus_one = [circuit.one()] * 8

    # data_pointer_inc = data_pointer + 1
    data_pointer_inc = [circuit.new_wire() for _ in range(8)]
    Adder8(
        circuit, data_pointer, one, circuit.zero(), data_pointer_inc, circuit.new_wire()
    )

    # data_pointer_inc = data_pointer - 1
    data_pointer_dec = [circuit.new_wire() for _ in range(8)]
    Adder8(
        circuit,
        data_pointer,
        minus_one,
        circuit.zero(),
        data_pointer_dec,
        circuit.new_wire(),
    )

    data_pointer_next = [circuit.new_wire() for _ in range(8)]
    in_is_fwd_bwd = circuit.new_wire()
    Or(circuit, in_is_fwd, in_is_bwd, in_is_fwd_bwd)
    tmp = [circuit.new_wire() for _ in range(8)]
    Mux1x2Byte(circuit, in_is_bwd, data_pointer_inc, data_pointer_dec, tmp)
    Mux1x2Byte(circuit, in_is_fwd_bwd, data_pointer, tmp, data_pointer_next)

    return Reg8(circuit, in_clk, data_pointer_next, data_pointer, 0)
</code></pre>
<pre><code class="language-python=">def DataMemory(circuit, in_clk, in_addr, in_is_inc, in_is_dec, out_data):
    one = [circuit.one()] + [circuit.zero()] * 7
    min_one = [circuit.one()] * 8

    is_wr = circuit.new_wire()
    Or(circuit, in_is_inc, in_is_dec, is_wr)

    data_inc = [circuit.new_wire() for _ in range(8)]
    data_dec = [circuit.new_wire() for _ in range(8)]
    Adder8(circuit, out_data, one, circuit.zero(), data_inc, circuit.new_wire())
    Adder8(circuit, out_data, min_one, circuit.zero(), data_dec, circuit.new_wire())
    data_next = [circuit.new_wire() for _ in range(8)]
    Mux1x2Byte(circuit, in_is_dec, data_inc, data_dec, data_next)

    return FastRAM(
        circuit, in_clk, is_wr, in_addr, data_next, out_data, [0 for _ in range(256)]
    )
</code></pre>
<p>Lastly, our computing machine start working when all of these modules get together in a single place:</p>
<pre><code class="language-python=">class CPU:
    def snapshot(self):
        print(&quot;Data Pointer:&quot;, self.data_pointer.snapshot())
        print(&quot;Instruction Pointer:&quot;, self.inst_pointer.snapshot())
        print(&quot;RAM:&quot;, self.ram.snapshot())

    def __init__(
        self,
        circuit: Circuit,
        in_clk: Wire,
        code: str,
        out_ready: Wire,
        out_data,
    ):
        inst_pointer = [circuit.new_wire() for _ in range(8)]
        inst = [circuit.new_wire() for _ in range(8)]

        data_pointer = [circuit.new_wire() for _ in range(8)]
        data = [circuit.new_wire() for _ in range(8)]

        is_fwd = circuit.new_wire()
        is_bwd = circuit.new_wire()
        is_inc = circuit.new_wire()
        is_dec = circuit.new_wire()
        is_jmp = circuit.new_wire()
        is_prnt = circuit.new_wire()

        Forward(circuit, is_prnt, out_ready)
        for i in range(8):
            Forward(circuit, data[i], out_data[i])

        # inst = Inst[inst_pointer]
        self.rom = InstructionMemory(circuit, in_clk, inst_pointer, inst, code)

        # is_fwd = inst[0:4] == 0000
        # is_bwd = inst[0:4] == 0100
        # is_inc = inst[0:4] == 0010
        # is_dec = inst[0:4] == 0110
        # is_prnt = inst[0:4] == 0001
        # is_jmp = inst[0] == 1
        Decoder(circuit, inst, is_fwd, is_bwd, is_inc, is_dec, is_jmp, is_prnt)

        # inst_pointer =
        #   if is_jmp: inst[1:8]
        #   else: inst_pointer + 1
        self.inst_pointer = InstructionPointer(
            circuit, in_clk, is_jmp, data, inst[1:8], inst_pointer
        )

        # data_pointer =
        #   if is_fwd: data_pointer + 1
        #   if is_bwd: data_pointer - 1
        #   else: P
        self.data_pointer = DataPointer(circuit, in_clk, is_fwd, is_bwd, data_pointer)

        # data = Data[data_pointer]
        #   if is_inc: Data[data_pointer] + 1
        #   if is_dec: Data[data_pointer] - 1
        #   else: Data[data_pointer]
        self.ram = DataMemory(circuit, in_clk, data_pointer, is_inc, is_dec, data)
</code></pre>
<p>Now, let's write a compiler/assembler that is able to convert Brainfuck codes into opcodes runnable by our Brainfuck Processor!</p>
<pre><code class="language-python=">def compile(bf):
    opcodes = []
    locs = []

    for c in bf:
        if c == &quot;&gt;&quot;:
            opcodes.append(0)
        elif c == &quot;&lt;&quot;:
            opcodes.append(2)
        elif c == &quot;+&quot;:
            opcodes.append(4)
        elif c == &quot;-&quot;:
            opcodes.append(6)
        elif c == &quot;.&quot;:
            opcodes.append(8)
        elif c == &quot;[&quot;:
            locs.append(len(opcodes))
        elif c == &quot;]&quot;:
            opcodes.append(1 + (locs.pop() &lt;&lt; 1))

    return opcodes + [0 for _ in range(256 - len(opcodes))]
</code></pre>
<p>Let's write a program that prints out the fibonnaci sequence and run it:</p>
<pre><code class="language-python=">if __name__ == &quot;__main__&quot;:
    circ = Circuit()
    clk = circ.new_wire()

    out_ready = circ.new_wire()
    out = [circ.new_wire() for _ in range(8)]

    OSCILLATOR = &quot;OSCILLATOR&quot;

    clk.put(OSCILLATOR, ZERO)

    code = &quot;+&gt;+[.[-&gt;+&gt;+&lt;&lt;]&gt;[-&lt;+&gt;]&lt;&lt;[-&gt;&gt;+&gt;+&lt;&lt;&lt;]&gt;&gt;[-&lt;&lt;+&gt;&gt;]&gt;[-&lt;+&gt;]&lt;]&quot;

    cpu = CPU(circ, clk, code, out_ready, out)
    print(&quot;Num components:&quot;, circ.num_components())

    while True:
        circ.stabilize()

        if out_ready.get() and clk.get():
            print(wires_to_num(out))

        clk.put(OSCILLATOR, 1 - clk.get())
</code></pre>
<p>Unfortunately, the CPU we just implemented is not a 100% accurate implementation of Brainfuck, the slight difference is that in standard Brainfuck, the operation <code>[</code> acts like a <code>JZ</code> (Jump if zero!) instruction, it jumps to the corresponding <code>]</code> when the data in the data-pointer is zero. In our implementation, the <code>[</code> operator is compiled to nothing, and is ignored, although this doesn't stop us for having loops!</p>
<h2 id="what-about-keyboards-monitors-and-etc"><a class="header" href="#what-about-keyboards-monitors-and-etc">What about keyboards, monitors and etc?</a></h2>
<p>So far, our CPU has been able to perform computation with values that were internally generated by repeatedly incrementing the value of a memory-cell, but we'd like to be able to pass data from the outside of the CPU (E.g a keyboard) too, It'd be also cool if the CPU was able to report the final output when it's done. We can't expect the user of the CPU to inspect the result of a program by looking at the RAM.</p>
<p>Typically, there are 2 ways CPUs can communicate with the external world:</p>
<ol>
<li>By allocating dedicated in/out wires.</li>
<li>Sharing the RAM with other devices</li>
</ol>
<h2 id="other-ways-to-compute"><a class="header" href="#other-ways-to-compute">Other ways to compute?</a></h2>
<p>I just got reminded of an interesting article I read 5 years ago on an IEEE Specturm magazine (You can find a lot of interesting stuff there!). The article was discussing some strange form of computing, known as <em><strong>Stochastic Computing</strong></em>. It has also been a popular research topic in 1960s, according to the article. I'm bringing it here to remind you that there isn't a single way to build machines that can compute.</p>
<p>The idea is emerged from the fact that computation costs a lot of energy. You'll need hundred (Or even thousands) of transistors in order to do single addition/multiplications, and each of these transistors are going to cost energy. Stochastic Computing, as its name suggests, tries to exploit the laws of probability for performing calculations. The concept can be perfectly understood with an example:</p>
<p>What is the odds of throwing a dice and getting a value less-than-or-equal to 3? Easy! There are a total of 3 outcomes that are less-than-equal 3 (1,2 and 3), thus, dividing \(\frac{3}{6}\) gives us 0.5. In the general case, the odds of getting an outcome less-than-equal \(n\) would be \(\frac{n}{6}\).</p>
<p>Now imagine we have two dices. If we throw them both, what is the odds of getting a value less-than-equal \(n_1\) for the first dice and a value less-than-equal \(n_2\) for the second dice? Based on the rules of probability, we know that the probability would be \(\frac{n_1}{6}\times\frac{n_2}{6}=\frac{n_1n_2}{36}\). For example, in case \(n_1=3\) and \(n_2=2\), the probability would be \(\frac{3}{6}\frac{2}{6}=\frac{1}{6}\). As you can see, a multiplication is happening here.</p>
<p>Now, the point is you don't have to do the calculation yourself. You can let the universe do it for you: just throw the pair of dices as many times as you can, and count the cases where the first dice got less-than-equal 3 and the second dice got less-than-equal 2, and then divide it by the total number of experiments. If you perform the experiment many times, the value calculated value will get closer and closer to \(\frac{1}{6}\).</p>
<p>In order to make use of this concept in an actual hardware, we first need some kind of encoding: a method by which we can translate actual numbers into probabilities (Because our method was only able to multiply probability values with each other and not any actual numbers). A smart-conversion for translating numbers in the range \(0 \le p \le 1\) is to create bit-streams in which you'll get 1s with probabiliy \(p\). E.g, you can translate the number 0.3 to a bit-stream like this: <code>00101000011001100000</code>.</p>
<p>Now, the goal would be to create a third bit-stream, in which the probability of getting a 1 is \(p_1 \times p_2\). This can be achieved with a regular AND gate! AND gates really behave like multipliers, if the numbers we are working with are binary. So just substitute deterministic 0 and 1 with probabilistic bit-streams, and you'll be able to multiply floating-point numbers between 0 and 1!</p>
<p>[IMG AND two bit-streams]</p>
<p>Unlike multiplying, adding is not as straightforward. The reason is, by adding two probabilities, which are numbers between 0 and 1, you'll get a value that can get above 1 (Maximum 2). This is not a valid probability, thus you can't represent it with a bit-stream. But there is a hack! Assume our goal is not to calculate \(p_1+p_2\) but to calculate \(\frac{p_1+p_2}{2}\), which is indeed a number below 1. If that's what we want to calculate, we can do it using a Multiplexer gate which its control pin is connected to a third bit-stream which gives out 1s 50% of the times. This way, we are effectively calculating the average of the inputs of the multiplexer, which is equal to \(\frac{p_1+p_2}{2}\). Smart, right?</p>
<p>In case you found the topic interesting, try designing a more challeging circuit yourself. E.g. try designing a circuit that can add two probabilities like this: \(min(p_1 + p_2,1)\) instead of \(\frac{p_1+p_2}{2}\). I'm not sure if such thing is possible at all, it's just something that popped in my mind, but it might be work thinking, and may also show you the limitations of this kind of computing.</p>
<p>That's it, yet another way to compute! The point is to admire how little pieces that do simple stuff can get together and do amazing stuff!</p>
<h2 id="exploiting-the-subatomic-world"><a class="header" href="#exploiting-the-subatomic-world">Exploiting the subatomic world</a></h2>
<p>So far, we have been working on cause-and-effect chains that were totally deterministic and predictable. We saw how we can exploit the flow of electricity and route it in a way so that it can do logical operations like AND, OR, NOT and etc.</p>
<p>There are some particles in our universe that do not have determinsitic behaviors but are probabilistic. You might first think that randomness is a poison for computers, but we humans are greedy, we want to take advantage of everything, and luckily, we have found ways to exploit non-determinism and solve problems with it that a normal computer just can't (Without spending more time than the age of the universe).</p>
<p>Before getting into the details of quantum computing and algorithms, it's good to know the history behind it.</p>
<p>As you may already know, Albert Einstein, the famous German physicist, in his special theory of relativity, argued that you can't transfer data between two points in the space faster than the speed of light. This means that, there are some unfortunate limitations in our universe. For example:</p>
<ul>
<li>We can't have real-time communication with people living in Mars, there will always be an annoting lag.</li>
<li>We can't  see the current state of the stars far away from us. We can only see their past. The star could be long gone and what we percieve could be really old photons that are reaching to our eyes from millions of years ago.</li>
<li>As humans residing on Earth, we will never see other humans reach planets that are more than hundreds of light-years far from us, even if we assume that we are capable of building spaceships that can travel near the speed of light. It will take hundreds of years to reach there, and we'll be dead by then!</li>
</ul>
<p>There is no way to escape this limitation. In fact, not only physical stuff, but also <em><strong>data</strong></em> cannot travel that fast. It takes around 7 minutes for light to travel from sun to earth. This means, it takes at least 7 minutes to send any kind of data from sun to earth. Sun, as you know, pulls the earth because of its gravity. What happens when you remove the sun from the solar system? Will the earth stop rotating around the non-existing sun and start moving in a straight line, immediately? No, it takes at least 7 minutes for earth to feel that nothing is pulling it anymore. The non-existing sun would just shine normally, and earth will rotate around it just as before, for 7 minutes, and then comes the darkness! If the loss of gravity of the sun was felt immediatly, we could build a communication system with no delay, i.e faster than the speed of light! You can just map existing of gravity to 1, and loss of gravity as 0, and send your data through such a protocol!</p>
<p>Everything was alright and made sense, until some physicists claimed that there are some particles in the universe that are somehow coupled/connected with each other. These particles have immediate effects on each other, even if they are millions of years away from each other. This meant that we can transfer data faster than light: given two particles that are &quot;paired&quot; with each other, you can do something with the first particle, and someone holding the other particle in the other side of the universe, can &quot;sense&quot; there is something going on with the first particle. Thus you guys can communicate with each other faster than the speed of light!</p>
<h2 id="we-live-in-the-matrix"><a class="header" href="#we-live-in-the-matrix">We live in The Matrix!</a></h2>
<p>We are not going to explore all the physics and math behind these phenomena, we are engineers, not physicists. In order to make sense of it, let's assume that the world we live in is a computer simulation, just like the movie: The Matrix</p>
<p>In this simulation, our world is made of <em><strong>particles</strong></em>. Smallest possible building blocks of this universe. For optimization purposes, some properties of these particles are undetermined and random. These properties will only get their determined values when someone tries to measure them!</p>
<p>Now, here is the strange thing: assume there are some particles in our simulated world that have a boolean property named &quot;spin&quot;, which can <em><strong>randomly</strong></em> become false (Down!), or true (Up!), upon measurement. But, some of these particles have a pair that are guaranteed to have opposite spin.</p>
<p>How is this possible? How can the spin of a particle be both:</p>
<ol>
<li>Random</li>
<li>Opposite of its pair</li>
</ol>
<p>at the same time? Quantum physicists argued that, when we measure the spin of the particle A, the second particle will collapse into the opposite state of B, instantly. That holds true even if the particles are light-years apart!</p>
<p>Let's investigate the behavior in an experiment. Assume we have a machine that is able to generate entangled particles and shoot them to the left and right sides, and there are some spin-detectors in both sides that will show the spin of the particles once they reach there:</p>
<p><img src="assets/entangled.png" alt="The spin of a particle is determined according to its pair" /></p>
<p>When you actually do this experiment in a lab, you'll always see that the spin of the right and left particles are opposite of each other. Quantum physicist's theory is that, the particles do not have definite spins when they are generated. They only acquire a definite spin when they reach the detector. If that's the case, and their spin is truly random, then how do these particles get opposite spins? If their spin is truly random, they'll have to to talk with each other, telling their spin so that the other particle can get the other spin. If the particles are far from each other, their data-transmission should happen faster than the speed of light.</p>
<p>Einstein, seeing that particles are not obeying his no-faster-than-light law, claimed that the spin of the entangled particles are not random, but their spins are deterministically chosen upon creation, so they don't have to &quot;communicate&quot; with each other. Nobody could prove that Einstein is wrong. Nobody could prove he is right either. In fact, some scientists claimed that this will always remain a mystery, since there is no way to experiment whether the particles know their spin before the measurement or not, until, an Irish physicist named John Stewart Bell designed an experiment that could show which theorem is true!</p>
<p>Fortunately, one doesn't need to know a lot of math and physics in order to understand his experiment. The experiment is as follows:</p>
<p>Imagine, instead of measuring only a single property, we measure three different properties (E.g spin of the particle around three different axis). The results will be similar to the case where we only measure a single axis: the spins of the right-hand-side will be opposite of the respective spins of the left hand side (E.g If the left-hand-side particle's spins are Up-Up-Down, the right-hand-side spins will be Down-Down-Up). Now, instead of measuring the spins in all three axis at the same time, we'll put three buttons on the detectors, allowing us to choose the axis we want to measure the spin in.</p>
<p><img src="assets/bellsinequality.png" alt="If Einstein's claim is true, the all three properties of the particle are determined prior reaching to the detectors" /></p>
<p>Unlike the previous experiment in which the spin of the left detector and right detector were opposite of each other, now it is possible to observe same spins by the detectors. Now, let's assume that Einstein's statement is true, and the spins of the particles are determined when the particles are generated. Assuming we randomly choose the button on the detectors, what is the probability of observing opposite directions on them? It's simple probability, let's try all different combinations:</p>
<p>[TODO]</p>
<p>It is obvious that in at least \(\frac{5}{9} \approx 55%\) of the experiments, the detectors should show opposite directions. Physicists experimented this and only in 50% of the samples the detectors appeared to show opposite directions. <em><strong>This was a strong proof that we live in The Matrix!</strong></em></p>
<h2 id="exploiting-the-indeterminism"><a class="header" href="#exploiting-the-indeterminism">Exploiting the indeterminism</a></h2>
<p>If you are now convinced that we are living in a computer simulation, we can now exploit the fact that some particles in our world do not have definite states, and try to build new types of computers with it, computers than can compute stuff that a simple classical computer just can't, welcome to the world of quantum computers!</p>
<p>Before teleporting to the quantum world, let's first agree on what <em><strong>state</strong></em> means on a classical computer. In a classical computer (E.g the Brainfuck processor we built in the previous sections), a n-bit register may only be in one of the \(2^n\) possible states. In the quantum world however, particles may have indefinite states. A particle may be 50% spin up and 50% spin down. By interpreting those indefinite properties as bits, we may have bits that are both 1 and 0 at the same time! So a n-bit quantum register maybe in all \(2^n\) states as a same time. In other words, an n-bit qunatum register is a probability distribution showing how possible each of the \(2^n\) states are. Let's simulate the a quantum-state as a Python class:</p>
<pre><code class="language-python=">import math
import random


class QuantumState:
    def __init__(self, bits):
        self.bits = bits
        self.values = [0 + 0j] * (2**bits)
        self.values[0] = 1 + 0j

    def is_unitary(self):
        return math.isclose(abs(sum(map(lambda v: v * v, self.values))), 1)

    def apply(self, gate):
        res = []
        for row in gate:
            res.append(sum([row[i] * self.values[i] for i in range(len(self.values))]))
        self.values = res

    def observe(self):
        dice = random.random()
        accum = 0
        for i, p in enumerate(self.values):
            accum += abs(p * p)
            if dice &lt; accum:
                s = bin(i)[2:]
                while len(s) &lt; self.bits:
                    s = &quot;0&quot; + s
                return s
        raise Exception()

    def sample(self, times=1000):
        states = {}
        for _ in range(times):
            v = self.observe()
            if v not in states:
                states[v] = 0
            states[v] += 1
        return states
</code></pre>
<p>As you can see in the code, a n-bit Quantum register is a list of \(2^n\) complex numbers. We can also assume that quantum-state is a unitary vector (A vector that its length is 1). In order to check if a qunatum-state is valid or not, we have implemented a <code>is_unitary</code> method which calculates the length of the vector, and checks if it is equal to 1.</p>
<p>Quantum-gates are transformations that can convert a unitary vector to another unitary vector. Such transformations can be represented with square matrices! The <code>apply</code> method applies a quantum-gate \(T\) (Which is basically a \(2^n \times 2^n\) matrix) on the gate, resulting to a new state: \(S_{next}=S \times T\)</p>
<p>Lastly, in order to simulate a quantum-state's non-deterministic behavior, we have added a <code>observe</code> which throws a dice (Using Python's <code>random.random()</code> function) and decides what the observed state of the quantum-state is, given the probability distribution.</p>
<p>We can sample the results of the <code>observe</code> function for many times, in order to get more sense of what is happening. We have defined a method <code>sample</code> for this purpose.</p>
<p>Initially, we set the probability of the n-bit quantum-state to be \(000 \dots 000\) for 100% of the time. Thus, if we start sampling a state with no transformations, we will always be in the first state:</p>
<pre><code class="language-python=">s = QuantumState(3)
print(s.sample(1000))  # {'000': 1000}
</code></pre>
<p>Here are some gates that can be applied on single qubits:</p>
<pre><code class="language-python=">def not_gate():
    return [[0, 1], [1, 0]]
</code></pre>
<p>And there are some </p>
<pre><code class="language-python=">def cnot_gate():
    return [[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 0, 1], [0, 0, 1, 0]]


def swap_gate():
    return [[1, 0, 0, 0], [0, 0, 1, 0], [0, 1, 0, 0], [0, 0, 0, 1]]
</code></pre>
<h2 id="why-matrices"><a class="header" href="#why-matrices">Why matrices?</a></h2>
<p>The term quantum computer is a bit misleading. In fact, a quantum-computer is a regular classical-computer equipped with a device that can perform operations on a quantum-state (Maybe someday, you’ll be able to connect a quantum-state to your laptop too). For example, the quantum operation could be radiating the “state” with a electromagnetic wave of some frequency. A real quantum computer doesn’t perform matrix multiplications, like what we did in our simulator! Matrices just happened to be good mathematical structures for modeling different quantum operations!</p>
<p>As previously noted, a quantum-state is somehow a probability distribution over its different possible states.</p>
<p>The state is a vector of length one. It’s length will always be one.</p>
<p>In a quantum operation, the final result of one bit is somehow a linear combination of all other bits. That's why quantum operations are defined by matrices, because matrices are just a group of coefficient-rows that are stacked on top of each other.</p>
<h2 id="brainfuck"><a class="header" href="#brainfuck">Brainfuck</a></h2>
<p>Most people say it's crucial to learn C, if you want to be a good programmer! I say, knowing how to program in Brainfuck is what makes you a Super Programmer! Brainfuck, built in 1993 by Urban Müller, is an esoteric programming language, which means, it has been designed in a way so that very few people understand or like it! Learning how to program in Brainfuck is a great way to see how it's possible to build wonderful stuff by putting simple components together.</p>
<p>Brainfuck is extremely minimalistic, it only consists of 8 simple commands. It is also very simple to learn, but hard to build anything meaningful out of it! Brainfuck is Turing-Complete, which means, you can theoritically build web browsers, 3D games, and any kind of complicated software with it! Here is the specification of the language:</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Description</th></tr></thead><tbody>
<tr><td>&gt;</td><td>Increment the data pointer</td></tr>
<tr><td>&lt;</td><td>Decrement the data pointer</td></tr>
<tr><td>+</td><td>Increment the byte at the data pointer</td></tr>
<tr><td>-</td><td>Decrement the byte at the data pointer</td></tr>
<tr><td>.</td><td>Output the byte at the data pointer</td></tr>
<tr><td>,</td><td>Store an input at the data pointer</td></tr>
<tr><td>[</td><td>Does nothing, acts as a flag</td></tr>
<tr><td>]</td><td>If the byte at the data pointer is not 0, jump to the corresponding [</td></tr>
</tbody></table>
</div>
<p>Before trying to build anything with Brainfuck, let's write an interpreter for this language first! The original Brainfuck machine specification has 30000 memory-cells, each storing a 8-bit byte (Unsigned integer between 0 to 255). </p>
<p>The following code is an Brainfuck interpreter written in Python, which executes a &quot;Hello World!&quot; program written in Brainfuck.</p>
<pre><code class="language-python3=">code = '''
++++++++[&gt;++++[&gt;++&gt;+++&gt;+++&gt;+&lt;&lt;&lt;&lt;-]&gt;+&gt;+&gt;-&gt;&gt;+[&lt;]&lt;-]&gt;&gt;.&gt;
---.+++++++..+++.&gt;&gt;.&lt;-.&lt;.+++.------.--------.&gt;&gt;+.&gt;++.
'''

memory = [0] * 30000
ptr = 0
pc = 0

stack = []
while pc &lt; len(code):
    if code[pc] == &quot;&gt;&quot;:
        ptr = (ptr + 1) % 30000
    elif code[pc] == &quot;&lt;&quot;:
        ptr = (ptr - 1) % 30000
    elif code[pc] == &quot;+&quot;:
        memory[ptr] = (memory[ptr] + 1) % 256
    elif code[pc] == &quot;-&quot;:
        memory[ptr] = (memory[ptr] - 1) % 256
    elif code[pc] == &quot;[&quot;:
        stack.append(pc)
    elif code[pc] == &quot;]&quot;:
        top = stack.pop()
        if memory[ptr] != 0:
            pc = top
            continue
    elif code[pc] == &quot;.&quot;:
        print(chr(memory[ptr]), end=&quot;&quot;)

    pc += 1
</code></pre>
<p>If you want to reach maximum speeds while running a Brainfuck program, it is also worth noting that Brainfuck can be directly transpiled to C, you'll just need to initialize some variables and then do these substitutions:</p>
<pre><code class="language-clike">unsigned char mem[30000] = {0};
unsigned int pc = 0;
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Equivalent C code</th></tr></thead><tbody>
<tr><td>&gt;</td><td><code>ptr++;</code></td></tr>
<tr><td>&lt;</td><td><code>ptr--;</code></td></tr>
<tr><td>+</td><td><code>mem[ptr]++;</code></td></tr>
<tr><td>-</td><td><code>mem[ptr]--;</code></td></tr>
<tr><td>.</td><td><code>putchar(mem[ptr));</code></td></tr>
<tr><td>,</td><td><code>mem[ptr] = getchar();</code></td></tr>
<tr><td>[</td><td><code>while(mem[ptr] != 0) {</code></td></tr>
<tr><td>]</td><td><code>}</code></td></tr>
</tbody></table>
</div>
<p>Here is a Brainfuck-to-C transpiler written in Python (<code>bf2c.py</code>):</p>
<pre><code class="language-python3=">print('#include &lt;stdio.h&gt;')
print('void main() {')
print('unsigned char mem[30000] = {0};')
print('unsigned int ptr = 0;')

mapping = {
    '&gt;': 'ptr++;',
    '&lt;': 'ptr--;',
    '+': 'mem[ptr]++;',
    '-': 'mem[ptr]--;',
    '[': 'while(mem[ptr]) {',
    ']': '}',
    '.': 'putchar(mem[ptr]);',
    ',': 'mem[ptr] = getchar();'
}

bf = input()

for ch in bf:
    if ch in mapping:
        print(mapping[ch])
    
print('}')
</code></pre>
<p>In order to use this tool for running your Brainfuck programs:</p>
<ol>
<li>Write your Brainfuck program in a file: <code>main.bf</code></li>
<li>Transpile it to C: <code>python3 bf2c.py &lt; main.bf &gt; main.c</code></li>
<li>Compile the C program: <code>gcc main.c</code></li>
<li>Run the program: <code>./a.out</code></li>
</ol>
<p>Let's try to build things with this language now!</p>
<p><strong>Hello World!</strong></p>
<p>Printing a string is the first thing people actually do when learning a new programming language. Surprisingly, printing stuff isn't that straightforward in an esoteric programming language like Brainfuck. Since a Brainfuck program's inputs and outputs are bytes, we'll need to work with an 8-bit character encoding (Like ASCII) in order to work with strings. </p>
<p>The instruction <code>.</code> is responsible for outputting bytes, and it outputs the byte the program is currently pointing at. So we somehow have to put our desired ASCII code in that memory location in order to print it. Naively, this would mean we have to put a lot of <code>+</code> instructions to make the current memory cell equal with our desired ASCII character. For example, we'll need to put 72 <code>+</code> instructions in order to print a <code>H</code> character! There are ways we can optimize the process of printing a string. Since the number 72 is already in the memory, we won't need to put 69 other <code>+</code> signs in another memory location in order to print the next letter <code>E</code>, we'll just need to subtract the old character by 3 (72-3=69), and print it again! This way we can write a Brainfuck program that can print &quot;HELLO WORLD&quot; in around 160 instructions:</p>
<pre><code>+++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++
++.---.+++++++..+++.                ; Print 'HELLO'

&gt;++++++++++++++++++++++++++++++++.&lt; ; Print ' '

++++++++.--------.+++.------.------
--.                                 ; Print 'WORLD'
</code></pre>
<p>Since printing the space character (ASCII code 32) required a huge jump, we preferred generating it in a separate memory cell (By moving the cursor to the next cell, incrementing it 32 times, printing it and the moving the cursor back to its original place).</p>
<p>From now, instead of jumping to different locations of the memory through <code>&lt;&gt;</code> instruction, for the sake of readability, we will express our will to jump to different locations of memory, by giving names to the locations in memory and using those names in our code when we want to jump.</p>
<p>As an example, imagine this is how we have named the memory cells of our machine:</p>
<pre><code>0 1 2 3 4 5 6 7 8 9 ...
    A     B   C
</code></pre>
<p>Imagine we would like to add the values in memory location B and C to A. Assuming we are currently on 0th memory cell, we can write the code like this:</p>
<pre><code>&gt;&gt;&gt;&gt;&gt;[-&lt;&lt;&lt;+&gt;&gt;&gt;]&gt;&gt;[-&lt;&lt;&lt;&lt;&lt;+&gt;&gt;&gt;&gt;&gt;]
</code></pre>
<p>As a human, it would be very hard to analyze what's happening in this code. We can make it significantly more readable by expressing it like this:</p>
<pre><code>B[-A+B]C[-A+C]
</code></pre>
<p>We can actually write a compiler that can handle all these namings and memory managements for us, and make our life easier!</p>
<p>Zeroing out a cell: <code>[-]</code>
Moving from A to B: <code>A[-B+A]</code>
Copying from A to B: <code>A[-B+T+A]T[-A+T]A</code></p>
<p><strong>Moving a number</strong></p>
<p>Sometimes you'll need to move a number from one memory cell to another</p>
<p><strong>Addition</strong></p>
<pre><code class="language-=">,&gt;,&lt;         ; Store two numbers in memory cells 0 and 1
[-&gt;&gt;+&lt;&lt;]     ; Add the number in slot 0 to slot 2
&gt;            ; Move to slot 1
[-&gt;+&lt;]       ; Add the number in slot 1 to slot 2
&gt;.           ; Move to slot 2 and print its content
</code></pre>
<p>Keep in mind that the program above gets ASCII characters as its input and outputs another ASCII character which its code is the sum of the input codes.</p>
<h2 id="befriending-complexity"><a class="header" href="#befriending-complexity">Befriending complexity</a></h2>
<p>As you write more complicated programs in Brainfuck, you will soon notice that the immense amount of complexity is going to become unmaintainable over time. and soon you won't be able to add more logic and features to your Brainfuck programs. That is the time when you start missing functions, classes, and all other fancy tools your favorite high-level programming language provided you for free.</p>
<p>Brainfuck is very similar to the assembly language of a very simple CPU. So it might make sense to start explaining our programs in a higher-level language that can be translated to Brainfuck, making it easier for us to build complicated programs that can run on our CPU without losing our minds. I have decided not to guide you through the process of building a compiler, because it's a world on its own. Compilers are programs that convert strings of one language to strings of another language. It's safe to say that compilers are effectively just string manipulation programs, and even if you don't know the inner workings of a modern compiler, you probably have some clues on how a compiler works. That's why we don't discuss building a compiler in this book, because the core idea behind a compiler is simple, and what we care about in this book is merely the ideas, and not production-level implemention and optimizations.</p>
<p>So, instead of designing a whole new language that can be translated to Brainfuck, a simpler approach would be to write a Python library for generating Brainfuck codes. The Python library will help us to split our Brainfuck applications into modules.</p>
<p>In this framework, we expect the modules of our Brainfuck application to reside in Python functions. These functions will all accept a <code>BrainfuckGenerator</code> class as their first argument, and all other inputs/outputs of the modules will be memory locations (<code>Pointer</code>s). There will be a <code>append</code> function within the generator class, allowing the modules to spit raw Brainfuck code into the generator. Besides that, it would be good to add some memory-management functionality to the generator class, allowing the user to allocate and free memory-cells on demand, so that the user doesn't have to worry about finding memory cells that are in-use by other modules, and focus on the logic of the application instead.</p>
<p>Here is an example of how it would look like:</p>
<pre><code class="language-python=">class Pointer:
    def __init__(self, pos: int):
        self.pos = pos


class BrainfuckGenerator:
    def __init__(self):
        self.code = &quot;&quot;
        self.pos = 0
        self.allocated = set()

    def append(self, code):
        self.code += code

    def alloc(self) -&gt; Pointer:
        pos = self.pos + 1
        while pos in self.allocated:
            pos += 1
        self.allocated.add(pos)
        return Pointer(pos)

    def free(self, ptr: Pointer):
        self.allocated.remove(ptr.pos)

    def move(self, target: Pointer):
        if target.pos &gt; self.pos:
            self.code += &quot;&gt;&quot; * (target.pos - self.pos)
        else:
            self.code += &quot;&lt;&quot; * (self.pos - target.pos)
        self.pos = target.pos
</code></pre>
<p>Our Brainfuck code generator helps us to keep track of memory locations which are being used by different modules of our Brainfuck programs and to prevent conflicts. The code generator will not let you to move to different memory locations by yourself, and you have to use to <code>move</code> function instead. The <code>move</code> function will also keep track of the current location of the data pointer and generates as many <code>&lt;</code>/<code>&gt;</code> characters as needed, when the pointer needs to be moved.</p>
<p>The <code>alloc</code> function finds the first unused memory location and flags it as allocated. The <code>free</code> function let's the user to free the memory cell again, by removing the flag from the <code>self.allocated</code> set.</p>
<p>Great! Now let's implement some modules. We'll start with simple ones, a module that zeroes out a memory-cell by moving into it and decrementing it until in gets 0 (<code>zoroize</code>), and a module for putting a fixed number into a memory-cell (<code>fill</code>). The <code>fill</code> module will use the <code>zeroize</code> module.</p>
<pre><code class="language-python=">def zeroize(bf: BrainfuckGenerator, target: Pointer):
    bf.move(target)
    bf.append('[-]')


def fill(bf: BrainfuckGenerator, target: Pointer, val: int):
    zeroize(bf, target)
    bf.move(target)
    bf.append('+' * val)
</code></pre>
<p>A more complicated example is the copy operation. As you know, we need a third memory cell in order to copy a value from a source to a destination cell. We'll use the <code>alloc</code> function in order to find an unused cell, and after we are done with it, we'll <code>free</code> it, allowing other modules to use it:</p>
<pre><code class="language-python=">def copy(bf: BrainfuckGenerator, src: Pointer, dst: Pointer):
    tmp = bf.alloc()

    # Move src to tmp and dst
    bf.move(src)
    bf.append(&quot;[-&quot;)
    bf.move(tmp)
    bf.append(&quot;+&quot;)
    bf.move(dst)
    bf.append(&quot;+&quot;)
    bf.move(src)
    bf.append(&quot;]&quot;)

    # Move tmp to src
    bf.move(tmp)
    bf.append(&quot;[-&quot;)
    bf.move(src)
    bf.append(&quot;+&quot;)
    bf.move(tmp)
    bf.append(&quot;]&quot;)

    bf.free(tmp)


bf = BrainfuckGenerator()
copy(bf, Pointer(5), Pointer(8))
print(bf.code)
</code></pre>
<p>We can even exploit the Python <code>with</code> expressions in order to implement for loops:</p>
<pre><code class="language-python=">class For:
    def __init__(self, bf: BrainfuckGenerator, i: Pointer, count: Pointer):
        self.bf = bf
        self.i = i
        self.count = count
    
    def __enter__(self):
        copy(self.bf, self.count, self.i)
        self.bf.move(self.i)
        self.bf.append('[')

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.bf.move(self.i)
        self.bf.append('-]')
</code></pre>
<p>Here is a program that prints out the letter <code>A</code> for 5 times:</p>
<pre><code class="language-python=">bf = BrainfuckGenerator()

i = bf.alloc()
cnt = bf.alloc()
ascii_a = bf.alloc()

fill(bf, ascii_a, 65)
fill(bf, cnt, 5)
with For(bf, i, cnt):
    bf.move(ascii_a)
    bf.append('.')
</code></pre>
<h2 id="what-really-happens"><a class="header" href="#what-really-happens">What really happens</a></h2>
<p>The Brainfuck CPU we created is similar to real CPUs in many ways, but it lacks many features making it impractical for any serious application. As an example, we didn’t cover how a cpu is able to interact with different hardware (our brainfuck cpu can’t), or how an operating system written for such a simple cpu would look like, or questions like that. In this section, we are going to explore some of those unclear questions you might have about your computer.</p>
<h2 id="how-can-your-computer-interact-with-other-hardware"><a class="header" href="#how-can-your-computer-interact-with-other-hardware">How can your computer interact with other hardware?</a></h2>
<p>Our brainfuck cpu doesn’t really have means for communicating with a 3rd party hardware, so you might still have confusions on how the cpu in a modern computer is connected to other hardware.</p>
<p>The answer is simple (You might figure it out and design a solution yourself too, by putting a bit of thought)
You will just need a few more wires coming out of your cpu, making it able to send/receive data with custom hardware. Besides that, you will need to add a few more instructions for writing/reading data to/from those wires (just like how you interact with your RAM)
As an example, in a x86-64 computer, the instructions x and x are used for communicating with other hardware, we can </p>
<p>Having I/O related instructions isnt the only way a CPU can connect to peripherals. There is one other way too, you can give your hardware access to some parts of your RAM, allowing your CPU to communicate with that hardware by putting data on that part of your RAM. This way, you won’t need dedicated wire for communicating data to the device, as your ram itself is being a medium for communication.</p>
<p>This method has been a popular solution for communicating with a monitor, the monitor could listen to some sections of the RAM (Also known as Video memory) and put the pixel data residing there on your monitor. This way, your cpu could render things on your monitor by simply writing stuff on your RAM. Not a single extra instruction needed!</p>
<p>Curious how you can manipulate your video memory on a Linux machine? Try this command to put random bytes on your monitor’s pixel buffer and see what happens!</p>
<h2 id="what-is-the-first-program-your-computer-executes"><a class="header" href="#what-is-the-first-program-your-computer-executes">What is the first program your computer executes?</a></h2>
<p>We saw that cpus are simple devices that can fetch instructions from memory, run them and write the side effects back to the memory. So, what are the first instructions that are being run in a computer? When you turn your computer on, your RAM is empty, and there are no instructions, so how does it start to load anything when a RAM is absolutely empty on a startup?</p>
<p>The answer is: although your computer has an empty ram, we can still trick your computer, making it believe that some constant pieces of data do exist in the very first bytes of your RAM, and put some initial programs there.</p>
<h2 id="how-can-programs-not-conflict-with-each-other-in-memory-locations"><a class="header" href="#how-can-programs-not-conflict-with-each-other-in-memory-locations">How can programs not conflict with each other in memory locations?</a></h2>
<p>This is a question that you might not have asked yourself but is an important one: when you compile a program, you will get a raw binary that contains the cpu opcodes that need to be executed. Those opcodes that have something to do with your RAM, may use static locations in your memory. Now, imagine you want your computer to load and maintain multiple programs on your ram at the same time. Since the programs are using static locations, there is a very high probability that they will use the same locations of memory for storing data. How does a cpu prevent that? Sometimes this could be malicious too, a program may try to read/write locations on memory that are not for itself (E.g a malicious program may try to read the password you entered for logging in to your shell program)</p>
<h2 id="how-are-the-keyboard-events-are-handled-by-a-computer"><a class="header" href="#how-are-the-keyboard-events-are-handled-by-a-computer">How are the keyboard events are handled by a computer?</a></h2>
<h2 id="how-can-multiple-programs-run-at-the-same-time"><a class="header" href="#how-can-multiple-programs-run-at-the-same-time">How can multiple programs run at the same time?</a></h2>
<h2 id="if-you-are-nerd-enough-to-write-an-os-yourself"><a class="header" href="#if-you-are-nerd-enough-to-write-an-os-yourself">If you are nerd enough to write an OS yourself</a></h2>
<p>You can’t really understand the way a modern computer’s cpu work without writing an operating system for it. Unfortunately, writing an operating system for a popular CPU like x86-64 involves a lot of details that are not necessarily helpful for a book like this. I’ll try my best to explain most of the important questions you might have here, but I highly encourage you to write a simple OS yourself! Here is a good roadmap for an OS project:</p>
<ul>
<li>Read about cross-compiler and try to build a C compiler targeting raw binaries on your CPU</li>
<li>Write a bootloader that is able to print something on the screen</li>
</ul>
<h2 id="lets-talk-in-gerber"><a class="header" href="#lets-talk-in-gerber">Let's talk in Gerber</a></h2>
<p>Using the discussed simulation techniques, we have been able to build a very simple computer that is surprisingly useful, only by connecting a bunch of transistors together! We showed how simple it is to build a CPU that is able to run Brainfuck programs, and we also showed that you can (With some practice and hard-work) write amazingly complex programs that can perform useful stuff using a programming language as simple as Brainfuck.</p>
<p>The fact that our CPU is only a simulation and not a real one, is a bit of a downer, but hey, since our simulation is actually a mixture of components that do exist in the real world, we can surely build a physical version of our computer with real electronic components!</p>
<p>The scary side is, our Brainfuck computer, although very simple, is still composed of thausands of transistors, which certainly means, good luck building it with a bunch of breadboards and tons of wires (Unless you are a real creep)!</p>
<p>So, what's the solution? Let's design the whole thing again using a electronic circuit-design software and ship the design file to an electronic board manufacturer? Well that's not how we do things in this book!</p>
<p>I hope you are convinced that you really can't handle the immense amount of complexity your super-simple CPU has with bread-boards. A cleaner solution is to replicate your circuit on an electronic board, where components are connected together through lanes of copper. If you are into electronics, you might already know that you can print your circuit on a fiber board which is fully covered by copper, and then put your board in a bucket of acid that is able to dissolve copper. That way, only the parts that are covered by the protected material will remain, and you will end up with a board replicating your circuit with copper lines.</p>
<p>After printing the circuit, you may drill the points where the electronic component pins should place in, and then solder them manually with a soldering iron.</p>
<p>Although the process is exciting, it involves a lot of dirt, and if you are not a professional, you may end up with a dirty board that does not work as you expect. The good news is, there are machines that do the whole process automatically for us, and their resulting board is much cleaner compared to a board made by hand.</p>
<p>So now the question is, how do these machines work, and what do we need to give them in order to get our desired output? In other words, how should we describe our board to these circuit-printing machines? Decades ago, engineers asked these questions from themselves too, so they decided that they need to design a description-language for it. The description-language would tell the board-printing-machine exactly how the copper lanes should be printed on the board. That way, the electronic-circuit-design software  could output a file containing the circuit description that could be shipped to manufacturers that are able to do all the complexities of printing circuits for us, using their machines.</p>
<p>One of the most famous languages designed for exactly this purpose is named Gerber, and in the next sections we are going to try to generate a Gerber file describing the physical version of our Brainfuck computer, again using a pure Python script. Let's dive in!</p>
<p>As you might have guessed, Gerber is somehow a graphical file format, since it describes an image that should be printed on a board. The difference is that Gerber files describe an image is printed via copper-metal, as oppsed to regular printing, where colorful inks and materials are involved.</p>
<p>Here is a Hello World Gerber program which outputs a solid circle filled with copper:</p>
<pre><code>%FSLAX26Y26*%
%MOMM*%
%ADD100C,1.5*%
D100*
X0Y0D03*
M02*
</code></pre>
<h2 id="fpgas"><a class="header" href="#fpgas">FPGAs</a></h2>
<p>Although CPUs are general purpose and can perform whatever computation you can ever imagine, sometimes it makes more sense to build specialized hardware for some applications. Not all algorithms need the fancy set of instructions your CPU provides. In fact, many of the computationally intensive application only require simple math operations. Algorithms performing image generation/manipulation are of the examples. That's why computer nowadays have an specialized processors called GPUs, which used to take of what you see on your monitos (GPUs today are not limiting themselves on graphical computations and are being used for many kinds of heavy computation)
GPUs are basically a bulk of processors which have simple instruction sets and they are really good in accelerating algorithms that are known to be <strong>embarrassingly parallel</strong>. An algorithm is embarrassingly parallel if you can divide it into chunks that can be processed by independent processors without any memory-sharing and interactions between the processors. These algorithms are so easily parallelizable, that it would be embarrasing for a programmer to be proud of parallelizing them!</p>
<p>Now there are times where you need something even simpler that a GPU (Well, GPUs are not that simple to be fair). E.g. imagine you need a device that is only able to perform multiplications, and it needs to do billions of them per second. Any CPU or GPU would be an overkill for such an application.</p>
<p>Unfortunately, it would be very costly to design and manufacture a completely new electronic board whenever you need specialized hardware. Instead of doing that, let's get smart and thing of an electronic circuit that can transform into arbitrary circuit without physical changes in its circuitry. Well, such infrastructures do exist and they are called Field-Programmable-Gate-Arrays!</p>
<p>Before getting to the details of the FPGAs, I would like you to think about the way something like a FPGA can work for a bit. The title itself is guiding you to the answer. It has something to do with &quot;gates&quot; that are &quot;programmable&quot;, maybe, unlike a regular logic gate such as AND/OR/NOT, a programmable gate is a gate that can be configured to become whatever gate you like. Try to build a programmable gate yourself, which accepts two inputs and gives out one output, and can transform to different gates when we tune it.</p>
<p>(Hint: You can use memory-cells for storing the chosen functionality of your programmable gate, and put your configuration in it through some extra input pins)</p>
<p>This way, &quot;programming&quot; a gate, would mean to put the right values inside the gate's memory-cells.</p>
<p>Here is a popular design of a programmable gate among FPGAs. They are also known as Configurable Logic Gates (Or CLBs).</p>
<h2 id="chip-8"><a class="header" href="#chip-8">CHIP-8</a></h2>
<h2 id="operating-systems"><a class="header" href="#operating-systems">Operating Systems</a></h2>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="0-preface.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="2-hear.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="0-preface.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="2-hear.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->


    </div>
    </body>
</html>
