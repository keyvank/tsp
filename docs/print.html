<!DOCTYPE HTML>
<html lang="en" class="light" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>The Super Programmer</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body class="sidebar-visible no-js">
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('light')
            html.classList.add(theme);
            var body = document.querySelector('body');
            body.classList.remove('no-js')
            body.classList.add('js');
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var body = document.querySelector('body');
            var sidebar = null;
            var sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            sidebar_toggle.checked = sidebar === 'visible';
            body.classList.remove('sidebar-visible');
            body.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="0-preface.html">Intro</a></li><li class="chapter-item expanded "><a href="1-build.html"><strong aria-hidden="true">1.</strong> Build!</a></li><li class="chapter-item expanded "><a href="2-hear.html"><strong aria-hidden="true">2.</strong> Hear!</a></li><li class="chapter-item expanded "><a href="3-see.html"><strong aria-hidden="true">3.</strong> See!</a></li><li class="chapter-item expanded "><a href="4-think.html"><strong aria-hidden="true">4.</strong> Think!</a></li><li class="chapter-item expanded "><a href="5-trust.html"><strong aria-hidden="true">5.</strong> Trust!</a></li><li class="chapter-item expanded "><a href="6-fly.html"><strong aria-hidden="true">6.</strong> Fly!</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">The Super Programmer</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="the-super-programmer"><a class="header" href="#the-super-programmer">The Super Programmer</a></h1>
<h2 id="preface"><a class="header" href="#preface">Preface</a></h2>
<p>The book you're about to read is the outcome of exploring various areas in computer science for over 15 years. The idea of writing this book began around 8 years ago when I was about 17 years old. At that time, my focus was on learning computer graphics and 3D rendering algorithms. The concept of generating 3D images by calculating the RGB values of pixels intrigued me, prompting a desire to teach it to every programmer I knew. Unfortunately, not everyone I knew was interested in learning low-level stuff like this. Instead of trying to teach what I had learned, I decided to write a book. I was confident I'd have an audience, as many programmers worldwide are eager to learn more than just web-application development (a common career path among software engineers).</p>
<p>So, I started writing the book, named it &quot;Programming the Visuals,&quot; and made a lot of progress! Not sure what happened exactly, but I got a bit discouraged after finding it hard to fill a book with content. I found myself explaining everything in less than 40 pages, and well, 40 pages are not enough for a technical book. I didn't want to clutter my book with all the details of different rendering algorithms. I just wanted to explain the core idea, in very simple words and with easy-to-understand code examples. My goal was to introduce this specific field of computer science to people, hoping they would get encouraged enough to learn anything else they'd need by themselves.</p>
<p>My computer graphics book remained untouched for years, during which I took a bachelor's degree in computer engineering and delved into other interesting fields of computer science. University was one of the places where I got clues on what to learn next. In fact, I didn't learn much in university because, contrary to what many people say, university professors do not really get deep into what they teach. They will tell you a lot of headlines, but they'll never get deep into any of them. And that makes sense too; you can't expect to get super deep in everything in a relatively short period of time. Chances are you will get specialized knowledge in only one of the fields of computer science.</p>
<p>The fact that success often comes from delving deep into only one of the many fields of computer science didn't stop me from learning them. After getting comfortable with generating pixels, I started to learn building computers, operating systems, and all of the low-level stuff many day-to-day software developers avoid learning. Unfortunately, even being a highly talented hardware engineer doesn't necessarily mean one is proficient in other aspiring (yet simple!) ideas only known to physicists, mathematicians, cryptographers, and engineers involved in areas beyond computer software and hardware. These topics remain vital for developing many fascinating forms of software, so I decided to learn them all.</p>
<p>The result? I transformed myself from a day-to-day web developer into a programmer that knows <em><strong>the starting point of building any kind of technology</strong></em> and hopefully can help get the progress of computer-related technology back on track in case a catastrophic event happens on Earth and all we have is gone (This is something that I think about a lot!).</p>
<p>After boosting my knowledge by learning all those things, I felt that it's time to extend my 40-page computer graphics book, and the result is this book!</p>
<h2 id="support"><a class="header" href="#support">Support</a></h2>
<p>If you enjoy what I'm writing and would like to support my work, I would appreciate crypto donations! I attempted to distribute my work through computer programming publishers, but the consensus is that these kinds of tutorials won't sell well. Therefore, I have decided to continue TSP as an open-source hobby project!</p>
<ul>
<li>Bitcoin: <code>bc1qjvcsjt57des7j4runchxalksueqlxgadx7fwll</code></li>
<li>Ethereum: <code>0x1a34a6763f55887444ffbd8f8d4fae8197478675</code></li>
</ul>
<p>Also, I'm thinking of allowing anyone to contribute in writing and editing of this book, so feel free to submit your shiny PRs!</p>
<p>GitHub: <a href="https://github.com/keyvank/tsp">https://github.com/keyvank/tsp</a></p>
<h2 id="intro"><a class="header" href="#intro">Intro</a></h2>
<p>Legos were my favorite toys as a kindergarten student. It was one of the only toys I could use to build stuff that didn't exist before. It let me bring my imaginations into the real world, and nothing satisfies a curious mind more than the ability to build unique structures out of simple pieces.</p>
<p>I have a cousin, who was really into electronics on that time (Now he is doing medicine!). He had a friend who worked in an electronics shop and he used to bring me there, where we could buy and solder DIY electronics kits together, for the sake of fun. Years later, seeing my cousin building robots by typing some characters on the screen and &quot;programming&quot; it into something he called a &quot;microcontroller&quot;, triggered the same parts in my brain, as playing with lego pieces. I didn't know the English alphabet those days, so I was just seeing different symbols coming on the screen after every keystrokes. The fact that certain ordering of some symbols could cause some kind of unique behavior was blowing my mind. I would copy/paste the codes on my cousin's book on his computer for free, just to see that a behavior emerges when I put some kind of &quot;cheat-code&quot; on his computer. I began to appreciate the power of characters. Characters were my new lego pieces, but there was an important difference, it was impossible to run out of characters. I could literally use billions of them to build different behaviors.</p>
<p>After around 20 years, I still get super excited when I build something I find magnificent by putting the right symbols in the right order. I was curious enough to study and deeply understand many applications of computers that have made significant impact in our everyday life but nobody gives them the attention they deserve these days, so I decided to gather all these information in one place and write this book.</p>
<p>When I started writing this book, I was expecting it to be a merely technical book with a lot of codes included, targetting only programmers as its audience, but I ended up writing a lot of history, philosophy and even human anatomy! So the book could be a good read for non-programmers too!</p>
<p>The Super Programmer is all about ideas, and how they have evolved through time, leading to the impressive technology we have today. I wanted this book to have least dependency to technologies, so that the codes do not get obsolete over time. I first thought of writing the codes in some pseudo-coding language, but I personally believe that pseudo-codes are not coherent enough, so I decided to choose and stick with a popular language like Python, which as of today, is a programming language that is known by many other engineers and scientists.</p>
<p>Throughout this book, I’m going to show you the inspirations that human beings got from the nature, in order to build technology. Humans themselves have always been a great  source of inspiration for building tech. You are going to read the phrase “The Creator” in this book a lot of times. The Creator can have different meanings for different people. Religious people may interpret it as God, and people with materialistic views may interpret it as the nature and the process of evolution. Either way, there is no doubt that there has been immense amount of intelligence behind the mind who/which created life. Engineering ideas that The Creator used to build life has been a great source of inspiration for the technology we have today. In many parts of the book, we are going to put our feet into The Creator's shoe and try to understand what has been going in its/his mind when engineering us.</p>
<h2 id="who-is-this-book-for"><a class="header" href="#who-is-this-book-for">Who is this book for?</a></h2>
<p>This book is for curious people who are eager to learn some of the most fundamental topics of computer and software engineering. The topics presented in this books, although very interesting in opinion, are some of the most underrated and least discussed fields of computer programming. This book is about the old technology, the technology we are using everyday, but we refuse to learn and extend as an average engineer. The literature around each of those topics is so large that, only specialists will ever be motivated to learn them.</p>
<p>The Super Programmer is for the programmers who don't want to limit their knowledge and skills on a very narrow area of software engineering. The Super Programmer is for programmers who can't sleep at night when they don't exactly understand how something in their computer works.</p>
<p>There is a famous quote, attributed to Albert Einstein, which says: 'You do not really understand something unless you can explain it to your grandmother.'. Not only I emphasize on this quote, I would like to extend this quote and claim that, you don't understand something unless you can explain it to your computer. Computers are dumb. You have to explain them every little detail, and you can't skip anything. If you are able to describe a something to a computer in a way that it can correctly simulate it, then you surely understand that thing!</p>
<p>Computers give you the ability to test and experiment stuff without actually owning the physical version of them. You can literally simulate an atomic bomb in your computer and throw it in your imaginary world to see what happens. You can simulate a rocket that travels to Mars, as a tiny step, towards your dream of opening a space company. You can describe a 3D environment, and try to understand how it feels to be there, by putting your imaginary eyes in there and calculating what it will perceive, as a computer image. Computers let you to experiment anything you can ever imagine without spending anything other than some of your time and talent.</p>
<p>The Super Programmer is going to show you &quot;what can be done&quot;, and not &quot;how can be done&quot;. You are not going to learn data-structure and algorithms here, but you are going to learn how you can embrace your creativity by using simple tools you already know. Thus in many parts of this book, we are going to apply the simplest and least-efficient solutions possible, because it's a better way to learn new things.</p>
<p>Some might argue that not all software engineers will ever need to learn any of the topics taught in this book. That's partially true. As an average programmer, you are not going to use any of these knowledge in your everyday work. Even if you do, you are probably not going to get creative and make anything substantially new out of them. Since the book is about the old technology, most of the topics discussed in this book are already studied and developed as much as they could be.</p>
<p>So why are we doing this? There are several reasons:</p>
<ul>
<li>You can use the problem-solving strategies and patterns you learn in this book in your everyday job too!</li>
<li>The book allows you walk through the entire world-map of technology, and when you do this, nothing will be able scare you. </li>
<li>It's fun!</li>
</ul>
<h2 id="how-to-make-the-most-of-this-book"><a class="header" href="#how-to-make-the-most-of-this-book">How to make the most of this book?</a></h2>
<p>The book is divided into 5 chapters. We will start by explaining the beauty of cause-and-effect chains, and how we can build useful and interesting structures by connecting simple lego pieces together. We will go through the history of transistors, how they work, and how we can simulate them using plain Python code. We will implement different logic gates by connecting transistors together, and will proceed to building more complicated circuits like adders, counters and finally, programmable computers. After building our super simple computer, we'll try to put a soul in it. We will introduce the Brainfuck programming language and how it can be compiled for our computer, and will try to design and implement impressibely complicated programs using this simple language.</p>
<p>In chapter 2 and 3, we'll discuss two of the most important human senses, the sense of hearing and vision. We will start with some history, explaining how how humans invented ways to record what they see or hear, as photos or tapes, and experience them later. Then we will see how the digital revolution changed the way we record and store media forever. We'll get deep on very simple computer file formats used for storing images and audio, and will try to generate them ourselves. We will learn how to please our ears and eyes by generating a bunch of bytes.</p>
<p>Chapter 4 is all about the cool parts of artificial intelligence. We will discuss how biological neurons are similar to tunable electronic gates, and how we can use calculus and differentiations to tune these gates. We will try to build a library for training neural networks by differentiating computation graphs. We will learn and implement some of the most import operations used in neural-network models that can understand language, and will try to implement a language model ourselves.</p>
<p>Chapter 5 is about how people can use math for bringing trust into their wild digital world. We will start by learning the history of cryptography, and how people can encrypt and sign digital documents with their digital identities. We will discuss the electronic-cash revolution and see how math can help us to save ourselves from the evil and escape some of the limitations governments put on us. We will discuss ways we can convincingly prove people that we know something, without revealing it, and see how we can use these methods for building truly private cryptocurrencies.</p>
<p>The last chapter is all about ways comptuers and software can get a physical body and have physical interactions with the world sorrounding us. We will discuss multiple topics in Physics, including classical mechanics and how we can use it in order to simulate our world in our computers, or build machines that can send humans on Mars by analyzing and exploiting those laws. We will also get deeper in Electronics, the giant beast that many computer-engineers (Even the good ones) are unable to fully understand, although it is the fundamental building block of computers. Like all other chapters, our approach is to build physics engines and circuit simulators in order to fully understand the concept.</p>
<p>Without a doubt, people love things they have built on their own more than anything else. If you are planning to implement the codes in this book on your own, I suggest you to do it in a programming language other than Python. Writing the codes in Python might make you feel you are not doing anything new, and you may really end up copying and pasting what you read in the book. On the other hand, by rewriting all the logic in another language, you will force yourself to translate what you are reading, leading to a much deeper understanding of what is happening. It will also give you the feeling of creating something new, increasing your dopamine levels and motivation!</p>
<h2 id="what-do-i-need-to-know"><a class="header" href="#what-do-i-need-to-know">What do I need to know?</a></h2>
<p>As previously noted, although the book is about ideas and not the implementations, and I didn't want to make the content in this book dependant on a specific programming language, I still chose to write the codes in a real programming language instead of using pseudo-codes. Pseudo-codes assume that the reader is a human and does not have the coherency of a real programming language, which is what we care in this book.</p>
<p>I found Python programming language a good choice, since it's the first (Or second?) most popular language among all the developers in the world. I thought Python is the English language of the programmer community. Python isn't the right choice for implementing many of the topics we are discussing in this book (Since efficiency is very important in most of them), but it's one of the easiest languages you can use for prototyping things and learning the concepts.</p>
<p>Therefore you will need to know the basics of Python programming. Some knowledge of *NIX operating systems can become handy in some parts of the book.</p>
<h2 id="how-did-i-write-this-book"><a class="header" href="#how-did-i-write-this-book">How did I write this book?</a></h2>
<p>As someone who had never written a book before, I found the process very unclear. I wasn't sure what text-editing software/format I should use for easier conversion to other formats. I had to add a lot of code-snippets and math equations in my book, so clearly Microsoft Word wasn't the most convenient option (At least I wasn't sure how can I do it efficiently with a word-processor like Microsoft Office). Besides that, I am personally not a fan of LaTeX. I find the syntax hard and I wasn't really willing to learn LaTeX and I wanted to put my focus on writing the actual text instead. My choice was Markdown language. It is very easy to use and there are plenty of software out there which I can use for converting a <code>.md</code> file to <code>.html</code>, <code>.pdf</code>, <code>.tex</code> and etc. Also, in case I needed to perform some costum, automated transformations on my text, Markdown is one of the easiest languages to parse and generate!</p>
<p>I wrote different chapters in separate <code>.md</code> files, and then I wrote a <code>Makefile</code> to concatenate all of them in a single <code>.pdf</code> file. I then used a Linux program named <code>pandoc</code> for doing so.</p>
<p>Here is how my <code>Makefile</code> script looked like:</p>
<pre><code class="language-Makefile">pdf:
	pandoc --toc --output=out.pdf *.md # Convert MD files to a PDF file
	pdfunite cover.pdf out.pdf tsp.pdf # Add the book cover
	pdftotext tsp.pdf - | wc -w # Show me the word-cound
</code></pre>
<p>The <code>--toc</code> flag generated the Table of Contents section for me automatically (Based on Markdown headers: <code>#</code>, <code>##</code>, ...), and I also had another <code>.pdf</code> file containing the cover of my book, which I concatenated with the pandoc's output. I was tracking my process by word-count.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="build"><a class="header" href="#build">Build!</a></h1>
<h2 id="which-came-first-the-chicken-or-the-egg"><a class="header" href="#which-came-first-the-chicken-or-the-egg">Which came first? The chicken or the egg?</a></h2>
<p>Imagine, for a second, that a catastrophic event occurs, causing us to lose all the technology we once had. Nothing but ashes will remain, and our situation will be similar to that of humans millions of years ago, with one difference: We still can read, and fortunately, there are plenty of books available explaining how our modern technology worked. Now here is an interesting question: How much time will it take to reach the point of advancement we are in right now?</p>
<p>My prediction is that we will get back on track only after a few decades, and the only reason this could take longer than expected is that we will need tools for building other tools. Obviously, we can't start building a modern CPU even though we have the specification and the detailed design of that CPU. We will first need to rebuild tools that we need for building complex electronic circuits. If we are completely out of technology (as we assumed), we will need to learn again how we can find and extract the materials we want from the earth and use them to build the simple tools we'll need, which will then be used for building more complicated tools. Here is a very important fact that makes all the technological progress we have had viable: <em><strong>technology can help accelerate its own creation</strong></em>!</p>
<p>Just like the chicken and egg paradox, I was always wondering how people built the very first compilers and assemblers for the first time. What language did they use for describing the very first assembly languages? Did they have to write the early assembler programs directly in 0s and 1s? After a bit of research, I figured that the answer is yes. In fact, as an example, the process of building a C compiler for the first time is as follows:</p>
<ol>
<li>You write a C compiler directly in machine-assembly (Or some other language),</li>
<li>You'll rewrite the same C compiler in C.</li>
<li>You'll compile the new source-code using the compiler written in assembly.</li>
<li>Now you can completely ignore the assembly implementation, and assume that, your C compiler was written in C in the first place!</li>
</ol>
<p>See this beautiful loop here? Technology maintains and reproduces itself, which kind of means, <em><strong>technology is a form of life!</strong></em> The simpler computer language (in this example, machine-assembly) helped the C-compiler to emerge, but after the compiler started to live, it could stand on its own feet. We won't need the machine-assembly implementation of it anymore, since there is nothing preventing us from describing a C-compiler in the C programming language!</p>
<p>Now let's get back to our original question. Which one was first, the chicken or the egg? If you look through the history of evolution, you will see that the creatures millions of years ago were not reproducing by dropping eggs. Basic living cells, for example, never had to reproduce like that; they would only cut themselves into two pieces. As living creatures get more complicated, phenomena like dropping eggs will &quot;slowly&quot; start to emerge. The very first chicken-like animal, which started to lay eggs, didn't necessarily come out of an egg. It could just be a mutation that brought about the egging behavior for a new generation, just like how a C compiler started to live, without depending on an assembly implementation of it!</p>
<h2 id="when-the-dominos-fall"><a class="header" href="#when-the-dominos-fall">When the dominos fall</a></h2>
<p>If you ask someone who is really into computers about how computers work at very deep levels, he will most probably start by telling you about electronic switches, transistors, and logic gates. Well, I'm also going to do the same, but in a slightly different way! Even though transistors are the basic building blocks of almost all modern computers, the real magic that makes computers do their thing is something I'd like to refer to as &quot;Cause &amp; Effect&quot; chains.</p>
<p>I would like you to start by listing a few examples of &quot;Cause &amp; Effect&quot; scenarios that happen in everyday life. Here is my list (please think and add yours too):</p>
<ul>
<li>You press a key on your computer -&gt; A character appears on the screen -&gt; <strong>END</strong></li>
<li>You push the first domino -&gt; The next domino falls -&gt; The next domino falls -&gt; ...</li>
<li>You ask someone to open the window -&gt; He opens the window -&gt; <strong>END</strong></li>
<li>You tell a rumor to your friend -&gt; He tells the rumor to his friend -&gt; ...</li>
<li>You toggle the switch -&gt; The light bulb turns on -&gt; <strong>END</strong></li>
<li>A neuron fires in your brain -&gt; Another neuron gets excited as a result and fires -&gt; ...</li>
</ul>
<p>Now, let's think about why some of these cause-and-effect chains keep going on and on, while others stop after just a few steps. Why do some things set off a series of events, while others don't?</p>
<p>There's a crucial pattern here: The long-lasting (i.e., interesting) effects emerge from cause-and-effect chains where <em><strong>the effects have the same type as the causes</strong></em>, which essentially means these chains are interesting when they can form cycles. For instance, when a &quot;mechanical&quot; cause has another &quot;mechanical&quot; effect (like dominos), or when an &quot;electrical&quot; cause leads to another electrical effect (like electronic circuits).</p>
<p>The most complex thing you can create with components that transform a single cause into a single effect is no different than a chain of falling domino pieces (another example is when rumors circulate in a company). It's still impressive and has its interesting aspects, but we don't want to stop there. We want to build things that can transform multiple causes into a single effect (all with the same types), and that's when Cause &amp; Effect chains truly shine! The simplest example of such a component is a switch. A switch manages the flow of an input to an output through a third controlling input. An example of a non-electrical switch is a faucet. A faucet allows you to control the flow of water in a pipe (considered as a single-cause/single-effect component) through a third input.</p>
<p>We won't delve deep into the inner workings of transistors just yet, but let's assume that transistors are components capable of converting electrical causes into electrical effects. This ability allows us to connect them together and create interesting things. In essence, transistors can be accurately described as switches, quite similar to push-buttons but with a key difference. A push-button is a component that accepts an electrical and a mechanical input, producing an electrical output.</p>
<p>[IMG push-button]</p>
<p>However, a push-button is definitely not a transistor because not all of its input causes are electrical. You still need a finger to push the button, and the output of a push button cannot be used as the mechanical input of another button. Therefore, you can't build domino-like structures with push-buttons! The push-button becomes more similar to a transistor when its mechanical input is substituted with an electrical input. In this case, all of its inputs and outputs will have the same types, allowing you to connect them together. Let's fix this!</p>
<p>Before starting to think of a electrical switch that can be controlled through an electrical cause, be aware that sometimes a cause/effect conversion is actually the result of many other cause/effect conversions chained together, occurring under the hood. For example, consider a light bulb connected to a push-button. In this system, the process begins with a person pushing the switch, initiating a mechanical action. Right after that, the mechanical cause triggers an electrical effect, and the electrical cause produces a visual effect, which eventually results in neural effects in your brain. The entire process converts a mechanical cause into a neural effect that can be sensed by a human brain. (Notice how new converters can be built by connecting/chaining other primitive converters.)</p>
<p>Now, here is a very stupid example of a push-button that has an electrical controller: Imagine there is a human that has a wire in his hand. This person turns the pushes the push-button when he feels electricty in his hand (Of course if the electricity is not strong enough to kill him). It might be the strangest thing in the world, but if you have enough of these transistors connected with each other, you can theoritically build computers out of it that can connect to the internet and render webpages!</p>
<p>Now that you get why something like a transistor might be handy, let's talk about transistors themselves. Formally speaking, a transistor is a resistor that its resistance can transform according to an electrical input. A transistor is something that can convert two electrical causes into single electrical effect. Transistors are very interesting candidates for building computers, because:</p>
<ol>
<li>They can convert causes to effects of the same type, directly! (Electricity)</li>
<li>They can be made in very small sizes (Nanometers?).</li>
<li>They are very fast!</li>
</ol>
<p>Because of these properties, we can build complicated and dense cause/effect chains and get interesting behaviors out of it by consuming very small amount of space (E.g your smartphone).</p>
<h2 id="taming-the-electrons"><a class="header" href="#taming-the-electrons">Taming the electrons</a></h2>
<p>Practically, if you want to build a real logic circuit and synthesize it on real silicone, you would describe your circuit in a hardware-description-language. Two most famous as of today are VLSI/Verilog. Since this book is about ideas we will try to emulate the same concept in Python programming language.</p>
<p>The most important primitives in our circuit emulations are wires. Wires, as their name suggest, are basically conductors, usually made of metal that allow our components to connect to each other, and talk to each other through the flow of electricity. The most important property of a wire is its voltage.</p>
<p>It is very important to understand the meaning of voltage. Formally, voltage is defined as the potential energy difference between two points of a circuit. Let's forget about electricity for a while and try to understand the concept by talking about heights. You know that it takes energy to pick up something heavy from the ground. The more you lift a heavy object, the more energy it is consumed (Because you get tired right? You need to get the energy back by eating food!). The law of conservation of energy says that, energy can neither be created nor destroyed; rather, it can only be transformed or transferred from one form to another. So, where does the consumed energy go when you lift something up?</p>
<p>Release what you have in your hand and let it fall. The heavy object will hit the ground, make a bang song, and it might even break the ground (Or itself). The more height the object has from the ground, the more damage it will make. It is also obvious that, energy is needed in order to make noises and damages. Where did that energy come from?</p>
<p>Now you know the answer! When you lifted the heavy object, you actually gave energy to it, and when you let it fall, the energy you gave got released! Physicist call this energy as potential energy. A lifted object has the potential to do work (Work is done by consuming energy), that's probably why we refer it as potential energy!</p>
<p>If you remember high-school physics, you know that the potential energy of an object can be calculated with the formula: \(u=mgh\) where \(m\) is the mass of the object, \(h\) is its height from the ground, and \(g\) is earth's gravity constant (Which is around \(9.807\)). Given this formula, when the object lies on the ground, \(h\) is 0 thus the potential energy is also 0. A very important question, does that mean, an object that lies on the ground does not have any potential energy? Well, it has! Take a shovel, dig the ground under the object, and the object will fall into the hole. The point is, the equation is giving you the potential difference, not the actual potential energy of that object! A more correct version of that equation would be: \(\varDelta{u}=mg\varDelta{h}\), which says, the potential energy difference between two points A and B is \(mg\) times the difference of their heights! It's relative!</p>
<p>The reason it takes energy to lift an object roots back to the fact that giant masses attract each other, a.k.a the universal law of gravitation (\(F=G\frac{m_1m_2}{r^2}\)). Since a very similar law also exists in the microscopic world (Electrons attract protons and defeat electrons, \(F=k_e\frac{q_1q_2}{r^2}\)), we have a similar concept of &quot;potential energy&quot; in the electromagnetic world too. It takes energy to pull two electrical charges of different types (Positive/Negative) from each other, and when you do so, and then release them, they will start moving to each other and release their energy.</p>
<p>That's basically the way batteries work, they try to make potential differences by moving electrons to higher &quot;heights&quot;, and when you let them fall (By connecting a wire from the negative pole of the battery to the positive pole), the electrons will start to fall through the wire. So when we say &quot;Voltage&quot;, we mean a difference of height/potential-energy. We don't exactly know what is the absolute height/potential-energy of points A and B, but we certainly know the height/potential difference!</p>
<h2 id="wires"><a class="header" href="#wires">Wires</a></h2>
<p>Enough explanation, lets jump into the code. Now that we know the concept of voltage, we can emulate an electrical wire. A wire in our emulation can have 4 different states:</p>
<ul>
<li>Free (The wire is not connected to anything)</li>
<li>Zero (The wire is connected to the ground thus has 0 voltage)</li>
<li>One (The wire has a voltage of 5.0V)</li>
<li>Unknown (We can not determine if the wire is 0 or 1)</li>
</ul>
<p>By default, a wire that is not connected to anywhere, is in the &quot;Free&quot; state. When you connect it to a gate/wire that has a state of One, the wire's state will also become One. A wire can connect to multiple gates/wires at the same time. The wire will get into the Unknown state when you connect it to two other wires/gates with conflicting values. E.g. if the wire is connected to both Zero and One sources at the same time, it's state will be Unknown.</p>
<p>We can calculate the truth table of wire logic to better understand the concept:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A + B</th></tr></thead><tbody>
<tr><td>Z</td><td>Z</td><td>Z</td></tr>
<tr><td>0</td><td>Z</td><td>0</td></tr>
<tr><td>1</td><td>Z</td><td>1</td></tr>
<tr><td>X</td><td>Z</td><td>X</td></tr>
<tr><td>Z</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>X</td></tr>
<tr><td>X</td><td>0</td><td>X</td></tr>
<tr><td>Z</td><td>1</td><td>1</td></tr>
<tr><td>0</td><td>1</td><td>X</td></tr>
<tr><td>1</td><td>1</td><td>1</td></tr>
<tr><td>X</td><td>1</td><td>X</td></tr>
<tr><td>Z</td><td>X</td><td>X</td></tr>
<tr><td>0</td><td>X</td><td>X</td></tr>
<tr><td>1</td><td>X</td><td>X</td></tr>
<tr><td>X</td><td>X</td><td>X</td></tr>
</tbody></table>
</div>
<p>A wildcard version of this table would look like this:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A + B</th></tr></thead><tbody>
<tr><td>Z</td><td><strong>x</strong></td><td><strong>x</strong></td></tr>
<tr><td><strong>x</strong></td><td>Z</td><td><strong>x</strong></td></tr>
<tr><td>X</td><td><strong>x</strong></td><td>X</td></tr>
<tr><td><strong>x</strong></td><td>X</td><td>X</td></tr>
<tr><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>1</td></tr>
<tr><td>0</td><td>1</td><td>X</td></tr>
<tr><td>1</td><td>0</td><td>X</td></tr>
</tbody></table>
</div>
<p><img src="assets/wires.png" alt="4 different wire states" /></p>
<p>Based on our definition of a wire, we can provide a Python implementation:</p>
<pre><code class="language-python=">FREE = &quot;Z&quot;
UNK = &quot;X&quot;
ZERO = &quot;0&quot;
ONE = &quot;1&quot;

BATTERY = 'BATTERY'


class Wire:
    def __init__(self):
        self.values = {}

    def one():
        w = Wire()
        w.put(BATTERY, ONE)
        return w

    def zero():
        w = Wire()
        w.put(BATTERY, ZERO)
        return w

    def get(self):
        curr = FREE
        for b in self.values.values():
            if b == UNK:
                return UNK
            elif b != FREE:
                if curr == FREE:
                    curr = b
                elif b != curr:
                    return UNK
        return curr

    def put(self, gate, value):
        self.values[gate] = value
</code></pre>
<p>Here on lines 13 and 18 we are also defining two static methods <code>zero()</code> and <code>one()</code> that return wires that are connected to the positive or negative poles of a battery.</p>
<h2 id="magical-switch"><a class="header" href="#magical-switch">Magical switch</a></h2>
<p>A transistor is an electronic component which typically accepts 2 wires as inputs and has a single output. These wires are called, base, emitter and collector. When the voltage of the base wire is above/below a threshold, the value of the emitter wire is copied into the collector wire. Otherwise, the collector wire will be on the Free state.</p>
<p>So far we have been working with logic gates that could only accept 0s and 1s as their inputs, but things are not ideal in the real-world, and wires connected to electronic logic gates could have unexpected voltages. Since a wire can have 4 different states in our emulation, our logic gates should also handle all the 4 states.</p>
<p>Let's redefine our primitive And/Or/Not gates given our definition of a wire:</p>
<p><em><strong>NOT gate:</strong></em> turns one to zero and zero to one. When the input is Free or Unknown, the output is Unknown:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>NOT A</th></tr></thead><tbody>
<tr><td>0</td><td>1</td></tr>
<tr><td>1</td><td>0</td></tr>
<tr><td>Z</td><td>X</td></tr>
<tr><td>X</td><td>X</td></tr>
</tbody></table>
</div>
<p><em><strong>AND gate:</strong></em> is zero when at least one of the inputs is zero, and gets One when all of the inputs are one. Otherwise the output is unknown.</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A AND B</th></tr></thead><tbody>
<tr><td>0</td><td>*</td><td>0</td></tr>
<tr><td>*</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>1</td></tr>
<tr><td></td><td></td><td>X</td></tr>
</tbody></table>
</div>
<p><em><strong>OR gate:</strong></em> is one when at least one of the inputs is one, and gets zero only when all of the inputs are zero. Otherwise the output is unknown.</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A OR B</th></tr></thead><tbody>
<tr><td>1</td><td>*</td><td>1</td></tr>
<tr><td>*</td><td>1</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>0</td></tr>
<tr><td></td><td></td><td>X</td></tr>
</tbody></table>
</div>
<p>We can define gates as classes with an <code>update()</code> function. The <code>update()</code> function is called whenever we want to calculate the output of a gate based on its inputs. </p>
<pre><code class="language-python=">class Not:
    def __init__(self, wire_in, wire_out):
        self.wire_in = wire_in
        self.wire_out = wire_out

    def update(self):
        v = self.wire_in.get()
        if v == FREE:
            self.wire_out.put(self, UNK)
        elif v == UNK:
            self.wire_out.put(self, UNK)
        elif v == ZERO:
            self.wire_out.put(self, ONE)
        elif v == ONE:
            self.wire_out.put(self, ZERO)


if __name__ == '__main__':
    inp = Wire.zero()
    out = Wire()
    gate = Not(inp, out)
    gate.update()
    print(out.get())
</code></pre>
<p>A transistor is a magical electrical component that allows to control whether two wires are connected or not, through an increase/decrease of potential energy in a controller wire (There are 3 wires involved according to the definition!).</p>
<p>https://upload.wikimedia.org/wikipedia/commons/3/37/Transistor.symbol.npn.svg</p>
<p>The most primitive element in a digital system is a transistor. A transistor is an electrical domino piece. It converts electrical causes to electrical effects. In very simple terms, a transistor is an electrically controlled switch. There are 3 wires involved which are known as <em>base</em>, <em>emitter</em>, and <em>collector</em>. The base wire is the controller of the switch. An electrical potential between the base and emitter wires will cause the collector wire to get connected with the emitter wire. In other word, the base wire will decide if emitter and collector are connected or not. The emitter will emit electrons and the collector will collect them.</p>
<p>There are two types of transistor. The Type-N transistor will turn on when the base wire is driven with a a high potential. And the Type-P transistors will turn on in case of a low voltage. We can sketch truth-table for them:</p>
<p>Type-N Transistors:</p>
<div class="table-wrapper"><table><thead><tr><th>B</th><th>E</th><th>C</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>Z</td></tr>
<tr><td>0</td><td>1</td><td>Z</td></tr>
<tr><td>1</td><td>0</td><td>0 (Strong)</td></tr>
<tr><td>1</td><td>1</td><td>1 (Weak)</td></tr>
</tbody></table>
</div>
<p>Type-P Transistors:</p>
<div class="table-wrapper"><table><thead><tr><th>B</th><th>E</th><th>C</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0 (Weak)</td></tr>
<tr><td>0</td><td>1</td><td>1 (Strong)</td></tr>
<tr><td>1</td><td>0</td><td>Z</td></tr>
<tr><td>1</td><td>1</td><td>Z</td></tr>
</tbody></table>
</div>
<p>It's very important to know that when the transistor is off, the collector is not driven with anything. It will be like a floating wire, which based on our definitions, will be in the Z state.</p>
<p>Assuming we define a voltage of 5.0V as 1 and a voltage of 0.0V as 0, a wire is driven with a strong 0, when its voltage is very close to 0 (E.g 0.2V), and it's a strong 1 when its voltage is close to 5 (E.g 4.8V). The truth is, the transistors we build in the real world aren't ideal, so they won't always give us strong signals. A signal is said weak when it's far from 0.0V or 5.0V, as an example, a voltage of 4.0V could be considered as a weak 1 and a voltage of 1.0V is considered as a weak 0. Type-P transistors that are built in the real world are very good in giving out strong 0 signals, on the other hand, Type-N transistors give out very good 1 signals. Using the help of those two types of transistors at the same time, we can build logic gates that give out strong output in every case.</p>
<p>Here is an example of a NOT gate, built with a type P and a type N transistor:</p>
<p>[TODO]</p>
<p>Now that we've got familiar with transistors, it's the time to examine the most primitive logic-gates </p>
<h2 id="mother-of-the-gates"><a class="header" href="#mother-of-the-gates">Mother of the gates</a></h2>
<p>A NAND gate is a logic-gate that outputs 0 if and only if both of its inputs are 1. It's basically an AND gate which its output is inverted. It can be proven that you can build all of the primitive logic gates (AND, OR, NOT), using different combinations of this single gate. It's the mother gate of all logic circuits. Although, it would be very inefficient to build everything with NANDS in practice, for the sake of simplicity, we'll stick to NAND and will try to build other gates by connecting NAND gates to each other.</p>
<p><img src="assets/nand.png" alt="NAND gate with transistors" /></p>
<p>It turns out that we can build NAND gates with strong and accurate output signals using 4 transistors (x2 Type-N and x2 Type-P). Let's prototype a NAND using our simulated N/P transistors!</p>
<p>[TODO]</p>
<p>Go ahead and implement other primitive gates using the NAND gate we just defined. After that, we can start making useful stuff out of these gates. The simplest digital circuit which is also useful is something that can add two numbers. Obviously we will be working with bunary numbers. Let's start with a circuit that can add two, one-bit numbers. The result of such an addition is a two bit number.</p>
<p>In order to design such a circuit, we first need to know what the desired outputs are, for each possible input. Since the output is a 2-bit number, we can decompose such a circuit into two subcircuits, each calculating its corresponding digit.</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>First digit</th><th>Second digit</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>0</td><td>1</td></tr>
</tbody></table>
</div>
<p>The second digit's relation with A and B is very familiar, it's basically an AND gate! Try to find out how the first digit can be calculated by combining primitive gates. (Hint: It outputs 1 only when A is 0 AND B is 1, OR A is 1 AND B is 0)</p>
<p>What we have just built is known as a half-adder. With an half-adder, you can add 1-bit numbers together, but what if we want to add multi-bit numbers? Let's see how primary school's addition algorithm works on binary numbers:</p>
<pre><code>   11111
   
  1011011
+  110101
-----------
       00

</code></pre>
<p>By looking to the algorithm, we can see that for each digit, an addition of 3 bits is being done (Not just two). So, in order to design a multi-bit adder we'll need a circuit that adds 3 one-bit numbers together. Such a circuit is known as a full adder and the third number is often referred as the carry value. Truth table of a three bit adder:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>C</th><th>D0</th><th>D1</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>0</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>0</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>0</td><td>1</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>1</td><td>1</td><td>1</td><td>1</td></tr>
</tbody></table>
</div>
<p>Once we have a triple adder ready, we can proceed and create multi-bit adders. Let's try building a 8-bit adder. We will need to put 8 full-adders in a row, connecting the second digit of the result of each adder as the third input value of the next adder, mimicking the addition algorithm we discussed earlier.</p>
<p>Before designing more complicated gates, make sure you are able to create a working simulation of a 8-bit adder using the primitive elements we simulated in the previous sections.</p>
<h2 id="when-addition-is-subtraction"><a class="header" href="#when-addition-is-subtraction">When addition is subtraction</a></h2>
<p>So far we have been able to implement the add operation by combining N and P transistors. Our add operation is limited to 8-bits, which means, the input and output values are all in the range \([0,255]\). If you try to add two numbers, which their sum is more than 255, you will still get a number in range \([0,255]\). This happens since a number bigger than 255 can not be represented by 8-bits and an <em><strong>overflow</strong></em> will happen. If you look carefully, you will notice that what we have designed isn't doing a regular add operation we are used to in elementary school mathematics, but it's and addition that is done in a finite-field. This means, the addition results are mod-ed by 256:</p>
<p>\(a \oplus b = (a + b) \mod 256\)</p>
<p>It is good to know that finite-fields have interesting properties:</p>
<ol>
<li>\((a \oplus b) \oplus c = a \oplus (b \oplus c)\)</li>
<li>For every non-zero number \(x \in \mathbb{F}\), there is a number \(y\), where \(x \oplus y = 0\). \(y\) is know as the negative of \(x\).</li>
</ol>
<p>In a finite-field, the negative of a number can be calculated by subtracting that number from the field-size (Here the size of our field is \(2^8=256\)). E.g negative of \(10\) is \(256-10=246\), so \(10 \oplus 246 = 0\).</p>
<p>Surprisingly, the number \(246\), acts really like a \(-10\). Try adding \(246\) to \(15\). You will get \(246 \oplus 15 = 5\) which is equal with \(15 + (-10)\)! This has a important meaning, we can perform subtraction without designing a new circuit! We'll just need to negate the number. Calculating the negative of a number is like taking the XOR of that number (Which is equal with \(255 - a\)), and adding \(1\) to it (Which makes it \(256 - a\) which is our definition of negation). This is known as the two's-complement form of a number.</p>
<p>It's very incredible to see that we can build electronic machines that can add and subtract numbers by connecting a bunch of transistors to each other! The good news is, we can go further and design circuits that can perform multiplications and divisions, using the same thought process we had while designing add circuits. The details of multiplication and division circuits are beyond the scope of this book but you are strongly advised to study them yourself!</p>
<h2 id="try-to-remember"><a class="header" href="#try-to-remember">Try to remember</a></h2>
<p>What we care about right now is to design a circuit which is able to run arbitrary algorithms for us! An algorithm is nothing but a list of operations that need to be executed. So far we have been experimenting with state-less circuits, circuits that didn't need to memorize or remember anything in order to do their job. Obviously, you can't get much creative with circuits that do now store anything from the past, thus, we are going to talk about ways we can store data on a digital circuit circuit and keep it through time!</p>
<p>When you were a child, you have most probably tried to put a light-switch in a middle state. If the switch had been in good condition and quality, you know how frustrating it can get to do it! The concept of <em><strong>memory</strong></em> emerges when a system with multiple possible states can only stabilize in a single state at a time, and once it gets stable, the state can only be changed by an external force. A light-switch can be used as a single-bit memory cell. </p>
<p>Imagine a piece of paper. It's stable. When you put it on fire, it slowly changes its state until it becomes completely burnt and stabilizes there. It's not easy to keep the paper a middle state. You can use a paper as a single bit memory cell. It's not the best memory cell and the most obvious reason is that you can't turn it back to its unburnt state!</p>
<p>Fortunately, there are ways you can build circuits with multiple possible states, in which only one state can stabilize. The simplest example of such a circuit is when you create a cycle by connecting two NOT gates to each other. There are two wires involved, if the state of the first wire is 1, the other wire will be 0 and the circuit will get stable (And vice versa). Simulating such a circuit in our Python simulator is a bit tricky, since a loop in our connections will create and infinite loop in our simulation. There are two ways we can fix this problem in our simulator:</p>
<ol>
<li>Break the update loop, when the state of the wires do not change after a few iterations (Meaning that the system has entered a stable state).</li>
<li>Give up, and try to simulate a memory-cell component without doing low-level transistor simulations.</li>
</ol>
<hr />
<p>So far, we have been able to design a circuit that stays stable in a single state, and we can set its state by triggering it through an auxillary port we call &quot;enable&quot;. This circuit is known as a Latch, and since it's hard to simulate it using bare transistors (Since there will be infinite loops which are unhandled by our simulator, as discussed), we are going to hardcode its behavior using plain Python code. It will have a fairly simple logic. It will accept a data and an enable wire as its inputs, and will have a single output. The output pin will output the current state of the Latch, and when 'enable' is 0, it will ignore the 'data' pin and won't change its state. As soon as the enable pin gets 1, the value of data pin will be copied to the internal state of the latch. We can describe the behavior of a Latch like this:</p>
<div class="table-wrapper"><table><thead><tr><th>Enable</th><th>Data</th><th>Output</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>s</td></tr>
<tr><td>0</td><td>1</td><td>s</td></tr>
<tr><td>1</td><td>0</td><td>0 (s &lt;= 0)</td></tr>
<tr><td>1</td><td>1</td><td>1 (s &lt;= 1)</td></tr>
</tbody></table>
</div>
<p>A latch is an electronic component that can store a single bit of information. Later on this book, we will be building a computer with memory-cells of size 8-bit (A.k.a a byte). So it might make sense to put 8 of these latches together as a separate component in order to build our memory-cells, registers and RAMs. We'll just need to put the latches in a row and connect their enable pins together. The resulting component will have 9 input wires and 8 output wires.</p>
<h2 id="make-it-count"><a class="header" href="#make-it-count">Make it count!</a></h2>
<p>Considering that now we know how to build memory-cells and maintain a state in our circuits, we can know build circuits that can maintain an state/memory and behave according to it! Let's build something useful out of it!</p>
<p>A very simple yet useful circuit you can build, using adders and memory-cells, is a counter. A counter can be made by feeding in the incremented value of the output of a 8-bit memory cell, back as its input. The challenge is now to capture the memory cell input value by trigerring the cell to update its inner value by setting its enable pin to 1.</p>
<p>The enable input should be set to 1 for a very VERY short time, otherwise, the circuit will enter and unstable state. As soon as the input of the memory-cell is captures, the output will also change in a short time, and if the value of enable field is still 1, the circuit will keep incrementing and updating its internal state. The duration which the enable wire is 1 should be short enough, so that the incrementor component doesn't have enough time to update its output. In fact, we will need to connect a pulse generator to the enable pin in order to make our counter circuit work correctly, and the with of the pulse should be smaller than the duration by which the output of the incrementor circuit is updated.</p>
<p>One way we can have such pulses is to connect a regular clock generator to an edge-detector. The edge-detector is a an electronic circuit which can recognize sharp changes in a signal.</p>
<p>In the real world, since gates propagate their results with delays, strange things can happen. The gates may output unexpected and invalid results, known as hazards. Take this circuit for example:</p>
<p><img src="assets/edgedetector.png" alt="An AND gate where one of the inputs is routed through three NOTs" /></p>
<p>When the input is 0, the output of the NOT gate is 1. When the input gets 1, the input wire without a NOT gate will get 1 immediately, but the second input will get 0 with a delay, thus there will be a very small moment where both of the inputs are 1, causing the AND gate to output 1.</p>
<p>Looking carefully to the behavior of this structure, we will notice that it can convert a clock signal into a train of pulses with ultra tiny widths. Let's connect this component to the enable pin of a Latch, so that the latch is updated only when a rise happens in the clock signal. The resulting circuit is known as a FlipFlop. The only difference between a FlipFlop and a Latch is that FlipFlops are edge-triggered while Latches are level-triggered. FlipFlops should be used instead of Latches in order to design synchronous circuits.</p>
<p>Let's simulate all these components and try to implement a counter circuit with FlipFlops:</p>
<pre><code class="language-python">class EdgeDetector:
    pass
</code></pre>
<pre><code class="language-python">class FlipFlop:
    pass
</code></pre>
<pre><code class="language-python">class Counter:
    pass
</code></pre>
<h2 id="chaotic-access"><a class="header" href="#chaotic-access">Chaotic access</a></h2>
<p>Now imagine we have a big number of these 8-bit memory cells which are identified by different addresses. We would like to build an electronic component which enabled us to read and write a memory-cell (Out of many memory-cells), given its address. We will call it a RAM, since we can access arbitrary and random addresses without losing speed (It's hard to randomly move on a disk-storage). In case of a RAM with 256 memory-cells (Each 8-bit), we'll need 17 input wires and 8 output wires.</p>
<p>The inputs are as follows:</p>
<ol>
<li>8 wires, choosing the memory-cell we want to read/write</li>
<li>8 wires, containing the data to be written on the chosen cell when enable is 1</li>
<li>1 enable wire</li>
</ol>
<p>And the output will be the data inside the chosen address.</p>
<p>The memory-cells in our RAM will need to know when to allow write operation. For each 8-bit memory cell, enable is set 1 when the chosen address is equal with the cell's address AND the enable pin of the RAM is also 1: <code>(addr == cell_index) &amp; enable</code></p>
<p>We will also need to route the output of the chosen cell to the output of a RAM. We can use a multiplexer component here.</p>
<p><em><strong>Multiplexer</strong></em></p>
<p>A gate that gets \(2^n\) value bits and \(n\) address bits and will output the values existing at the requested position as its output. A multiplexer with static inputs can be considered as a ROM. (Read-Only Memory)</p>
<h2 id="computer"><a class="header" href="#computer">Computer</a></h2>
<p>Now you know how tranistors work and how you can use them to build logical gates. It's time to build a full-featured computer with those gates!</p>
<p>I would say, the most important parts of a modern computer are its RAM and CPU. I would like to start by explaining a Random-Access-Memory by designing one. It will be the simplest implementation of a RAM and it won't be similar to what it's used in production today, but the idea is still the same.</p>
<p>RAM is the abbreviation of Random-Access-Memory. Why do we call it random access? Because it's very efficient to get/set a value on a random address in a RAM. Remember how optical disks and hard-disks worked? The device had to keep track of the current position, and seek the requested position relative to its current positions. It is efficient only if the pattern of memory access is like going forward/backward 1 byte by 1 byte. But life is not that ideal and many programs will just request very different parts of the memory, which are very far from each other, in other words, it seems so unpredictable that we can call it random.</p>
<h2 id="exploiting-the-subatomic-world"><a class="header" href="#exploiting-the-subatomic-world">Exploiting the subatomic world</a></h2>
<p>So far, we have been working on cause-and-effect chains that were totally deterministic and predictable. We saw how we can exploit the flow of electricity and route it in a way so that it can do logical operations like AND, OR, NOT and etc.</p>
<p>There are some particles in our universe that do not have determinsitic behaviors but are probabilistic. You might first think that randomness is a poison for computers, but we humans are greedy, we want to take advantage of everything, and luckily, we have found ways to exploit non-determinism and solve problems with it that a normal computer just can't (Without spending more time than the age of the universe).</p>
<pre><code class="language-python=">class Qubit:
    def __init__(self, zeroness, oneness):
        self.zeroness = zeroness
        self.oneness = oneness

</code></pre>
<p><em><strong>Bell's Inequality</strong></em></p>
<h2 id="brainfuck"><a class="header" href="#brainfuck">Brainfuck</a></h2>
<p>Most people say it's crucial to learn C, if you want to be a good programmer! I say, knowing how to program in Brainfuck is what makes you a Super Programmer! Brainfuck, built in 1993 by Urban Müller, is an esoteric programming language, which means, it has been designed in a way so that very few people understand or like it! Learning how to program in Brainfuck is a great way to see how it's possible to build wonderful stuff by putting simple components together.</p>
<p>Brainfuck is extremely minimalistic, it only consists of 8 simple commands. It is also very simple to learn, but hard to build anything meaningful out of it! Brainfuck is Turing-Complete, which means, you can theoritically build web browsers, 3D games, and any kind of complicated software with it! Here is the specification of the language:</p>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Description</th></tr></thead><tbody>
<tr><td>&gt;</td><td>Increment the data pointer</td></tr>
<tr><td>&lt;</td><td>Decrement the data pointer</td></tr>
<tr><td>+</td><td>Increment the byte at the data pointer</td></tr>
<tr><td>-</td><td>Decrement the byte at the data pointer</td></tr>
<tr><td>.</td><td>Output the byte at the data pointer</td></tr>
<tr><td>,</td><td>Store an input at the data pointer</td></tr>
<tr><td>[</td><td>Does nothing, acts as a flag</td></tr>
<tr><td>]</td><td>If the byte at the data pointer is not 0, jump to the corresponding [</td></tr>
</tbody></table>
</div>
<p>Before trying to build anything with Brainfuck, let's write an interpreter for this language first! The original Brainfuck machine specification has 30000 memory-cells, each storing a 8-bit byte (Unsigned integer between 0 to 255). </p>
<p>The following code is an Brainfuck interpreter written in Python, which executes a &quot;Hello World!&quot; program written in Brainfuck.</p>
<pre><code class="language-python3=">code = '''
++++++++[&gt;++++[&gt;++&gt;+++&gt;+++&gt;+&lt;&lt;&lt;&lt;-]&gt;+&gt;+&gt;-&gt;&gt;+[&lt;]&lt;-]&gt;&gt;.&gt;
---.+++++++..+++.&gt;&gt;.&lt;-.&lt;.+++.------.--------.&gt;&gt;+.&gt;++.
'''

memory = [0] * 30000
ptr = 0
pc = 0

stack = []
while pc &lt; len(code):
    if code[pc] == &quot;&gt;&quot;:
        ptr = (ptr + 1) % 30000
    elif code[pc] == &quot;&lt;&quot;:
        ptr = (ptr - 1) % 30000
    elif code[pc] == &quot;+&quot;:
        memory[ptr] = (memory[ptr] + 1) % 256
    elif code[pc] == &quot;-&quot;:
        memory[ptr] = (memory[ptr] - 1) % 256
    elif code[pc] == &quot;[&quot;:
        stack.append(pc)
    elif code[pc] == &quot;]&quot;:
        top = stack.pop()
        if memory[ptr] != 0:
            pc = top
            continue
    elif code[pc] == &quot;.&quot;:
        print(chr(memory[ptr]), end=&quot;&quot;)

    pc += 1
</code></pre>
<p>If you want to reach maximum speeds while running a Brainfuck program, it is also worth noting that Brainfuck can be directly transpiled to C, you'll just need to initialize some variables and then do these substitutions:</p>
<pre><code class="language-clike">unsigned char mem[30000] = {0};
unsigned int pc = 0;
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Instruction</th><th>Equivalent C code</th></tr></thead><tbody>
<tr><td>&gt;</td><td><code>ptr++;</code></td></tr>
<tr><td>&lt;</td><td><code>ptr--;</code></td></tr>
<tr><td>+</td><td><code>mem[ptr]++;</code></td></tr>
<tr><td>-</td><td><code>mem[ptr]--;</code></td></tr>
<tr><td>.</td><td><code>putchar(mem[ptr));</code></td></tr>
<tr><td>,</td><td><code>mem[ptr] = getchar();</code></td></tr>
<tr><td>[</td><td><code>while(mem[ptr] != 0) {</code></td></tr>
<tr><td>]</td><td><code>}</code></td></tr>
</tbody></table>
</div>
<p>Here is a Brainfuck-to-C transpiler written in Python (<code>bf2c.py</code>):</p>
<pre><code class="language-python3=">print('#include &lt;stdio.h&gt;')
print('void main() {')
print('unsigned char mem[30000] = {0};')
print('unsigned int ptr = 0;')

mapping = {
    '&gt;': 'ptr++;',
    '&lt;': 'ptr--;',
    '+': 'mem[ptr]++;',
    '-': 'mem[ptr]--;',
    '[': 'while(mem[ptr]) {',
    ']': '}',
    '.': 'putchar(mem[ptr]);',
    ',': 'mem[ptr] = getchar();'
}

bf = input()

for ch in bf:
    if ch in mapping:
        print(mapping[ch])
    
print('}')
</code></pre>
<p>In order to use this tool for running your Brainfuck programs:</p>
<ol>
<li>Write your Brainfuck program in a file: <code>main.bf</code></li>
<li>Transpile it to C: <code>python3 bf2c.py &lt; main.bf &gt; main.c</code></li>
<li>Compile the C program: <code>gcc main.c</code></li>
<li>Run the program: <code>./a.out</code></li>
</ol>
<p>Let's try to build things with this language now!</p>
<p><strong>Hello World!</strong></p>
<p>Printing a string is the first thing people actually do when learning a new programming language. Surprisingly, printing stuff isn't that straightforward in an esoteric programming language like Brainfuck. Since a Brainfuck program's inputs and outputs are bytes, we'll need to work with an 8-bit character encoding (Like ASCII) in order to work with strings. </p>
<p>The instruction <code>.</code> is responsible for outputting bytes, and it outputs the byte the program is currently pointing at. So we somehow have to put our desired ASCII code in that memory location in order to print it. Naively, this would mean we have to put a lot of <code>+</code> instructions to make the current memory cell equal with our desired ASCII character. For example, we'll need to put 72 <code>+</code> instructions in order to print a <code>H</code> character! There are ways we can optimize the process of printing a string. Since the number 72 is already in the memory, we won't need to put 69 other <code>+</code> signs in another memory location in order to print the next letter <code>E</code>, we'll just need to subtract the old character by 3 (72-3=69), and print it again! This way we can write a Brainfuck program that can print &quot;HELLO WORLD&quot; in around 160 instructions:</p>
<pre><code>+++++++++++++++++++++++++++++++++++
+++++++++++++++++++++++++++++++++++
++.---.+++++++..+++.                ; Print 'HELLO'

&gt;++++++++++++++++++++++++++++++++.&lt; ; Print ' '

++++++++.--------.+++.------.------
--.                                 ; Print 'WORLD'
</code></pre>
<p>Since printing the space character (ASCII code 32) required a huge jump, we preferred generating it in a separate memory cell (By moving the cursor to the next cell, incrementing it 32 times, printing it and the moving the cursor back to its original place).</p>
<p>From now, instead of jumping to different locations of the memory through <code>&lt;&gt;</code> instruction, for the sake of readability, we will express our will to jump to different locations of memory, by giving names to the locations in memory and using those names in our code when we want to jump.</p>
<p>As an example, imagine this is how we have named the memory cells of our machine:</p>
<pre><code>0 1 2 3 4 5 6 7 8 9 ...
    A     B   C
</code></pre>
<p>Imagine we would like to add the values in memory location B and C to A. Assuming we are currently on 0th memory cell, we can write the code like this:</p>
<pre><code>&gt;&gt;&gt;&gt;&gt;[-&lt;&lt;&lt;+&gt;&gt;&gt;]&gt;&gt;[-&lt;&lt;&lt;&lt;&lt;+&gt;&gt;&gt;&gt;&gt;]
</code></pre>
<p>As a human, it would be very hard to analyze what's happening in this code. We can make it significantly more readable by expressing it like this:</p>
<pre><code>B[-A+B]C[-A+C]
</code></pre>
<p>We can actually write a compiler that can handle all these namings and memory managements for us, and make our life easier!</p>
<p>Zeroing out a cell: <code>[-]</code>
Moving from A to B: <code>A[-B+A]</code>
Copying from A to B: <code>A[-B+T+A]T[-A+T]A</code></p>
<p><strong>Moving a number</strong></p>
<p>Sometimes you'll need to move a number from one memory cell to another</p>
<p><strong>Addition</strong></p>
<pre><code class="language-=">,&gt;,&lt;         ; Store two numbers in memory cells 0 and 1
[-&gt;&gt;+&lt;&lt;]     ; Add the number in slot 0 to slot 2
&gt;            ; Move to slot 1
[-&gt;+&lt;]       ; Add the number in slot 1 to slot 2
&gt;.           ; Move to slot 2 and print its content
</code></pre>
<p>Keep in mind that the program above gets ASCII characters as its input and outputs another ASCII character which its code is the sum of the input codes.</p>
<h2 id="what-really-happens"><a class="header" href="#what-really-happens">What really happens</a></h2>
<p>The Brainfuck CPU we created is similar to real CPUs in many ways, but it lacks many features making it impractical for any serious application. As an example, we didn’t cover how a cpu is able to interact with different hardware (our brainfuck cpu can’t), or how an operating system written for such a simple cpu would look like, or questions like that. In this section, we are going to explore some of those unclear questions you might have about your computer.</p>
<h3 id="how-can-your-computer-interact-with-other-hardware"><a class="header" href="#how-can-your-computer-interact-with-other-hardware">How can your computer interact with other hardware?</a></h3>
<p>Our brainfuck cpu doesn’t really have means for communicating with a 3rd party hardware, so you might still have confusions on how the cpu in a modern computer is connected to other hardware.</p>
<p>The answer is simple (You might figure it out and design a solution yourself too, by putting a bit of thought)
You will just need a few more wires coming out of your cpu, making it able to send/receive data with custom hardware. Besides that, you will need to add a few more instructions for writing/reading data to/from those wires (just like how you interact with your RAM)
As an example, in a x86-64 computer, the instructions x and x are used for communicating with other hardware, we can </p>
<p>Having I/O related instructions isnt the only way a CPU can connect to peripherals. There is one other way too, you can give your hardware access to some parts of your RAM, allowing your CPU to communicate with that hardware by putting data on that part of your RAM. This way, you won’t need dedicated wire for communicating data to the device, as your ram itself is being a medium for communication.</p>
<p>This method has been a popular solution for communicating with a monitor, the monitor could listen to some sections of the RAM (Also known as Video memory) and put the pixel data residing there on your monitor. This way, your cpu could render things on your monitor by simply writing stuff on your RAM. Not a single extra instruction needed!</p>
<p>Curious how you can manipulate your video memory on a Linux machine? Try this command to put random bytes on your monitor’s pixel buffer and see what happens!</p>
<h3 id="what-is-the-first-program-your-computer-executes"><a class="header" href="#what-is-the-first-program-your-computer-executes">What is the first program your computer executes?</a></h3>
<p>We saw that cpus are simple devices that can fetch instructions from memory, run them and write the side effects back to the memory. So, what are the first instructions that are being run in a computer? When you turn your computer on, your RAM is empty, and there are no instructions, so how does it start to load anything when a RAM is absolutely empty on a startup?</p>
<p>The answer is: although your computer has an empty ram, we can still trick your computer, making it believe that some constant pieces of data do exist in the very first bytes of your RAM, and put some initial programs there.</p>
<h3 id="how-can-programs-not-conflict-with-each-other-in-memory-locations"><a class="header" href="#how-can-programs-not-conflict-with-each-other-in-memory-locations">How can programs not conflict with each other in memory locations?</a></h3>
<p>This is a question that you might not have asked yourself but is an important one: when you compile a program, you will get a raw binary that contains the cpu opcodes that need to be executed. Those opcodes that have something to do with your RAM, may use static locations in your memory. Now, imagine you want your computer to load and maintain multiple programs on your ram at the same time. Since the programs are using static locations, there is a very high probability that they will use the same locations of memory for storing data. How does a cpu prevent that? Sometimes this could be malicious too, a program may try to read/write locations on memory that are not for itself (E.g a malicious program may try to read the password you entered for logging in to your shell program)</p>
<h3 id="how-are-the-keyboard-events-are-handled-by-a-computer"><a class="header" href="#how-are-the-keyboard-events-are-handled-by-a-computer">How are the keyboard events are handled by a computer?</a></h3>
<h3 id="how-can-multiple-programs-run-at-the-same-time"><a class="header" href="#how-can-multiple-programs-run-at-the-same-time">How can multiple programs run at the same time?</a></h3>
<h2 id="if-you-are-nerd-enough-to-write-an-os-yourself"><a class="header" href="#if-you-are-nerd-enough-to-write-an-os-yourself">If you are nerd enough to write an OS yourself</a></h2>
<p>You can’t really understand the way a modern computer’s cpu work without writing an operating system for it. Unfortunately, writing an operating system for a popular CPU like x86-64 involves a lot of details that are not necessarily helpful for a book like this. I’ll try my best to explain most of the important questions you might have here, but I highly encourage you to write a simple OS yourself! Here is a good roadmap for an OS project:</p>
<ul>
<li>Read about cross-compiler and try to build a C compiler targeting raw binaries on your CPU</li>
<li>Write a bootloader that is able to print something on the screen</li>
</ul>
<h2 id="lets-talk-in-gerber"><a class="header" href="#lets-talk-in-gerber">Let's talk in Gerber</a></h2>
<p>Using the discussed simulation techniques, we have been able to build a very simple computer that is surprisingly useful, only by connecting a bunch of transistors together! We showed how simple it is to build a CPU that is able to run Brainfuck programs, and we also showed that you can (With some practice and hard-work) write amazingly complex programs that can perform useful stuff using a programming language as simple as Brainfuck.</p>
<p>The fact that our CPU is only a simulation and not a real one, is a bit of a downer, but hey, since our simulation is actually a mixture of components that do exist in the real world, we can surely build a physical version of our computer with real electronic components!</p>
<p>The scary side is, our Brainfuck computer, although very simple, is still composed of thausands of transistors, which certainly means, good luck building it with a bunch of breadboards and tons of wires (Unless you are a real creep)!</p>
<p>So, what's the solution? Let's design the whole thing again using a electronic circuit-design software and ship the design file to an electronic board manufacturer? Well that's not how we do things in this book!</p>
<p>I hope you are convinced that you really can't handle the immense amount of complexity your super-simple CPU has with bread-boards. A cleaner solution is to replicate your circuit on an electronic board, where components are connected together through lanes of copper. If you are into electronics, you might already know that you can print your circuit on a fiber board which is fully covered by copper, and then put your board in a bucket of acid that is able to dissolve copper. That way, only the parts that are covered by the protected material will remain, and you will end up with a board replicating your circuit with copper lines.</p>
<p>After printing the circuit, you may drill the points where the electronic component pins should place in, and then solder them manually with a soldering iron.</p>
<p>Although the process is exciting, it involves a lot of dirt, and if you are not a professional, you may end up with a dirty board that does not work as you expect. The good news is, there are machines that do the whole process automatically for us, and their resulting board is much cleaner compared to a board made by hand.</p>
<p>So now the question is, how do these machines work, and what do we need to give them in order to get our desired output? In other words, how should we describe our board to these circuit-printing machines? Decades ago, engineers asked these questions from themselves too, so they decided that they need to design a description-language for it. The description-language would tell the board-printing-machine exactly how the copper lanes should be printed on the board. That way, the electronic-circuit-design software  could output a file containing the circuit description that could be shipped to manufacturers that are able to do all the complexities of printing circuits for us, using their machines.</p>
<p>One of the most famous languages designed for exactly this purpose is named Gerber, and in the next sections we are going to try to generate a Gerber file describing the physical version of our Brainfuck computer, again using a pure Python script. Let's dive in!</p>
<p>As you might have guessed, Gerber is somehow a graphical file format, since it describes an image that should be printed on a board. The difference is that Gerber files describe an image is printed via copper-metal, as oppsed to regular printing, where colorful inks and materials are involved.</p>
<p>Here is a Hello World Gerber program which outputs a solid circle filled with copper:</p>
<pre><code>%FSLAX26Y26*%
%MOMM*%
%ADD100C,1.5*%
D100*
X0Y0D03*
M02*
</code></pre>
<h2 id="fpgas"><a class="header" href="#fpgas">FPGAs</a></h2>
<p>Although CPUs are general purpose and can perform whatever computation you can ever imagine, sometimes it makes more sense to build specialized hardware for some applications. Not all algorithms need the fancy set of instructions your CPU provides. In fact, many of the computationally intensive application only require simple math operations. Algorithms performing image generation/manipulation are of the examples. That's why computer nowadays have an specialized processors called GPUs, which used to take of what you see on your monitos (GPUs today are not limiting themselves on graphical computations and are being used for many kinds of heavy computation)
GPUs are basically a bulk of processors which have simple instruction sets and they are really good in accelerating algorithms that are known to be <strong>embarrassingly parallel</strong>. An algorithm is embarrassingly parallel if you can divide it into chunks that can be processed by independent processors without any memory-sharing and interactions between the processors. These algorithms are so easily parallelizable, that it would be embarrasing for a programmer to be proud of parallelizing them!</p>
<p>Now there are times where you need something even simpler that a GPU (Well, GPUs are not that simple to be fair). E.g. imagine you need a device that is only able to perform multiplications, and it needs to do billions of them per second. Any CPU or GPU would be an overkill for such an application.</p>
<p>Unfortunately, it would be very costly to design and manufacture a completely new electronic board whenever you need specialized hardware. Instead of doing that, let's get smart and thing of an electronic circuit that can transform into arbitrary circuit without physical changes in its circuitry. Well, such infrastructures do exist and they are called Field-Programmable-Gate-Arrays!</p>
<p>Before getting to the details of the FPGAs, I would like you to think about the way something like a FPGA can work for a bit. The title itself is guiding you to the answer. It has something to do with &quot;gates&quot; that are &quot;programmable&quot;, maybe, unlike a regular logic gate such as AND/OR/NOT, a programmable gate is a gate that can be configured to become whatever gate you like. Try to build a programmable gate yourself, which accepts two inputs and gives out one output, and can transform to different gates when we tune it.</p>
<p>(Hint: You can use memory-cells for storing the chosen functionality of your programmable gate, and put your configuration in it through some extra input pins)</p>
<p>This way, &quot;programming&quot; a gate, would mean to put the right values inside the gate's memory-cells.</p>
<p>Here is a popular design of a programmable gate among FPGAs. They are also known as Configurable Logic Gates (Or CLBs).</p>
<h2 id="chip-8"><a class="header" href="#chip-8">CHIP-8</a></h2>
<h2 id="operating-systems"><a class="header" href="#operating-systems">Operating Systems</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="hear"><a class="header" href="#hear">Hear!</a></h1>
<h2 id="human-senses"><a class="header" href="#human-senses">Human senses</a></h2>
<p>Before starting this chapter, I'm expecting you to understand that human brains are biologically evolved computers. They are massive networks of interconnected cause/effect gates, which can dynamically change their behavior (Unlike a silicon computer gate, which has a fixed behavior over time) to learn stuff. These interconnected gates excite each other through electrical impulses. Electrical impulses are the language with which our neurons talk with each other. So, in order to sense something from the external world, some kind of translation is needed, and that's why we have <strong>Senses</strong>.</p>
<p>There are 6 different kinds of ways a human brain can make sense of the external world. Here is the list, we used to call it the 5 main senses, but there are actually 6 (Do not confuse it with the paranormal sixth sense in the fictions!):</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Organ</th><th>Stimulus</th><th>Stimulator</th></tr></thead><tbody>
<tr><td>Sight</td><td>Eyes</td><td>Light</td><td>Physical self</td></tr>
<tr><td>Hearing</td><td>Ears</td><td>Sound</td><td>Larynx</td></tr>
<tr><td>Balance</td><td>Inner-ears</td><td>Acceleration</td><td>?!</td></tr>
<tr><td>Smell</td><td>Nose</td><td>Chemical substances</td><td>Sweat</td></tr>
<tr><td>Taste</td><td>Tongue</td><td>Chemical substances</td><td>?!</td></tr>
<tr><td>Touch</td><td>Skin</td><td>Position/Motion/Temperature</td><td>Touch/Hit</td></tr>
</tbody></table>
</div>
<p>Human brains need to communicate with each other in order to maximize their evolutionary goals, but they are not directly wired to each other (Imagine they were actually connected to each other directly through wires, an interesting question would be, would they then become a single person?) So what is the solution? How can a conscious piece of meat trapped inside a hard skull communicate with other brains? Pretty much like regular computers you have in your home, brains do also have external auxillary hardware connected to them. Eyes, ears, nose, tongue and skin are examples of devices that are connected to the brain to allow it to sense effects of the external world.</p>
<p>After all, our brain's language is the flow of electricity inside denderites and axons. Before reading the answer, let's imagine we are The Creator and we are going to design a communication system for our creatures to transfer data t</p>
<p>In this chapter I would like to talk about one of the pleasurable inventions of human beings, music. You hear it everyday, whether as an artistic piece to please your ears, or the sound you hear from your phone when you press a key. I believe composing and playing sounds is one of the most important applications of a computer, which is very underrated topic in computer science. Musical notes are lego pieces of our mind. Putting the right notes in the right order can manipulate a mind, bringing sadness, happiness, excitement, horror, magic and all kinds of emotions in a human brain. The good news is, sound waves, which are the most primitive components of music, can be easily generated a computer, because there are ways to convert electrical causes to mechanical effects. Guess what kind of effect a computer is good at generating it? With the current technology, it’s not trivial to generate “smell” effects. We will go through the history of sound and we will try to understand it by breaking a music to its most primitive parts, and in the end of this chapter, we will be able to make your hear a symphony of beethoven by writing a program that outputs nothing but numbers.</p>
<p>Understanding music will make you a better programmer, because music itself is all about playing with lego pieces, which is what we programmers basically do everyday.</p>
<h2 id="history-of-vibration"><a class="header" href="#history-of-vibration">History of vibration</a></h2>
<p>Thomas Alva Edison, some people think of him as a bad guy who stole Tesla’s ideas. We are not here to judge, anyways, he was an inventor and made inventions through his life that had big impacts in our history and were inspiring many people. Here I want to talk about one of his inventions which I myself find very primitive and impressive, the Phonograph (Nowadays we call them Gramophone too) (1877).</p>
<p>Phonographs, as defined in Wikipedia, are devices that can record and reproduce music. The idea behind it is both very smart and simple. Imagine a needle on a rotating disk, where the needle is connected to something like a loudspeaker, which vibrates when someones speaks near it. The needle drills holes on the disk when it vibrates. As the disk rotates, there will be different holes with different depths over time, effectively recording the intensity of air pressure over time.</p>
<p>There is an organ in our body that can vibrate the air in different rates, larynx. When people speak, a neural effect is effectively causing a mechanical effect, which is vibration of the larynx. (Unrelated to this section, but can't resist to tell you that when you speak, somebody hears, and that hearing will cause neural effects. So human communcations are basically neural transistors, capable of building complicated computers which are able to do weird stuff)</p>
<p>Here is a cause/effect analysis of a phonograph: a mechanical effect (Vibrating air) will cause another mechanical effect (Vibrating needle) which will itself cause another mechanical effect which is drilling holes on the disk.</p>
<p>Now imagine we stop recording, rotate the disk in reverse direction so that the needle is on its original position and start again. The holes on the disk will cause vibration on the needle which will itself cause vibration of the loudspeaker which will cause vibration of the air will cause vibration of our eardrum, which will end up as an electrical signal in our brain.</p>
<p>Here is a very useful engineering principle for you: a rotating disk, or basically anything (Physical or conceptual) that can capture the intensity of a world property, can record it. This tape can later be replayed.</p>
<p>If you look closely, you will figure that there is also something familiar and interesting happening when a phonograph plays a music, the vibration applied on the phonograph needle is not able to vibrate the air around it and create sound, but the vibration is routed to the mechanical loudspeaker and somehow intensified there, before reaching our ears, very similar to an electrical amplifier. That's exactly what happens in a transistor, with the difference that the type of cause and effects in a transistor is electricity.</p>
<p>How do we hear? To answer this question, we have to first figure how a vibration (Mechanical effect) is causing a neural stimulation (Electrical effect) in our brain.</p>
<p>Sound is the result of flowing of a mechanical wave through the air. Air is the context here, in a vacuum environment, sound won’t pass. Humans are able to shake the air in their lungs and generate sound. This sound passes through the air and reaches to ears of other humans. Through this process, neural effects in one brain causes neural effects in another brain. Building a meta computer that we call it “society”. (Though, this is not the only medium, people can record their neural effects on a piece of paper by writing, causing neural effects in humans of the future)</p>
<p>Now I want you to think about the translation process here. How is a neural effect translated into a sound in our system? And how is a mechanical cause converted to a neural effect when the sound reaches our ears? Before analyzing a human larynx, I would like to you how a electrical speaker works. The way an electrical speaker generates sound is actually much simpler than a human. An electrical speaker is basically a electromagnet (A magnet in which magnetic field is generated by the flow of electricity through a coil), that is installed besides another magnet which is connected to an elastic plate. When current flows in the coil, the imposed magnetic field will pull the other magnet and the plate. When the current stops flowing, magnetic field goes away and the plate will go back to its original position. You can see the obvious conversion of an electrical wave into a mechanical wave here.</p>
<p>Another interesting fact is that, the same system can act like an electrical microphone too (Remember a phonograph could both record and play music?). Vibration of air will vibrate the magnet which is connected to the plate, and that magnet will impose an electrical flow inside the coil. Voila!</p>
<h2 id="primitive-sounds"><a class="header" href="#primitive-sounds">Primitive sounds</a></h2>
<p>We now know that a single electrical signal is enough to generate voices and also, a single mechanical signal is enough to hear voices. But unfortuantely, that's not how a brain generates/analyzes sounds. The reason is that analyzing a single signal is too complicated, and the nature has not been smart enough to design a brain that is able to hear with a single signal.</p>
<p>When you are in a party, everybody dancing to a loud music, you still can hear what your friend is saying, which is very amazing, because, sound is a single signal, a single stream of intensities. The loud music and the voice of your friend are combined into a single signal and mixed together. The reason you can hear your friend even in a loud room is the same reason you can recognize the taste of an energy drink inside a cocktail, even when it has too many ingredients (Loud in some sense!), even though everything is mixed together. Because there are different receptors that can recognize different primitive elements of that sense, whether hearing or tasting. In case of tasting, the primitive elements of a taste are probably sweetness, sourness, bitterness and etc. But what is the primitive element of an audio signal?</p>
<p>Joseph Fourier, the french mathematician, described that a function/signal can be expressed as the sum of a series of sine or cosine terms. This means that pure sine functions can be primitive elements that form a signal. If we combine two different sine terms of different frequencies by summing them, we can still get them back after a conversion, which is called a Fourier Transform.</p>
<p>So theoritically, if someone speaks in some frequency range, and someone else speak in another frequency range, our brain will be able to distinguish between these two, even if they speak at the same time. If their frequency ranges are too close, it will become hard for brain to understand what each of them is saying. So, human larynx has evolved in a way so that everyone has a unique frequency range!</p>
<p>Enough talking, let's write a program to generate sounds of different frequencies, and their combinations, and then hear how it sounds. This will help you understand the concept much better!</p>
<p>In order to generate a wave of frequency \(f\), you can use this formula:</p>
<p>\(sin(2\pi ft)\)</p>
<p>There is a program in Linux distributions named <code>pacat</code>. PulseAudio Cat's goal is to allow you directly put sound samples on your computer's speaker. It does this at default rate of 44100 samples per second. By default, it gets signed 16bit integer from its standard input and plays it on your speaker by differentiating the voltage applied on the speakers magnet plate. When the sample has lowest possible value (-32768), maximum negative voltage is applied and the plate is pulled, and when the samples has highest possible value (32767), the plate is pushed. A sample of value 0 means zero voltage which means zero magnetic field and the plate remains in its orginal position. Given that the sample ratio is 44100, we should substitute the \(t\) variable with \(\frac{n}{44100}\) where \(n\) is the sample number: \(sin(2\pi f\frac{n}{44100})\)</p>
<pre><code class="language-python=">import sys
import struct
import math


# Send sound sample to stdout as a 16-bit signed integer
def put(x):
    sys.stdout.buffer.write(struct.pack(&quot;h&quot;, int(x * 32767)))


sample_rate = 44100  # Rate per second
step = 1 / sample_rate
length = 5  # Seconds
freq = 440


def f(t):
    return math.sin(t * 2 * math.pi * freq)


t = 0
for _ in range(sample_rate * length):
    put(f(t))
    t += step
</code></pre>
<p><code>put(x)</code> function is getting a floating point value \(-1 \leq x \leq 1\) as its input and putting a signed short integer between \(-32768 \leq s \leq 32767\) into the stdout. It is the main gate which allows us to convert an electrical cause to a mechanical effect, by vibrating a magnetic plate in your computer!</p>
<p>Redirect your script's output to the <code>pacat</code> program and hear the voice of your program:</p>
<pre><code class="language-bash">pacat &lt;(python3 music.py)
</code></pre>
<p>Now let's combine two frequencies and hear how it sounds!</p>
<pre><code class="language-python">def f(t):
    a = math.sin(t * 2 * math.pi * 440)
    b = math.sin(t * 2 * math.pi * 660)
    return (a + b) / 2
</code></pre>
<p>We are taking an average from <code>a</code> and <code>b</code> so that the output value remains between -1 and 1.</p>
<p>If you hear this function, you will actually notice that it consists of two sounds. Your brain can successfully decomposite the output wave into two sounds, and this is amazing! The reason that you can recognize the 440Hz and 660Hz sound in the output of this script is the same reason you can hear your friend in a loud room full of noise, your brain is able to decouple sounds with different frequencies.</p>
<p>Now that we are able to generate sounds of different frequencies, I want you to do an experiment. Try generating frequencies that are of the form \(2^nf\). E.g. try hearing these frequencies: \(440, 880, 1760, 3520, \dots\)</p>
<pre><code class="language-python=">def f(t):
    sec = t * sample_rate
    if sec &lt; 1:
        return math.sin(t * 2 * math.pi * 440)
    elif sec &lt; 2:
        return math.sin(t * 2 * math.pi * 440 * 2) # 880Hz
    elif sec &lt; 3:
        return math.sin(t * 2 * math.pi * 440 * 2 * 2) # 1760Hz
    elif sec &lt; 4:
        return math.sin(t * 2 * math.pi * 440 * 2 * 2 * 2) # 3520Hz
</code></pre>
<p>In the code above, we are generating different frequencies through time. We start with 440Hz, and we double the frequency every 1 second.</p>
<p>Hear them carefully, and then compare how they sound when their frequency is doubled. Try a different coefficient. Generate sounds that are of the form: \(1.5^nf\): \(440, 660, 990, 1485, \dots\)</p>
<p>We can discover something very strange and important here. Sounds that are generated when the frequency is doubled each time, are very similar to each other (At least, to our brain). While in the second experiment, sounds seem to be different with each other. If the sounds that are generated in the first experiment are similar, then what makes them different?</p>
<p>Let's try another experiment (This time without coding!). Play one of your favorite musics and try to sing on it. Try to sing on it with lower and higher pitches. Even though you have changed your voice, your singing still &quot;fits&quot; the song. By singing on a song with higher pitch, you won't shift your frequency by some number, but you will actually multiplying it by a power of two. A man and woman with totally different frequency ranges can both sing on the same song, but both of the singings will &quot;fit&quot; on the song, as long as the frequencies are multiplies of powers of 2. I think it's now safe two say, frequencies that are twiced every time, have same feelings.</p>
<p>Let's start with 300Hz. We calculate powers of two multiplied by the base frequency. Here is what we get:</p>
<p><code>..., 37.5Hz, 75Hz, 150Hz, 300Hz, 600Hz, 1200Hz, 2400Hz, ...</code></p>
<p>Let's agree that they are all basically the same &quot;sound&quot;, and let's put a name on them. Let's call them S1.</p>
<p>Whatever frequency we take from the range 300Hz-600Hz, there will also exist the corresponding &quot;same-feeling&quot; sound in ranges 75-150, 150-300, 600-1200, 1200-2400 and etc.</p>
<p>Conversely, we can also conclude that any random frequncy have an corresponding &quot;same-feeling&quot; frequency in 300Hz-600Hz range. In order to find its same-feeling frequency, we just need to halve/double it, until it gets between 300Hz-600Hz. (E.g. let's start with 1500Hz, we halve it 2 times and we get 375Hz which exists in the range, so 375Hz is the equivalent same-feeling sound of 1500Hz). We know there are infinite number of frequencies between 300Hz-600Hz. A single S1 is not enough for creating beautiful pieces of music. We could only build Morse codes out of the single sounds! So let's discover and define other sounds in the same range.</p>
<p>Imagine we define S2 as a sound that is in the middle of two S1s. Given that the self-feeling sounds are repeated in a loop, here is what we should expect:</p>
<pre><code>S1 - 75Hz
S2 - ?Hz
S1 - 150Hz
S2 - ?Hz
S1 - 300Hz
S2 - ?Hz
S1 - 600Hz
S2 - ?Hz
S1 - 1200Hz
</code></pre>
<p>What is the definition of middle? Let's say, \(C\) is in the middle of \(A\) and \(B\), when the distance between \(C\) and \(A\) is equal with the distance between \(C\) and \(B\). How is <em>distance</em> defined in case of frequencies? As a first guess, we can take the average of two S1 frequencies in order to find the S2 frequency.</p>
<pre><code>S1 - 75Hz
S2 - (75 + 150)/2 = 112.5Hz
S1 - 150Hz
S2 - (150 + 300)/2 = 225Hz
S1 - 300Hz
S2 - (300 + 600)/2 = 450Hz
S1 - 600Hz
S2 - (600 + 1200)/2 = 900Hz
S1 - 1200Hz
</code></pre>
<p>As you can see in the calculations, you can get other S2 sounds by multiplying/dividing any S2 sound by powers of 2, just like what happened with S1. So the derived S2 frequencies are all valid and all same in terms of their feelings.</p>
<p>This is not the only way one can define the &quot;middle&quot; frequency here. Imagine instead of taking the average, we multiply the numbers, and take their square-root instead. This is called an &quot;multiplicative&quot; average, or a geometric mean (As opposed to an arithmetic-mean that we used in the first example):</p>
<p>\(m=\sqrt{ab}\)</p>
<p>We know that the frequencies are doubled in each iteration, so \(b=2a\). Substituting this in the equation we get: \(m=\sqrt{2a^2}=a\sqrt{2}\)</p>
<pre><code>S1 - 75Hz
S2 - 75 x sqrt(2) = 106.06Hz
S1 - 150Hz
S2 - 150 x sqrt(2) = 212.13Hz
S1 - 300Hz
S2 - 300 x sqrt(2) = 424.26Hz
S1 - 600Hz
S2 - 600 x sqrt(2) = 848.52Hz
S1 - 1200Hz
</code></pre>
<p>As you can see, both of these definitions of &quot;middle&quot; give us valid sounds (By valid, I mean they are frequencies that are same-feeling), that indeed are in the middle of the S1 frequncies. The first definition of &quot;middle&quot; gives us numbers that have same arithmetic distance with the S1 frequencies (\(m-a=b-m\)), while in the second definition, the results are numbers that have same multiplicative distance with the S1 frequencies (\(\frac{m}{a}=\frac{b}{m}\)). Unfortunately, each of these defintions of middle is giving us different middle frequencies.</p>
<p>So, the million dollar question is, which one is the more appropriate defintion of &quot;middle&quot; here?</p>
<p>Let's look to those numbers again, this time without considering the middle frequencies. Take 3 consecutive S1s in a row. (E.g <code>300Hz 600Hz 1200Hz</code>). By definition, if we take 3 consecutive sounds, the second one is in the middle of the first and third sound. If we forget about our artificial middle frequencies and take a stream of S1s as our reference sounds, are the middle frequencies the artithmetic or the geometric mean of the other frequencies? </p>
<p>Let's say our 3 consecutive sounds are \(2^ka\), \(2^{k+1}a\) and \(2^{k+2}a\). How can we calculate the middle frequency if we only had the values for the first and the third frequency? Let's try both artithmetic and geometric means.</p>
<p>\(m_a=\frac{2^ka+2^{k+2}a}{2}=\frac{2^k(a+4a)}{2}=5\times 2^{k-1}a\)</p>
<p>\(m_g=\sqrt{2^ka \times 2^{k+2}a}=2^{k+1}a\)</p>
<p>Obviously, geometric mean is the natural definition of &quot;middle&quot; in a raw stream of S1 frequencies, so it makes a lot of sense to define middle as the geometric mean.</p>
<p>Good to mention that another bug also happens when we try to define middle frequencies with arithmetic means. Although S2 resides in the middle of two S1s, S1s do not reside in the middle of S2s! \(\frac{112.5 + 225}{2} \neq 150\). This does not happen when we use geometric means: \(\sqrt{106.06 \times 212.13}=150\).</p>
<p>Fortunately, we have been able to find a way to halve frequency ranges and create new same-feeling sounds out of them! But are 2 sounds enough for making a song? Well, we don't have to stop here. We can still find the middle of a S1 and a S2 and define a new S3 sound. The middle of the gap between an S2 and the next S1 can also define a new S4 sound. We can build infinitely many sounds just by halving the frequency gaps!</p>
<p>Enough explanation. Given that you now know how same-feeling sounds are derived, let's talk about the standard frequencies that are used in the music we hear everyday. Just like how we defined a base frequency S1 for deriving new sounds, music composers also defined a base frequency (That is 440Hz) and derived the other sounds out of it. They called their base frequency <strong>A</strong>, splitted the gap between two consecutive <strong>A</strong>s into 12 different sounds (Probably because 12 was big enough to make big variations of music and small enough so that the sounds remain distinguishable for human ears) and named the 11 other derived sounds as <code>A# B C C# D D# E F F# G G#</code>. How can you take 12 sounds out of a base frequency? New sounds can be derived by multiplying the previous sound by \(\sqrt[12]2 \simeq 1.05946\). Starting from \(A\) sound, if you do this 12 times, you get back to the next same-feeling A sound again, because \(\sqrt[12]2^{12}=2\).</p>
<pre><code>A = 440Hz
A# = 440 * 1.05946 = 466.16
B = 440 * 1.05946^2 = 493.88
C = 440 * 1.05946^3 = 523.25
C# = 440 * 1.05946^4 = 554.37
D = 440 * 1.05946^5 = 587.33
D# = 440 * 1.05946^6 = 622.25
E = 440 * 1.05946^7 = 659.25
F = 440 * 1.05946^8 = 698.46
F# = 440 * 1.05946^9 = 739.99
G = 440 * 1.05946^10 = 783.99
G# = 440 * 1.05946^11 = 830.61
</code></pre>
<p>Let's get our hands dirty and play some melodies with these sounds!</p>
<p><code>E E E _ E E E _ E</code></p>
<hr />
<p>After playing some melodies by generating different frequencies in a sequence, you might nag that the notes are very pure, emotionless, and not at all close to what we hear when we press a key on a piano, and you are right. We are generating pure sine-waves, meaning that what we hear contains only a single frequency. If you analyze the sound coming out of a musical instrument, you will notice that not only it contains frequencies other than the main frequency, but also the strength of those frequencies change over time.</p>
<p>It's not easy to generate a piano sound using pure sine frequencies, but there are other ways we can oscillate a loud-speaker, letting us to get more creative and generate sounds that are more interesting and weird.</p>
<p>Imagine sharp jumpings to -1 and +1 instead of smoothly going up and down like a sine wave. This will make a square wave that feels very differently. Square-waves have vintage feeling, since the game consoles back then didn't have speakers with enough precision for generating sound with needing smoother movement of the speaker's magnetic plate. All they could do was to sharply pull and push the magnetic plate!</p>
<p>Here are some other forms you can oscillate a speaker. Try hearing them all!</p>
<p><strong>Different oscillators - Sawtooth - Square - Triangle</strong></p>
<h2 id="sine"><a class="header" href="#sine">Sine</a></h2>
<pre><code class="language-python">import math

def Sine(freq):
    def f(t):
        return math.sin(2 * math.pi * freq * t)
    return f
</code></pre>
<h2 id="square"><a class="header" href="#square">Square</a></h2>
<pre><code class="language-python">import math

def Square(freq):
    def f(t):
        if math.floor(2 * t) % 2 == 0:
            return 1
        else:
            return -1
    return f
</code></pre>
<h2 id="sawtooth"><a class="header" href="#sawtooth">Sawtooth</a></h2>
<pre><code class="language-python">def Sawtooth(freq):
    def f(t):
        ...
    return f
</code></pre>
<h2 id="triangle"><a class="header" href="#triangle">Triangle</a></h2>
<pre><code class="language-python">def Triangle(freq):
    def f(t):
        ...
    return f
</code></pre>
<h2 id="delay"><a class="header" href="#delay">Delay</a></h2>
<pre><code class="language-python">def Delay(sampler, delay):
    def f(t):
        return sampler(t - delay)
    return f
</code></pre>
<h2 id="compose"><a class="header" href="#compose">Compose</a></h2>
<pre><code class="language-python">def Compose(samplers):
    def f(t):
        v = sum([sampler(t) for sampler in samplers])
        return v
    return f
</code></pre>
<h2 id="playing-notes"><a class="header" href="#playing-notes">Playing notes</a></h2>
<pre><code class="language-python">music = Compose([
    Delay(Adsr(Sine(440), 1, 1, 1, 1, 1, 0.7), 0),
    Delay(Adsr(Sine(440), 1, 1, 1, 1, 1, 0.7), 1.5),
    Delay(Adsr(Sine(440), 1, 1, 1, 1, 1, 0.7), 3),
    Delay(Adsr(Sine(440), 1, 1, 1, 1, 1, 0.7), 4.5),
])
</code></pre>
<p><strong>ADSR</strong></p>
<p>Hearing all these compositions of different oscillators, you may still notice that the sounds are far from being pleasant to your ears, and one of the main reasons is that the intensity of those sounds is constant in time, while in real-world, a note gets loud with a delay, and will smoothly lose its intensity as time passes. One way we can bring such effect in our simulation is to actually manipulate the volume of our oscillator through time.</p>
<p>One of those methods, known as ADSR (Attack, Delay, Sustain, Release), assumes that a musical note starts with a volume of 0, quickly reaches its peak volume and then quickly gets down to relatively quieter volume, stays there for a longer time and then starts decreasing its intensity until it reaches zero.</p>
<p>These timings might be different for different instruments, and they do not neccessarrily change linearly. For the sake of simplicity, we will assume the changes all happen in a linear fashion. Here is a graph:</p>
<p>[ADSR chart]</p>
<p>Fortunately, applying an ADSR effect is as simple as multiplying the ADSR function with the oscillator function!</p>
<pre><code class="language-python">def Adsr(sampler, a_dur, d_dur, s_dur, r_dur, a_level, s_level):
    def f(t):
        if t &lt; 0:
            coeff = 0
        elif t &lt; a_dur:
            coeff = (t / a_dur) * a_level
        elif t &lt; a_dur + d_dur:
            coeff = a_level - ((t - a_dur) / s_dur) * (a_level - s_level)
        elif t &lt; a_dur + d_dur + s_dur:
            coeff = s_level
        elif t &lt; a_dur + d_dur + s_dur + r_dur:
            coeff = s_level - ((t - a_dur - d_dur - s_dur) / r_dur) * s_level
        else:
            coeff = 0
        return sampler(t) * coeff
    return f
</code></pre>
<h2 id="macro-music-language"><a class="header" href="#macro-music-language">Macro Music Language</a></h2>
<p>Macro Music Language (MML) is a very old and deprecated music description language for storing melodies on computers. MML was originally designed to be used in video games back in 70s, so you probably can't find a lot of software that can play MML files, though I chose to introduce and implement this format since it's fairly simple to implement and there are plenty of music available in this format which you can test your synthesizer with. Here is a brief spec of this language:</p>
<p>[TODO: MML Spec]</p>
<p>[TODO: MML Composer]</p>
<pre><code class="language-python">def ComposeMML(mml):
    return Compose([
        # ...
    ])
</code></pre>
<h2 id="frequency-modulation"><a class="header" href="#frequency-modulation">Frequency Modulation</a></h2>
<p>One of the interesting sounds you can try to generate is the sound of a siren. A siren is a device that can generate a loud sound, with alternating frequency. The frequency is alternated itself in a sine pattern. Assuming the sound's frequency alternates between \(f_1\) and \(f_2\), we can calculate frequency, by time, as follows:</p>
<p>\(f=f_1 + (f_2-f_1)\frac{sin(t) + 1}{2}\)</p>
<p>We already know altering the intensity of a sound is as simple as applying a coefficient to its sampler function. If you multiply the above function with an oscillator, its volume will alternate. Knowing that we can generate sine wave with frequency \(f\) with \(sin(2.\pi.f)\), you may conclude that the sound of a siren can be modeled by substituting \(f\) with the alternating \(f\) formula:</p>
<p>\(sin(2.\pi.(f_1 + (f_2-f_1)\frac{sin(t) + 1}{2}))\)</p>
<p>Try to generate and play this sound. It will sound weird, not at all like a siren. But why?</p>
<p>[TODO: Frequency modulation]</p>
<p>How can we emulate an ear in a computer</p>
<p>\(X_k=\sum\limits_{n=0}^{N-1}{x_n.e^{-i2\pi kn/N}}\)</p>
<h2 id="reverb-sound-tracing-and-"><a class="header" href="#reverb-sound-tracing-and-">Reverb, sound tracing and …</a></h2>
<h2 id="sound-is-data"><a class="header" href="#sound-is-data">Sound is data</a></h2>
<h2 id="electromagnetism"><a class="header" href="#electromagnetism">Electromagnetism</a></h2>
<p>Sounds are the result of vibrating air propagating through space. Sound is a kind of wave. When you disturb a still water from some point, the disturbance will start propagating from that point. A cause on a point will have effects on points far from the original point. Just like water (Or any other liquid), waves can be propagated through gases too. Waves are a very important mean of communication. Humans mainly use sound waves for communication. They disturb the air by vibrating their larynx, and the diturbance will propagate in air until it reaches the ears of the listener. Computers can communicate through sound too. Using what you have learnt so far, you can write programs that can encode data as sound and send it through the air to another computer.</p>
<p>Since the sounds we make are propagated through air, without air, we won't able to speak with each other. If you put two people in a vacum space, all they'll see is their friend's lips moving without hearing anything! That's why astronomers communicate through walkie-talkies with each other!</p>
<p>World is a strange place, besides particles and materials, there are non-mechanical things too. Even wondered what prevents two magnets with same poles to get close to each other? If you try to get them close, you'll feel there is &quot;something&quot; in between them, but there actually is nothing. It turns out that moving that &quot;thing&quot; (As the result of moving the magnet), can disturb the area around it too, just like when you move inside water.</p>
<p>Here's another way to think about it: Imagine your entire body is floating in the water in a swimming pool. Assume that the water is completely still, and it will remain so as long as you also remain still and don't move any part of your body. A very slight movement of your hand will create a disturbance in the water (in this case, the water represents the context). Your hand's disturbance will start propagating and reach all parts of the pool. The effect is not immediate, and it will take some time for the motion to reach other areas of the pool. If you start vibrating your hand with some frequency, you will soon see that a slighter vibration (with the same frequency) will begin happening in other parts of the water. The farther the destination point, the more time it takes for the motion to reach, and the less powerful the vibration will be. The very same thing happens in the air. We are all floating in a pool of air, and any movement in the air will have effects on the way air moves. That's why we can communicate with each other. In this case, the context is &quot;air.&quot;</p>
<p>Now, there exists a more unusual kind of context in which waves can occur. We can assume that space is filled with some kind of unknown matter that gets distorted when magnets/electrons move through it. This is the context where electromagnetic waves can propagate. This is the context which our cell-phones, wireless networks, gps satellites, remote controls communicate through. The disturbances in this medium are propagates with speed of light, and that’s one of the reasons why we building our computers to communicate through sounds ( which propagate through air, with a speed of 300ms, a lot less than the speed of light)</p>
<p>Metals are also isolated environments in which certain kind of waves can propagate. Imagine having two wires, connected to a power source with a voltage of 5V. Assume we slowly decrease the voltage to 0. The fact is, the effect is not immediate, and the decrease in voltage will reach the end of the wire with some delay!</p>
<p>Einstein claimed that there can’t be anything faster than light [TODO]</p>
<p>If you even remove the sun from the solar system, the earth will keep orbiting around the missing sun for about 7 minutes, [TODO]</p>
<p>Heinrich Hertz, the German physicist, was the first to prove the existence of electromagnetic waves (that's why the unit of frequency is Hertz). James Clerk Maxwell (we'll learn more about his work in the next chapters) predicted the existence of such waves even before Hertz. However, Hertz was the first to show that they truly exist. He accomplished this by capturing the transmitted waves through an antenna he built himself. It's amusing to know that Hertz believed his invention was worthless and had no use, as he said:</p>
<p>&quot;It's of no use whatsoever... this is just an experiment that proves Maestro Maxwell was right—we have these mysterious electromagnetic waves that we cannot see with the naked eye. But they are there.&quot;</p>
<p>It's challenging to imagine our world nowadays without his invention. Hertz's story is a good example that demonstrates the potential and impact of studying seemingly useless science in our lives.</p>
<p>Hertz's transmitter and antenna were straightforward, and you can build one yourself if you're curious enough.</p>
<p>Although your computer can generate electromagnetic waves in specific frequency ranges (such as WiFi and Bluetooth), unfortunately, it's not possible to generate arbitrary electromagnetic waves. I always wished there was a way to generate electromagnetic waves by putting wave samples on a wave generator hardware (just like what we do with audio). There are good reasons why manufacturers have not included hardware for that in your computer. If you could generate arbitrary waves, you could interfere with many government-controlled facilities, including national television and radio.</p>
<p>Waves are waves, whether mechanical or electromagnetic; they all share very similar traits. The most important and useful feature of a wave is its ability to transfer data.</p>
<p>Studying waves and how you can utilize them to connect people together is a fascinating topic in both computer and electrical engineering. As I always say, experimenting is the best way to learn. So, throughout the next sections, we are going to experiment with waves using an easy-to-generate kind of wave. We know that it's not possible to generate electromagnetic waves with your computer, and we have also seen how easy it is to generate sound waves. Therefore, we will stick to sound waves and try to transfer different kinds of data between computers through sounds!</p>
<h2 id="distribute-sound-radio-stations"><a class="header" href="#distribute-sound-radio-stations">Distribute sound, radio stations</a></h2>
<p>Sound is the primary medium of communication for humans, but unfortunately, speaking becomes ineffective when your audience is far away, and the reason is that sound waves lose energy as they propagate in the space.
The world was a very different place before the invention of telecommunication technologies. The only way you could communicate with your beloved ones (Who were far away), was to send them physical letters. In the best case, your letter could be delivered in the time it took to transfer a physical object from you to your destination (Which was not very fast obviously). There are faster things in universe by which you can transfer messages of course, light is an example. Lights are also waves, just like sounds, but unfortunately we can't &quot;hear&quot; electromagnetic waves, so we can't use them directly, as a medium of &quot;verbal&quot; communication. We can try to design an intermediary language for translating sentences to visual effects and vice versa. The simplest example of such protocol, is some coding technique known as Morse codes.</p>
<p>Invented in the 1830s by an American artist, Samuel Morse (Yes, sometimes artists are pioneers of technology), Morse code is a method for encoding/decoding latin-alphabet letters into a series of signals (Electrical or visual). It is worth noting that Morse-codes are designed in a way such that the most frequent letters in latin-alphabet have shorter signal representations.</p>
<p><img src="assets/morse.png" alt="International Morse-codes" />{ width=250px }</p>
<h2 id="hearing-with-your-computer"><a class="header" href="#hearing-with-your-computer">Hearing with your computer</a></h2>
<p>PulseAudio's <code>pacat</code> program lets you to put raw audio samples on your computer's speakers. On the other hand, there is another program <code>parec</code> which allows you to record audio samples. <code>pacat</code> puts whatever it gets through stdin on your computer's speaker, while <code>parec</code> puts audio samples it gets through your computer's microphone on stdout. Using these commands together you can record and play audio:</p>
<pre><code>parec &gt; record.wav
pacat &lt; record.wav
</code></pre>
<p>Another interesting thing to experiment is to pipe the the <code>parec</code>'s output into <code>pacat</code>. Spoiler alert! Your voice will be echoed:</p>
<pre><code>parec | pacat
</code></pre>
<p>Now let's try to pass the <code>parec</code>'s input through a filter that we'll write in Python, and hear its output via <code>pacat</code>:</p>
<p><code>parec | python3 filter.py | pacat</code></p>
<p>Here is a simple filter that allows only half of the samples to go through (<code>filter.py</code>):</p>
<pre><code class="language-python">import sys, struct

def get():
    return struct.unpack('h', sys.stdin.buffer.read(2))[0] / 32767

def put(x):
    sys.stdout.buffer.write(struct.pack(&quot;h&quot;, int(x * 32767)))

while True:
    get() # Skip one sample
    put(get())
</code></pre>
<p>You will hear a high-pitched version of your voice! (Since skipping the waves-samples will make the waves in the input sound to seem like they are alternating two times faster).</p>
<p>By skipping one of the samples per every two sample, we were able to halven the length of the sound, increasing the speed and frequency of the input sound by a factor of two.</p>
<p>Looking carefully, by skipping the samples, what we are actually doing is taking the samples like this:</p>
<p>\(out[i] = in[2i]\)</p>
<p>Changing the coefficient to 3, makes our input sound 3 times faster. but what if we want to make it only x1.5 faster?</p>
<p>\(out[i] = in[1.5i]\)</p>
<p>Unfortunately, all kinds of digital signals which we process in a computer are discrete, meaning that they are sequences of numbers, the result of sampling the signal over a fixed interval, and you don’t directly have the signal in between two intervals. Although we don’t have the signal data between two intervals, we can predict them with a good accuracy! A very simple prediction model assumes that the distance between two consecutive samples goes through a line!</p>
<p>In other words, you can assume that \(inp[5.5] \simeq \frac{inp[5] + inp[6]}{2}\)</p>
<p>So far, we have had done a lot of experiments using the <code>pacat</code> command, and now it's the time to see what can be done if we allow other computers to receive wave-samples. We have learnt to compose sounds, now its time to decompose them! Putting samples on your computer’s speaker allows you to make disturbance in the air around your computer’s speaker. The disturbance, as seen in the previous sections, will propagate in the space finally reach your ears and you will hear it. Computers can hear those disturbances too, through microphones. Using these two devices together you can build protocols with which computers can talk with each othrr, without any wire connection.</p>
<p>The disturbance doesn’t necessarily need to happen in the air, for example you can basically build devices that can disturb the water in a pool in one side and build a device to detect and listen to the disturbances in the other side of the pool. Using these two, two computers may communicate with each other through water waves!</p>
<p>In real world, what your computer is generating is an electrical signal that is given to a speaker. You can connect the exact same wire to other things too. In fact:</p>
<ul>
<li>Connect that wire to a speaker, and the data will propagate through air.</li>
<li>Connect that wire directly to the destination computer, and the data will propagate through the electrons in the wire.</li>
<li>Connect that wire to an antenna, and the data will propagate through space.</li>
<li>Connect that wire to a light-emitter within a optical fiber cable, and the data will propagate through visible light.</li>
</ul>
<h2 id="fourier-transform"><a class="header" href="#fourier-transform">Fourier Transform</a></h2>
<p>Fourier-Transform is a method/algorithm by which you can extract frequencies within a wave-form. Remember we could generate sounds that were compositions of two sine-waves with different frequencies? When hearing those sounds, your brain is able to successfully recognize the presence of two different frequencies in what it hears, and that is actually why we are able to understand what someone is saying in a crowded environment with a lot of noise. Our brain is able to focus on a certain frequency (Which is the frequency-range of your friend's larynx). If our brains are able to decompose sounds by their frequency, it's reasonable to think that computers can do that too. Fourier-Transform is the answer. Given a list of signal samples, it will tell you what frequencies are present in that signal. Here is an example:</p>
<pre><code class="language-python">import cmath  # Math for complex numbers
import math
import matplotlib.pyplot as plt


def fft(x):
    N = len(x)
    if N &lt;= 1:
        return x
    even = fft(x[0::2])
    odd = fft(x[1::2])
    T = [cmath.exp(-2j * cmath.pi * k / N) * odd[k] for k in range(N // 2)]
    return [even[k] + T[k] for k in range(N // 2)] + [
        even[k] - T[k] for k in range(N // 2)
    ]


def get_freqs(x):
    result = [abs(v) / (len(x) / 2) for v in fft(x)]
    return result[: len(x) // 2]


def sine(freq, t):
    return math.sin(2 * math.pi * freq * t)


def sampler(t):
    return sum(
        [
            sine(440, t)
            + 5 * sine(1000, t)
            + 2 * sine(2000, t)
            + 0.5 * sine(9000, t)
            + 8 * sine(16000, t)
        ]
    )


samples = [sampler(t / 32768) for t in range(32768)]
freqs = get_freqs(samples)

plt.plot(freqs)
plt.show()
</code></pre>
<p><img src="assets/fft.png" alt="The FFT result of a signal composed of 5 different sine frequencies" /></p>
<p>Assuming our sample-rate is \(2^n\), the \(get_freqs\) function will get an array of size \(2^n\) (The signal samples), and will return an array of size \(2^{n-1}\). The \(i\)th element of this array tells your the presence of a sine wave with \(i\)Hz frequency in your input signal. The reason that the output array has half of the number of elements in the input array comes back to the fact that, in order to be able to recognize a signal of frequency \(f\), you need to at least have \(2f\) samples of that signal (E.g you can't recognize a 20000Hz frequency in a signal, if your sample-rate is 30000).</p>
<p><img src="assets/nyquist.png" alt="An example of undersampling, the sampled signal seems to be a sine wave wit lower frequency" /></p>
<p>Humans are able to hear sounds with frequencies as high as around 20000Hz, that's why the typical sample-rate for audio files is something around twice of 20000. (A sample-rate of 44100 is pretty popular!).</p>
<h2 id="dummiest-modulation-algorithm-ever-dmae"><a class="header" href="#dummiest-modulation-algorithm-ever-dmae">Dummiest Modulation Algorithm Ever (DMAE)</a></h2>
<p>Assuming that we can generate waves of a single frequency in one machine, and recognize the existence of that exact frequency in another machine, let's try to design an algorithm to transfer data through audio, by encoding the bits into sound waves on one sides, and decoding them, converting back the audio waves into bits on other side (The encoding/decoding parts are usually referred as Modulation and Demodulation).</p>
<p>Let's start by simply generating a sine wave of frequency \(f_d\) (Data frequency) when we want to transmit a 1, and avoid generating it when we want to transmit a 0. On the other computer, we will listen to the sound samples and perform a fourier transform on them. Whenever we recognize a \(f_d\) frequency, we will output a 1, and otherwise a 0. Obviously, we have to agree on a fixed time interval by which bits are sent, otherwise we wont know how many consecutive 0s (Or 1s) are meant to be received in case the receiver is the presence/absence of \(f_d\) is being detected for a long period of time.</p>
<p>As an extra feature, we would like to let the other machine know whenever we have finished sending our data. Right know, we will probably stop generating any sound when there are no more bits to be sent. The receiver machine is not able to know whether we are out of bits, or we are just sending a lot of 0 bits. A simple solution to that problem is to include another frequency \(f_e\) in our generated signal, which is only generated when there are data to be sent.</p>
<p><img src="assets/modulation.png" alt="Transferring bits through three signals" /></p>
<p>In this case, the receiver will only accept bits when the \(f_e\) frequency is also present in the received signal (Besides presence or absence of data frequency).</p>
<h2 id="noises-noises-everywhere"><a class="header" href="#noises-noises-everywhere">Noises, noises everywhere...</a></h2>
<p>Unfortunately, the air is full of noises, if you start speaking while two computers are transmitting data through audio, the disruption may corrupt data, leading unwanted data to be sent on the destination computer. Even the echo/reflections of the sound in the environment may have negative effects (Remember, all waves share similar traits, reflections happen for electromagnetic waves too)</p>
<p>There are methods and algorithms by which you can detect and correct errors in data transfers.</p>
<p>For the sake of simplicity, we won’t discuss error correction. We will try to provide an effective way for error detection, and ask the sender computer to resend the data in case it detects errors.</p>
<h2 id="telephone-revolution"><a class="header" href="#telephone-revolution">Telephone revolution</a></h2>
<p>When talking about the invention of telephone, many people will give all the credit to the Scottish-born inventor, Alexander Graham-Bell, while just like many other inventions, telephone has a long history too, which includes several names. Graham-Bell was not the first one who had the idea of building a device which could transmit voice through a wire. One of the notable people who worked on a similar idea was a German inventor named Johann Philipp Reis, who invented the Reis telephone, 15 years before Graham-Bell. Unfortunately, Reis died before he could be credited for the invention of telephone. </p>
<p>Reis considered his invention as a device for transmitting music, so he termed his microphone the 'singing station'. Very similar to a phonograph, the Reis telephone was based on a vibrating needle that could increase/decrease electrical resistance between two contacts, which could lead to generation of a electrical disturbance/signal, traveling through a wire. It's very interesting to know that phonographs was invented after telephone (1877)!</p>
<p>In a phonograph, the vibrations made on the needle was causing mechanical effects on a spinning disk. In the Reis'es telephone, those vibrations were causing electrical effects in a wire. Both of these effects could be later/farther be played by a receiver through a speaker. In case of a telephone, the receiver would just amplify those electrical effects, causing vibration in the air, restoring the sound.</p>
<p>Alec Reeves - inventor of pcm 1930s</p>
<p>James Russel - 1978 - store music on optical</p>
<p>Hdd 1956 IBM</p>
<p>Digital data transfer samuel morse early 19th</p>
<p>1950 computers connected dedicated communication lines</p>
<p>Aliasing claude shannon</p>
<p>Humans love to store and copy. If you can copy or store something, you can transfer it. You can write your thoughts on a letter and then give it to your lover to read</p>
<p>Humans dream: being able to share their past experience to the present and future. To the people that are not near them. To people in the future even after they physically die, because life has evolved in a way to keep you alive as long as possible, sometimes the conceptual version of you, and not the physical you. That’s probably why people proudly compromise their lives for something they believe in, because it will make them eternal. Life is strange.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="see"><a class="header" href="#see">See!</a></h1>
<p>Vision is my (Or probably all people's) favorite way of sensing the world. Imagine out of 6 humans senses, you only could have one of them, which one would you choose?</p>
<p>Vision allows you to find stuff around you, even when they are far enough that you can't access them by your hands. It guides you to things in a physical environment. It shows you the wild animal a coming to you before it's too late.</p>
<h2 id="history-of-colors"><a class="header" href="#history-of-colors">History of colors</a></h2>
<p>Human eyes are 2d-arrays of electromagnetic receptors that can recognize electromagnetic waves inside the visible spectrum, which are waves with wavelengths of 380-700 nanometers, or in terms of frequency, waves with frequencies of 400-790 terahertz. Theoritically, of you pick a magnet, and and shake it 400,000,000,000,000 times per second, you will see red light coming out of it. Shake it even faster and it will become violet, after that, it will become ultra violet which is not visible by human eyes.</p>
<p>Before studying how an human eye works, let's design one for ourself. As you may already know, electrical flows run a biological neural network. So external inputs need to be translated into electrical signals before they can be understood by your brain. We can use a linear mapping for this conversion. We can map the visible specturm into a voltage between 0.0 and 1.0, where 0.0 is red and 1.0 is violet:</p>
<p>\(e=\frac{f-400tHZ}{390tHZ}\)</p>
<p>Unfortunately, this mapping doesn't explain how black and white colors are represented in a brain. Well I have to tell you something. Black and white colors do not exist. (Or even light-red and dark-blue colors!) They are imaginary colors our brain has invented for itself in order to perceive darkness (Black) and presence of all waves (White). Well I have some bad news. A light beam doesn't necessarily have a single frequency in it. It can be a combination of multiple frequencies, and our mapping can only handle a single frequency. so we need a different represantation for a color of a pixel. A very naive solution is to have a lot of sensors sensing the strength of different frequencies in the visible spectrum for each pixel. I.e. we can have a set of sensors \(e_{400}\), \(e_{401}\), ..., \(e_{790}\), that can measure the presence of different frequencies (And the neighbour frequencies) as a voltage between 0 and 1. In this model, when all frequencies are 0, the brain will perceive it as black. When all frequencies are 1, the brain will perceive it as white. The problem with this model is that it will need a lot of cells for each pixel. If the human eye is a \(n \times n\) array, then we'll need \(n \times n \times 390\) cells in order to perceive an image.</p>
<p>We can get smarter than that. Imagine there are only two sensors per pixel, one will tell you how close the frequency is to \(f_a\) and another will tell you how close you are to \(f_b\) (Imagine \(f_a=500tHZ\) and \(f_b=600tHZ\)) </p>
<p>If you are ok in math, you probably know that we can build such behavior using the exponetiation of the absolute difference. (Or squared difference, like a Gaussian distribution equation)</p>
<p>\(e_a = s.e^{-abs(\frac{f - 500}{50})}\)
\(e_b = s.e^{-abs(\frac{f - 600}{50})}\)</p>
<p>Now let's try different frequencies in this scheme (Let's assume the strength \(s\) of all frequencies is \(1\)):</p>
<p>\(f=0\) then \(e_a \simeq 0\) and \(e_b \simeq 0\)
\(f=500\) then \(e_a = 1\) and \(e_b \simeq 0.13\)
\(f=550\) then \(e_a \simeq 0.36\) and \(e_b \simeq 0.36\)
\(f=600\) then \(e_a \simeq 0.13\) and \(e_b = 1\)
\(f=1000\) then \(e_a \simeq 0\) and \(e_b \simeq 0\)</p>
<p><em>It's much easier for a brain to analyze differences between outputs, rather than memorizing different values</em></p>
<p>Now let's take advantage of this design and hack it! Let's say I have two light bulbs, one can emit \(500tHZ\) lights and one can emit \(600tHZ\) lights. Is there a way I can convince the eye that it is seeing a \(550tHZ\) light? Yes! Instead of emitting a \(550tHZ\) light with strength \(1\), I can emit a \(500tHZ\) light of strength \(\simeq 0.32\) and a \(600tHZ\) light of strength \(\simeq 0.32\) at the same time. This will make \(e_a = e_b \simeq 0.36\) which are the same values needed to convince the brain it is seeing a \(550tHZ\) light!</p>
<p>Now the brain's algorithm can be something like this:</p>
<ul>
<li>If both \(e_a\) and \(e_b\) are zero, then there is no color (Darkness, infrared or ultraviolet)</li>
<li>If \(e_a\) is much higher than \(e_b\) then the color is orange.</li>
<li>If \(e_b\) is much higher than \(e_a\) then the color is green.</li>
<li>If \(e_a\) and \(e_b\) are relatively equal, then the color is yellow.</li>
</ul>
<p>Enough imagination! These numbers and formulas are all invented by me to explain the concept. Let's talk about the actual design of human eyes. So the human eyes is designed very much similar to the artifical eye we designed in the previous section. The only difference is that the human eye has receptors for 3 colors instead of 2. I'm sure you can guess what these three colors are! Red, Green and Blue. This fact was discovered in 1802 by Thomas Young (British polymath) and Hermann von Helmholtz (German physicist). They argued that there are 3 kinds of photoreceptors (Now known as cone-cells) in the eye, and they also mentioned that these cells have overlapping response to different wavelengths, allowing our brains to also recognize colors in-between red, green and blue wavelengths. They also mentioned that human eye is not perfect, because it is not able distinguish between yellow, and a mixture of red and blue. If our brains were able to distinguish between those two, it would be much much harder to build computer screens that we have today (Might be even impossible!). That's when God says, this is a feature, not a bug! It's also kind of sad that we are actually blind since our vision (Even in the visible specturm) is very limited and we can only observe very few combinations of light waves.</p>
<h2 id="memento"><a class="header" href="#memento">Memento</a></h2>
<p>Years later, in 1826, a french inventor named Nicéphore Niépce had the dream of recording scenes of real life. Back then people knew that there are some chemical compounds that make chemical reactions when they are exposed to light. The chemical reaction would convert the compound to a different compound which fortunately had a different color. The more intense the light is, the stronger the chemical reaction is, applying stronger color changes to the compoound. Nicéphore took advantage of this, he made a plate coated with such a compound and put it inside a camera obscura. A camera obscura was a dark, isolated room with a small hole (Filled with a lense) on one side that projected the image of the outside on the wall. Nicéphore put his coated plate on the wall, and let it be there for a few days. After a few days, the image of the outside started to appear on the plate, which is the very first photography ever done in the world. The resulting picture wasn't perfect (What did you expect?) but the experiment was revolutionary enough to inspire other inventors for building the modern photography.</p>
<p>James Clerk Maxwell, you probably have heard his name before, because of the electromagnetic equations he discovered before, was only 24 years old when he discovered the importance of the trichromatic theory that Young and Helmholz proposed in 1802. The three-colour method, first proposed by Maxwell, was a method for taking colour photographs, given the fact that human eye is only sensetive to 3 ranges of colours. Redness, greenness, and blueness.</p>
<p>He argued that if we take three photographs of the same scene, one with a filter that only passes red light, one that only passes green light and one that only passes blue light, and then somehow combine these three photographs together on a plate, our eyes will be hacked to see a coloured version of that scene. 6 years later, he made the very first colour photography of the history.</p>
<p>You probably already know that when coloured movies came out, old fashioned movie makers were skeptical of them. Good to know that photographers back then also resisted to take coloured photos, but history has shown us that nobody can fight against advancement of technology.</p>
<h2 id="digital-era"><a class="header" href="#digital-era">Digital era</a></h2>
<p>Over a century passed before humans invented digital photography, and a lot of inventions and discoveries happened in between (E.g. people started to take pictures in very high speeds and record &quot;movies&quot;), and I would like skip the history and advancements of the analog photography industry in the next 100 years, because there are too many details that are unrelated to the core idea, and start talking about the digital era, the time when people started to store vision on a computer.</p>
<p>It's good to know that digital scanners came before digital cameras. It's also kind of obvious that they have a much simpler structure than digital cameras. The very first digital scanner was invented in 1957 by an american engineer named Russell Kirsch. His scanner could scan photos of size 5cmx5cm in the resoluion of 176x176 pixels (30976 pixels, i.e. ~30 kilopixels!). The bit-depth of his scanner was only 1-bit! The pixels could only be complete black or complete white, so there were no intermediate shades of gray.</p>
<p>In order to deeply understand how digital photography works, you first have to know there exist some materials that their electrical resistance change when they are exposed to light. They are called photoresistors. Their resistance typically decrease when they are exposed to light. So, if you connect a battery to them, when there is no light, no/small current will flow. But when there is light, current will flow. The more intense light is, the more current it will flow. Now how can we use this to measure light intensity of a physical point? Imagine we emit light to a black surface. A black surface will reflect no light, so a photoresistor nearby won't get excited. A white surface will reflect all the light. so the photoresistor will get excited and current will flow. Now imagine we have an electrical circuit that measures the electrical current in a photoresistor. If current is higher than a threshold \(t\), it will output 1, otherwise it will output 0.</p>
<p>What Russell Kirsch did in 1957, was something like this: He made a photoresistor that could move on a 2D grid with electrical motors. It would start on the point \((0,0)\) and scanned a complete row, by moving little by little (In case of a 5cmx5cm area, the distance between pixels is 5cm/176, which is around 0.28mm. Then it would move to the next row and scan another line of pixels. It would output 0 or 1 for each pixel. His scanner was so simple so it couldn't scan grayscale information. But he did a trick. Remember there was a threshold \(t\)? He scanned a point several times with different thresholds, (E.g. \(t=0.1\), \(t=0.2\), \(t=0.3\), ...) then he stored number of times he got the 1 output. This way, he could recognize how white a pixel is and store grayscale information too, without much change in the original design! Kirsch's very first digital scanning is one of the most important pictures taken in the history of photography.</p>
<p>Digital cameras are not scanners. It takes a very long time to takes photos by moving a photoactive subtance and taking samples from it. So what's the solution? Well, naively thinking, instead of a single photon sampler (Photoresistor or ...), we can have and array of a lot of them. In case of Kirsch's design, instead of one moving photoresistor moving on a 2D grid, we can have a plate of 176x176 (30976) photoresistors laying on a 2D grid, which can scan the whole thing in a single step. This design has a very important issue, and the issues is that we might need millions of wires coming out of such a plate, in order to get the outputs of all this resistors (Imagine we want to take a very high resolution image!), which is practically impossible. Engineering is all about giving solutions to challenging problem!</p>
<p>12 years later, in 1969, two Bell Labs physicist named George Smith and Willard Boyle invented the very first Charge-Coupled Device, while working on solutions to improve video-telephone technology. They sketched the first design of a CCD in an hour or so. CCDs are the main elements of modern digital photography. Just like our proposed design, they consist of an 2D array of very small cells that convert light causes to electrical effects. A very common technique is used in order to minimize the number of wires coming out of such an array. Instead of taking a wire out of every cell and reading the content of the cell directly, the cells are interconnected to each other through a single wire that passes through all the cells, and pass their contents to their neighbors in each time step (Shift-registers are used in order to store and pass the data). The CCD will actually output the contents of the image through one line, in a serial fashion.</p>
<p>Applying the trichromatic theory and Maxwell's colour photography idea, we can take colored digital photos too. There exists physical filters that you can put on a CCD array, allowing the neighbouring cells to independently capture the redness, blueness and greenness of a point. They are called Bayer filters. Sometimes, instead of putting a Bayer filter on a CCD array, they natively integrate 3 different CCDs on a CCD array, each of which take the RGB values for each pixel. The method is called, 3-CCD. Obviously using a Bayer filter has a much simpler design.</p>
<h2 id="anatomy-of-a-computer-image"><a class="header" href="#anatomy-of-a-computer-image">Anatomy of a computer image</a></h2>
<p>Knowing all this history and human anatomy, we can now tell that a computer image is a 2D array of pixels, where each pixel has 3 properties, red, green and blue. Typically, each color component can have 8-bit value (0 to 255). When the value is 0, that color component is completely off and when the values is 255, it means that color component has highest possible intensity. When all three components are 0, the pixel has complete darkness so we see it as black, and when all of them are 255, we see white (Our brains will be tricked that we are seeing all of the possible waves of the visible spectrum, but we are only seeing three colors!)</p>
<p>It is obvious that a colored computer image can be stored using \(W \times H \times 3\) bytes. (\(W \times H\) pixels, each having three 8-bit components). In order to get comfortable with digital computer images, we are going to manipulate and generate them. Since we don't want to bother ourselves with details of computer image formats (There is so much to learn about how PNG, JPEG and etc works), we are going to use a very simple file format named <code>PPM</code> (Portable PixMap) that emerged in 1980s. PPM stores the image in raw format and doesn't do any compression, that's why it's very simple to generate and manipulate these files. The only metadata that this file format holds is the width and height of the image.</p>
<p>Here is a spec of this file format:</p>
<pre><code>P6 800 600 255
[800x600x3 bytes of data]
</code></pre>
<p>A PPM file starts with the magic string <code>P6</code>, then comes a width (As an ASCII string), then the height and then the maximum value of a color component. The metadata values are separated using whitespaces. After the metadata, there comes a whitespace and then we'll have the raw image data. In the example above, we are describing a 800x600 image in which each color component is between 0 to 255. It is worth noting again that the metadata comes as a human readable ASCII string and not bytes. The size of final file is:</p>
<p><code>P6</code> (2 bytes) + whitespace (1 byte) + <code>800</code> (3 bytes) + whitespace (1 byte) + <code>255</code> (3 bytes) + whitespace (1 byte) + raw image data (1440000 bytes).</p>
<p>Let's write a function in Python which is able to save a PPM file using the described format:</p>
<pre><code class="language-python=">import io

def save_ppm(width, height, rows):
    with io.open('output.ppm', 'wb') as f:
        f.write(f&quot;P6 {width} {height} 255\n&quot;.encode('ascii'))
        for row in rows:
            for (r, g, b) in row:
                f.write(bytes([r, g, b]))
</code></pre>
<p>In this function, the <code>rows</code> argument should be a list of <code>height</code> number of rows, in which each row has <code>width</code> number of pixels (tuples) of RGB triads. As an example on how to use this function, let's generate a 800x600 image that all pixels are red:</p>
<pre><code class="language-python=">def color_of(x, y, width, height):
    return (255, 0, 0) # Always return red


WIDTH = 800
HEIGHT = 600
rows = []
for y in range(HEIGHT):
    row = []
    for x in range(WIDTH):
        row.append(color_of(x, y, WIDTH, HEIGHT))
    rows.append(row)

save_ppm(800, 600, rows)
</code></pre>
<p>In order to make our future image generations easier, instead of calculating the color of the pixel directly in the loop, I made a function called <code>color_of</code> which returns the color of the \((x,y)\)th pixel in an image of size \((width, height)\). Currently, this function only returns red, so you may not see anything special in the output, but try this function instead:</p>
<pre><code class="language-python=">import math


def color_of(x, y, width, height):
    xx = x / width
    yy = y / height

    r = (math.sin(x / width * 100) + 1) / 2 * 255
    g = (math.cos(x * y / height / width * 100) + 1) / 2 * 255
    b = (math.sin(y / height * 100) + 1) / 2 * 255
    return (int(r), int(g), int(b))
</code></pre>
<p>See what it generates, try different functions and play with it a bit. Guess how shocking it was for computer scientist back then to be able to generate vision using code. That opened doors for insane amount of creativity and the event was big enough to call it a revolution in my opinion!</p>
<p>Drawing a line</p>
<p>Drawing a circle</p>
<blockquote>
<p>Why do we use electrical cause effects? Because they are small and fast, and can easily be routed by metal wires Fastest cause effect type is light</p>
</blockquote>
<h3 id="having-fun-with-the-pixels"><a class="header" href="#having-fun-with-the-pixels">Having fun with the pixels</a></h3>
<p>When learning computer graphics, before jumping to complicated algorithms like 3D rendering, there are some other stuff you can do to leverage your power of manipulating pixels.</p>
<p>There are plenty of things you can draw on a 2D surface. Let's start with drawing a simple 2D line. A 2d line may be defined by its slope and offset:</p>
<p>\(y = ax + b\)</p>
<p>Given two points, you can find the corresponding \(a\) and \(b\) that passes through this line too. Assuming the points are: \(P_1 = (x_1, y_1)\) and \(P_2 = (x_2, y_2)\):</p>
<p>\(a = \frac{y_2 - y_1}{x_2 - x_1}\)</p>
<p>\(b = -ax_2 + y_2\)</p>
<p>Let's have a class for working with lines!</p>
<pre><code class="language-python=">class Line:
    def __init__(self, slope: float, offset: float):
        self.slope = slope
        self.offset = offset
    
    def get_y(self, x: float):
        return self.slope * x + self.offset

    @staticmethod
    def from_points(a: Vec2D, b: Vec2D) -&gt; Line:
        slope = (b.y - a.y) / (b.x - a.x)
        offset = -slope * b.x + a.x
        return Line(slope, offset)

</code></pre>
<p>Here is something interesting to draw with simple lines:</p>
<p>[TODO]</p>
<h4 id="circle"><a class="header" href="#circle">Circle</a></h4>
<p>A circle can be defined given its center and radius. Just like the <code>Line</code> class, we may also have a <code>Circle</code> class:</p>
<pre><code class="language-python=">class Circle:
    def __init__(self, center: Vec2D, radius: float):
        self.center = center
        self.radius = radius
</code></pre>
<h3 id="fractals"><a class="header" href="#fractals">Fractals</a></h3>
<p>One of them is to draw fractals! Fractals are patterns that repeat forever. If you zoom in what you see is very similar to the whole image. Let's draw a few of them:</p>
<h4 id="serpinski-triangle"><a class="header" href="#serpinski-triangle">Serpinski Triangle</a></h4>
<h4 id="koch-snowflake"><a class="header" href="#koch-snowflake">Koch Snowflake</a></h4>
<h4 id="julia-sets"><a class="header" href="#julia-sets">Julia sets</a></h4>
<h2 id="ray-tracing"><a class="header" href="#ray-tracing">Ray Tracing</a></h2>
<p>3D computer rendering is probably the most complicated and interesting way a computer
can stimulate our vision. Our perception is evolved in a way to understand our 3-dimensional
space and world. Being able to generate arbitrary 3D looking images with a computer brings 
us infinite possibilities. Nowadays people are trying to immerse themselves into virtual worlds
by putting computer screens really close to their eyes, which renders photorealistic images.
There are many methods and algorithms by which we can 3D computer images, we are going to 
implement two of the most important ones in this book. One of those methods will give you very
photorealistic outputs with high rendering times, while the other method gives you inaccurate 
outputs but is fast enough to generate images in real-time, making it perfect for 3D games.</p>
<p>Surprisingly (Or obviously for some!), the rendering algorithm that gives you real-looking
outputs is much simpler to implement, so let's dive in!</p>
<p>Ray-Tracing, as its name suggests is an algorithm, inspired by the science of physics, that
tries to generate 3D scenes by predicting and tracking the way photons move in imaginary
3D environements. Since there are infinite number of photons coming out of a light source,
it might seem infeasible to generate images with this method. But the fact is, most of
the photons coming out of a light source end up somewere that do not have any impact on
out final image (They do not reach our imaginary eyes). We only care about those photons
that reach our virtual eye/camera. Given this fact we can get clever and do this simulation
in a much more efficient way! We just need to go backwards. We will generate rays from our
virtual eye and see if they will end up on a lit source! This is the core idea behind the
Ray-Tracing algorithm!</p>
<p>The Ray-Tracing algorithm for generating 3D computer images is all about tracing 
the route a photon goes through when reaching our eyes. You can assume that photons 
are like particles that are emitted from light sources, as if a lamp is shooting out
a lot of ultra tiny balls. These balls change their colors when they hit objects and 
absorb their colors, and finally some of them reach our eyes, letting us to see the 
world around us. Since photons move on straight lines, we can study their behavior 
with mathematical vectors. Since we live in a 3D world, the movements of our photons
can be analyzed using 3D vectors. A 3D vector is nothing but a tuple of 3 floating-point
numbers. A 3D vector can be used for storing the position or direction of a photon.</p>
<pre><code class="language-python">class Vec:
    def __init__(self, x, y, z):
        self.x = x
        self.y = y
        self.z = z
</code></pre>
<p>There are two very special and interesting operations that can be done on 3D vectors:</p>
<ol>
<li>
<p>Dot-product: Calculates how aligned the vectors are. The dot-product of two vectors 
is in its maximum when both vectors are pointing at the same direction. The dot-product
of two vectors is a scalar value, which can be calculated in two ways:</p>
<ul>
<li>\(\vec{A}.\vec{B} = A_x.B_x + A_y.B_y + A_z.B_z\)</li>
<li>\(\vec{A}.\vec{B} = |\vec{A}|.|\vec{B}|.sin(\theta)\)</li>
</ul>
</li>
<li>
<p>Cross-product: Calculates how perpendicular two vectors are. The length of cross-product
of two vectors is in its maximum when the vectors are perpendicular with each other. The
result of a cross-product is a vector, that is perpendicular to both vectors, and its length
is equal with the product of length of the vectors multiplied with cosine of their angle.
Assuming the cross-product of \(\vec{A}\) and \(\vec{B}\) is \(\vec{C}\), the elements of \(\vec{C}\)
can can be calculated with the following formula:</p>
<ul>
<li>\(C_x = A_y.B_z + A_z.B_y\)</li>
<li>\(C_y = A_z.B_x + A_x.B_z\)</li>
<li>\(C_z = A_x.B_y + A_y.B_x\)</li>
</ul>
<p>Alternatively, you can calculate the length of a cross-product using this formula:</p>
<ul>
<li>\(|\vec{C}| = |\vec{A}|.|\vec{B}|.cos(\theta)\)</li>
</ul>
</li>
</ol>
<p>Let's go ahead and implement these operations as methods on our <code>Vec</code> class:</p>
<pre><code class="language-python">def dot(self, other):
    return self.x * other.x + self.y * other.y + self.z * other.z

def cross(self, other):
    return Vec(
        self.y * other.z + self.z * other.y,
        self.z * other.x + self.x * other.z,
        self.x * other.y + self.y * other.x,
    )
</code></pre>
<p>Reminding you of high-school math, a 2D vector's length could be calculated by summing the square
of vector elements and taking its root, the length of a 3D vector can also be calculated using a
similar approach:</p>
<p>\(|\vec{A}|=\sqrt{A_x^2 + A_y^2 + A_z^2}\)</p>
<p>Alternatively, we can calculate the length of a vector by taking the square root of the vector, 
dotted with itself:</p>
<p>\(|\vec{A}|=\sqrt{\vec{A}.\vec{A}}\)</p>
<pre><code class="language-python">def length(self):
    return math.sqrt(self.dot(self))
</code></pre>
<p>Another useful operation is multiplication of a vector by an scalar. We are going to override the
multiplication operator in order to have this operation in our <code>Vec</code> class:</p>
<pre><code class="language-python">def __mul__(self, other):
    return Vec(
        self.x * other,
        self.y * other,
        self.z * other,
    )
</code></pre>
<p>Normal of a vector \(\vec{A}\) is defined as a vector with length \(1\) that has the same direction
as vector \(\vec{A}\). Based on the definition, we can calculate the normal vector by dividing the
elements of the vector by the length of the vector:</p>
<p>\(norm(\vec{A})=\frac{\vec{A}}{|\vec{A}|}\)</p>
<pre><code class="language-python">def norm(self):
    len_inv = 1 / self.length()
    return self * len_inv
</code></pre>
<p>Although your compiler's optimizer will do the job for you, it's generally better to calculate
the inverse of a number and multiply it with your variables, instead of dividing the variables
by a number, since multiplication is a much cheaper operation and will take much less clock 
cycles of your CPU compared to divisions.</p>
<p><img src="assets/rtc.png" alt="Shooting rays from an imaginary eye" /></p>
<p>Assuming our imaginary eye is located at \(\vec{E}\), looking at an object that is located on a
target \(\vec{T}\), we may assume what is being seen by the eye is reflected on a square plane 
located with a distance of \(1\), which its center is \(\vec{C}\). Obviously, the direction of 
\(\vec{EC}\) should be equal with \(\vec{ET}\). Since the size of \(\vec{EC}\) should be 1, we may
conclude that \(\vec{EC}\) is the normalized vesion of \(\vec{ET}\).</p>
<p>Now, assuming we have the position of the left-down corner of this plane (\(\vec{LD}\)), and we 
want to render a \(W \times H\) resolution image, we may loop through each of the pixels on the 
image and calculate the corresponding 3D point located on the 3D plane (Let's name it 
\(\vec{P_{ij}}\)), in order to calculate the ray that starts from \(E\)and goes in the direction 
of \(\vec{EP_{ij}}\).</p>
<p>\(\vec{P_{ij}}=\vec{LD}+\frac{i}{W}\vec{R}+\frac{j}{H}\vec{U}\)</p>
<p>Let's hold the position and direction of a ray in a seperate <code>Ray</code> class:</p>
<pre><code class="language-python">class Ray:
    def __init__(self, pos, dir):
        self.pos = pos
        self.dir = dir
</code></pre>
<p>We can use the PPM image generator we developed in the previous sections in order to calculate
a ray-traced scene. We just need to reimplement the <code>color_of</code> function:</p>
<pre><code class="language-python">def color_of(x, y, width, height):
    p = ld + (x / width) * r + (y / height) * u
    direction = (e - p).norm()
    ray = Ray(e, direction)
    return trace_ray(ray)
</code></pre>
<p>The <code>trace_ray</code> function will take a ray as an argument and will calculate the color and intensity
of photons that are going through that ray for us.</p>
<p><img src="assets/eye.png" alt="Calculation of eye-generated rays" /></p>
<h3 id="rasterization"><a class="header" href="#rasterization">Rasterization</a></h3>
<p>Rasterization is another effective technique in rendering 3D scenes and it is quite faster than ray-tracing (Or any other method involving simulation of Physics). Although the results are less accurate, it is the main technique used in real-time rendering applications (E.g Video games). You don't have much time to render the next frame in a game! (Although, games are slowly switching to ray-tracing in some parts nowadays, as our hardware becomes faster)</p>
<p>In the rasterization algorithm, instead of emitting rays abd finding the object that it intersects with and calculating its color, we will try to map the 3D points of an object into 2D points on your computer screen through mathematical formula. In other words, when rendering each frame, we loop through the objects in our scene, and all of the 3D points that make those objects, and we will apply a function which convert a triplet \((x, y, z)\) to a pair of floats \((x,y)\). We then fill those pixels on the screen!</p>
<p>Since it is impractical to represent a 3D object by its points (A 3D object it made of infinite number of points), we usually represent them by a bunch of 3D triangles. Looping through the triangles of an object, using the same 3D-to-2D point conversion formula, we can convert a 3D triangle to a 2D one. We just have to apply the function on all three 3D vertices of the triangle in order to get the respective 2D ones.</p>
<p>Filling a 2D triangle on an image is a straightforward process. Before getting into the more complicated parts, let's first draw a triangle on a PPM image, given the 2D position of its vertices. It's good to defined classes for storing 2D points and triangles, so let's first create a class named <code>Vec2D</code> which stores two floating point numbers and another class named <code>Triangle2D</code> for storing three <code>Vec2D</code>s. Our PPM triangle renderer should accept a <code>Triangle2D</code> and fill the pixels within that triangle.</p>
<pre><code class="language-python=">class Vec2D:
    def __init__(self, x: float, y: float):
        self.x = x
        self.y = y


class Triangle2D:
    def __init__(self, a: Vec2D, b: Vec2D, c: Vec2D):
        self.a = a
        self.b = b
        self.c = c
</code></pre>
<h3 id="matrices-programmable-math-objects"><a class="header" href="#matrices-programmable-math-objects">Matrices, programmable math objects!</a></h3>
<p>When doing ray tracing, we exactly knew where are imaginary eye/camera is, but so far in the rasterization algorithm, we were assuming that the eye/camera is placed at the origin point \((0,0,0)\). So, how could we move in this 3D scene and see it from different perspectives? The solution is a bit different compared to what we were doing in a ray tracer. Here, instead of moving/rotating the camera around the world, we move/rotate all of the objects in that world, in order to make it feel like the camera is placed in a different location! Since we are working with 3D points, before passing the points to the rendering function, we have to apply a <em><strong>transformation</strong></em> function to put the point in a different location.</p>
<p>These transformations are done through matrices! There are matrices that apply certain geometric changes when being multiplicated with vectors.</p>
<p>Assuming our points are represented in 4D vectors where the last element is 1, we can invent a matrix that can move a point by adding a offset vector to it when multiplied with the original vector. This matrix is known as <em><strong>translation</strong></em> matrix. Assuming we want to move our vector \((x, y, z)\) by \((T_x, T_y, T_z)\), the translation matrix works as follows:</p>
<p>\[\begin{bmatrix} 1 &amp;&amp; 0 &amp;&amp; 0 &amp;&amp; T_x \\ 0 &amp;&amp; 1 &amp;&amp; 0 &amp;&amp; T_y \\ 0 &amp;&amp; 0 &amp;&amp; 1 &amp;&amp; T_z \\ 0 &amp;&amp; 0 &amp;&amp; 0 &amp;&amp; 1 \end{bmatrix} \times \begin{bmatrix} x \\ y \\ z \\ 1 \end{bmatrix} = \begin{bmatrix} x + T_x \\ y + T_y \\ z + T_z \\ 1 \end{bmatrix}\]</p>
<p>(We have to add a fourth element in order to make these matrices work)</p>
<p>Nothing explains the concept better than a piece of code. Since all of the transformation matrices we use in this section are 4 by 4 matrices, let's define a <code>Matrix4x4</code> class for this use and add methods for creating different transformation matrices:</p>
<pre><code class="language-python=">class Matrix4x4:
    def __init__(self, rows):
        self.rows = rows

    @staticmethod
    def translate(offset: Vec3D):
        return Matrix4x4([
            [1, 0, 0, offset.x],
            [0, 1, 0, offset.y],
            [0, 0, 1, offset.z],
            [0, 0, 0, 1]
        ])
    
    def apply(self, vec: Vec3D):
        # ...

</code></pre>
<p>Now, here is an interesting fact about transformation matrices: because of the <em>Associative Property of Multiplication</em> of matrices (\(A \times (B \times C)=(A \times  B) \times C\)), they combined with each other, resulting in new 4x4 transformation matrices that behave as if each matrix is applied to the vector independently. This literally means that you can compress infinite number of transformation matrices into a single matrix. As an example, if you multiply two translation matrices which move a point by \((T_{x_1},T_{y_1},T_{z_1})\) and \((T_{x_2},T_{y_2},T_{z_2})\) respectively, you will get a new translation matrix that moves a point by: \((T_{x_1} + T_{x_2},T_{y_1} + T_{y_2},T_{z_1} + T_{z_2})\).</p>
<p>Transformation matrices are not limited to moving points by an offset. There are transformation matrices for rotating objects around different axis too!</p>
<p>\[R_x(\theta) = \begin{bmatrix}
1 &amp;&amp; 0 &amp;&amp; 0 &amp;&amp; 0 \\
0 &amp;&amp; cos(\theta) &amp;&amp; -sin(\theta) &amp;&amp; 0 \\
0 &amp;&amp; sin(\theta) &amp;&amp; cos(\theta) &amp;&amp; 0 \\
0 &amp;&amp; 0 &amp;&amp; 0 &amp;&amp; 1
\end{bmatrix}\]</p>
<p>\[R_y(\theta) = \begin{bmatrix}
cos(\theta) &amp;&amp; 0 &amp;&amp; -sin(\theta) &amp;&amp; 0 \\
0 &amp;&amp; 1 &amp;&amp; 0 &amp;&amp; 0 \\
sin(\theta) &amp;&amp; 0 &amp;&amp; cos(\theta) &amp;&amp; 0 \\
0 &amp;&amp; 0 &amp;&amp; 0 &amp;&amp; 1
\end{bmatrix}\]</p>
<p>\[R_z(\theta) = \begin{bmatrix}
cos(\theta) &amp;&amp; -sin(\theta) &amp;&amp; 0 &amp;&amp; 0 \\
sin(\theta) &amp;&amp; cos(\theta) &amp;&amp; 0 &amp;&amp; 0 \\
0 &amp;&amp; 0 &amp;&amp; 1 &amp;&amp; 0 \\
0 &amp;&amp; 0 &amp;&amp; 0 &amp;&amp; 1
\end{bmatrix}\]</p>
<h3 id="camera-matrix"><a class="header" href="#camera-matrix">Camera matrix</a></h3>
<p>Recall that we move/rotate the world around us instead of placing a camera in an arbitrary position rotation, there is a shortcut way for transforming the world as if a camera at \(\vec{P}\) is looking at a target \(\vec{T}\), and its upper-side is pointing at \(\vec{U}\). This matrix can be created as follows:</p>
<p>\[T = \begin{bmatrix}
1 &amp;&amp; 0 &amp;&amp; 0 &amp;&amp; 0 \\
0 &amp;&amp; 1 &amp;&amp; 0 &amp;&amp; 0 \\
0 &amp;&amp; 0 &amp;&amp; 1 &amp;&amp; 0 \\
-P_x &amp;&amp; -P_y &amp;&amp; -P_z &amp;&amp; 1
\end{bmatrix}\]</p>
<p>\(F = normalize(T - P)\)</p>
<p>\(R = normalize(U \times F)\)</p>
<p>\(U = F \times R\)</p>
<p>\[O = \begin{bmatrix}
R_x &amp;&amp; U_x &amp;&amp; F_x &amp;&amp; 0 \\
R_y &amp;&amp; U_y &amp;&amp; F_y &amp;&amp; 0 \\
R_z &amp;&amp; U_z &amp;&amp; F_z &amp;&amp; 0 \\
-P_x &amp;&amp; -P_y &amp;&amp; -P_z &amp;&amp; 1
\end{bmatrix}\]</p>
<p>Then the look-at matrix \(L\) can be calculated as follows:</p>
<p>\(L = O \times T\)</p>
<h3 id="the-magical-matrix"><a class="header" href="#the-magical-matrix">The magical matrix</a></h3>
<p>The perspective law says that the distance between 2 points look less when the points get farther of our eyes. There is a magical transformation matrix, called the <em><strong>perspective</strong></em> transformation matrix, which applies this effect for us:</p>
<p>\[\begin{bmatrix}
\frac{1}{tan(\frac{FOV}{2})a} &amp;&amp; 0 &amp;&amp; 0 &amp;&amp; 0 \\
0 &amp;&amp; \frac{1}{tan(\frac{FOV}{2})} &amp;&amp; 0 &amp;&amp; 0 \\
0 &amp;&amp; 0 &amp;&amp; \frac{-(Z_{far} + Z_{near})}{Z_{far} - Z_{near}} &amp;&amp; \frac{-2 Z_{far} Z_{near}}{Z_{far} - Z_{near}} \\
0 &amp;&amp; 0 &amp;&amp; -1 &amp;&amp; 0
\end{bmatrix}\]</p>
<p>Where \(FOV\) is field-of-view in radians (Normally \(\frac{\pi}{4}\)), \(a\) is the aspect ratio (Your screen width divided by height), and \(Z_{near}\) and \(Z_{far}\) the closest and farthest objects you can see in the rendered image.</p>
<p>Assuming the output of this multiplication is \((x,y,z,w)\), by dividing the \(x\) and \(y\) components by \(w\), you will get a pair of numbers between \(-1\) and \(1\), which tell you where on the computer screen should this point be rendered. We can map these numbers to points on screen with resolution \(W \times H\):</p>
<p>\(P=(W\frac{\frac{x}{w}+1}{2},H\frac{\frac{y}{w}+1}{2})\)</p>
<h3 id="3d-cube"><a class="header" href="#3d-cube">3D Cube</a></h3>
<p>With the tools we created in the previous sections, we are now able to render a simple 3D cube. Each side of a cube is a square, and therefore consists of two triangles. We will be coloring each side of the cube with a unique color, so that sides are distinguishable with each other.</p>
<p>First, we will need a data structure for storing 3D shapes. Our data structure will be storing the 3D triangles making that object. Let's create a Python class for this purpose and call it <code>Mesh</code>. We will also implement different static-methods generating Mesh objects for different 3D shapes. Let's start with a simple cube-builder:</p>
<pre><code class="language-python=">class Mesh:
    def __init__(self, trigs):
        self.trigs = trigs

    @staticmethod
    def cube(pos: Vec3D, size: Vec3D):
        return Mesh(
            [
                Vec3D(pos.x, pos.y, pos.z), Vec3D(pos.x + size.x, pos.y, pos.z), Vec3D(pos.x, pos.y + size.y, pos.z), 
                Vec3D(pos.x + size.x, pos.y, pos.z), Vec3D(pos.x, pos.y + size.y, pos.z), Vec3D(pos.x + size.x, pos.y + size.y, pos.z),
                Vec3D(pos.x, pos.y, pos.z), Vec3D(pos.x + size.x, pos.y, pos.z), Vec3D(pos.x, pos.y + size.y, pos.z + size.z), 
                Vec3D(pos.x + size.x, pos.y, pos.z), Vec3D(pos.x, pos.y + size.y, pos.z), Vec3D(pos.x + size.x, pos.y + size.y, pos.z + size.z),
                # TODO
            ]
        )
</code></pre>
<h3 id="barycentric-coordinates"><a class="header" href="#barycentric-coordinates">Barycentric coordinates</a></h3>
<p>In the previous section, we saw how to draw a boring 3D cube with each side filled with a single color. Sometimes you'll want to use an image instead of a plain color on the sides of your object.</p>
<p>Putting image textures on a triangle is a straightforward process: when drawing the 2D triangle, for each of the pixels you are putting on the screen, you must somehow calculate the respective location on an image that the color should be fetched from.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="think"><a class="header" href="#think">Think!</a></h1>
<h2 id="yins-and-yangs"><a class="header" href="#yins-and-yangs">Yins and Yangs</a></h2>
<p>Years ago when I was a high-school student, once our Chemistry teacher wanted take an oral quiz from us. He randomly chose a student, brought him to the blackboard and asked him an unusual question. Why does a proton has positive electrical charge, while an electron has negative electrical charge? Why isn't it the other way round?</p>
<p>The question has a fairly simple answer, negativity and positivity are merely names assigned to these primitive particles, so that we can analyze their behaviors. The question is like asking why humans with male reproductive systems are called men, while humans with female reproductive systems are called women? The student got confused and couldn't answer the question anyway. I still adore that teacher for asking these kind of meta-questions, because sometimes, learning is not all about memorizing things.</p>
<p>Genders and electrical charges are not the only dualities in our universe. In fact, we have infinite concepts in our unverse that has duals. Good and bad, happiness and sadness, light and dark, love and hate, forward and backward, angel and devil, heaven and hell, or even zeros and ones in our computers, they are all examples of dualities.</p>
<p>In many of these duals, one thing refers to the presence of something while the other things refers to the absence of that thing. In context of zeros and  ones, we can say one refers to existence of some quantity while zero defines absence of it.</p>
<p>There is a famous saying, that love and hate are two sides of the same coin. In fact, all duals are actually the sides of a single coin. A coin would not exist if it didn't have two sides. That's also true for all other duals. Happiness wouldn't exist if there wasn't any sadness. Positive numbers wouldn't exist if there weren't any negative numbers (If we didn't have negative numbers, our algebra would become bugos).</p>
<p>Here are some other coin samples and their analogical sides!</p>
<ul>
<li>Data is the coin, zeros and ones are its sides.</li>
<li>Feeling is the coin, happiness and sadness are its sides.</li>
<li>Ethics is the coin, good and bad are its sides.</li>
<li>Emotion is the coin, love and hate are its sides.</li>
</ul>
<p>You can see that many of these interesting phenomena emerge when we try to pull &quot;numbness&quot; from two sides and break it into into two pieces that when come together again, they become numb again. (E.g You feel numb when you are neither happy or sad or you get zero when you add the negative (dual) of a number to itself).</p>
<p>Some of these halvenings are conceptual, meaning that they are not something emerged in our universe like protons and electrons, or women and men. And example is negative and positive numbers, or real and imaginary numbers. We can somehow argue that negative and positive numbers are things that exist even if our universe does not exist (Or can't we? Nobody knows that at least).</p>
<p>And some of them are reflections of these conceptual Yin and Yangs. The fact that some living creatures have genders only emerged after millions of years of evolution. In fact many living creatures did not have genders and they split into two only after evolution decided to mimick duality, maybe because duality is good.</p>
<p>A hard, solid piece of rock is a creature that perhaps doesn't experience any of the human feelings. A rock doesn't fall in love, or become happy or sad. A rock will experience no pain, doesn't need to breath and eat to survive, you might think that a rock has a wonderful life (And in some ways, it has).</p>
<p>A rock's luckiness perhaps partly comes back to the fact that it has a fairly simple structure. If you study the molecular structure of a rock, you will see that a rock is built of a limited set of atoms, orderly placed along each other, which makes it a very hard break. A human being on the other hand has a much more complicated structure, and we can't see the perfect atomical ordering of a rock in a human body too. While a rock has a wonderful life, its life is very boring (From the viewpoint of an observer), a human life on the other hand, despite having sadness, pain and suffer, is much more interesting and worth living. Nature's goal has never been to build a long-lasting life, without any happiness and pain like a rock, but to build a life that maximizes <em><strong>interestigness</strong></em>.</p>
<p>You might now already know that I'm going to talk about one of the most interesting laws of physics, the second law of thermodynamics. This law was first discovered by Sadi Carnot, the french Physicist, who discovered that you can't build a motor engine that is able to convert 100% of the heat energy into mechanical work, and some of the energy will always be wasted. In other words, there is a efficiency limit in a system that converts heat into mechanical work. The same law can be expressed in other ways too, for example, you can't build a refrigerator (Or an air conditioner) that is able to decrease the temperature of a closed area, without disposing a higher heat (Higher than the amount reduced in the closed area) outside that area.</p>
<p>Heat is some kind of chaos and disorder in atoms. When atoms take energy, they start to move in directions in a chaotic way. The more they move, the hotter they become. We can measure how chaotic the elements of a system (E.g. the atoms inside a closed area) are, and call it the Entropy of that system.</p>
<p>Given the definition of Entropy, we can redefine the second law of thermodynamics in another words: <em><strong>The entropy of the universe always increases.</strong></em> I.e the sum of disordered-ness of all elements in our universe always gets higher, which again means, I can't decrease the heat in my room in a sunny day without generating even more heat into the universe. You might now think that we are making the earth warmer by building air conditioners, but the truth is the heat is radiated into the universe!</p>
<h2 id="our-path-towards-artificial-general-intelligence"><a class="header" href="#our-path-towards-artificial-general-intelligence">Our path towards Artificial General Intelligence</a></h2>
<p>Here we are going to talk about a philosophical approach of building consciousness in computers.</p>
<p>So we have been doing years and years of research on things so called Artificial Intelligence and Machine Learning, but what I'm talking about here is Artificial General Intelligence, something more than a multilayer regression model used for classifying and prediction.
Perhaps the reason we have had a giant progress in development of Machine Learning models is all about money. These things are useful in the world we live in, we can build self-driving cars, smart recommender systems and ...
We can't just build a business out of a human-level intelligent system. (Edit: When I wrote this paragraph, LLMs were not as sophisticated as they are today! Things are very different now)</p>
<h3 id="learning-is-not-enough-genetic-matters"><a class="header" href="#learning-is-not-enough-genetic-matters">Learning is not enough, genetic matters</a></h3>
<p>You can try teaching Kant Philosophy or General Theory of Relativity to your dog, but I bet it would be disappointing. The mere ability to learn is not enough, the way a brain is wired matters, and that only changes through what we call evolution.</p>
<h3 id="biological-simulation-isnt-the-right-path"><a class="header" href="#biological-simulation-isnt-the-right-path">Biological simulation isn't the right path</a></h3>
<p>Although researching on biological side of things could be helpful, but doing it excessively could </p>
<h3 id="we-are-so-close-to-agi"><a class="header" href="#we-are-so-close-to-agi">We are so close to AGI!</a></h3>
<p>You can hear people saying that our computers can't even simulate the brain of a bee.
Humans are smart, nature is dumb, the only thing that is making nature superior than us in engineering self-aware creatures is its vast ability to experiment different random things. Nature can create amazing stuff, but nature is not good at optimizing things. Think of it this way: </p>
<h3 id="the-environment"><a class="header" href="#the-environment">The Environment</a></h3>
<p>You want your lovely artificial creature to learn and do amazing things by himself? The first step is to give him the opportunity to do so! How can you expect a chatbot to magically understand the concept of self-awareness without giving it the chance to explore the world and distinguish himself with others?
Humans are impressive and amazing, but the environment that was complex (yet not overly complicated) and creative enough that gave organisms the opportunity to evolve to the level of human mind is just brilliant. It's not about how to build a brain, but more about how to build an appropriate <strong>environment</strong> where a brain can evolve.</p>
<h2 id="lets-act-like-a-god"><a class="header" href="#lets-act-like-a-god">Let's act like a God</a></h2>
<p>The very first thing we need for creation of a self-aware creature, is a <em><strong>goal</strong></em>. Simplest form of a goal is <em><strong>survival</strong></em>, which simply means, to exist. In order to make existence a goal, we need to put concepts and things which harms the existence of that creature. We can make the creature dependent on some concept and intentionally take it away from him. Let's call that concept:</p>
<p><em>Look, but don't touch. Touch, but don't taste. Taste, but don't swallow...</em></p>
<h3 id="we-cant-afford-infinite-randomness"><a class="header" href="#we-cant-afford-infinite-randomness">We can't afford infinite randomness</a></h3>
<p>The infinite monkey theorem states that a single monkey randomly hitting the keys of a keyboard for an infinite amount of time can write any given text, even complete works of Shakespear. But our computer resources, as opposed to the atoms in our universe, is limited. So we can't build intelligence by bruteforcing simulated atoms in a simulated world!</p>
<h3 id="death-genes-weapon-for-survival"><a class="header" href="#death-genes-weapon-for-survival">Death, gene's weapon for survival</a></h3>
<p>There is no reason for a cell, organism or creature to get old and die, as soon as in some part of its code, it is programmed to restore itself by consuming the materials around him (aka food). But most of the animals die (There are some exceptions, some kind of Marjan in Japan never dies by aging), why that happens?
Paradoxically, the death phenomenon can be an important reason why human-level intelligence exists!
Only the genes who die after sometime, will survive.
The population will boom in an unexpected way and that could lead to the extinction of that specy.</p>
<p>Charles Darwin was always wondering why depression exists.</p>
<h3 id="consciousness-is-a-loop"><a class="header" href="#consciousness-is-a-loop">Consciousness is a loop</a></h3>
<p>There are several evidences supporting the idea, that consciousness is the result of a loop in our nervous system, created during the evolution. Simple creatures do not have it, and the loop gets stronger and stronger when we reach to homo-sapiens. A loop in the input/output gateways of our brain make the &quot;thinking of thinking&quot; phenomenon possible.</p>
<p>People with schizophrenia cannot distinguish between feedback inputs and environmental inputs, so they may hear sounds, that do not exist in real world, driving them crazy.  Thinking is like talking without making sounds, and redirecting it back to your brain without hearing it. A healthy brain would expect to hear a sound whenever it talks. Whenever this expectation is somehow broken, the brain cannot recognize if the voice it is hearing is external or it is somebody else inside his brain. It is kind of brain's failure in removing its own voice's echo.</p>
<h3 id="how-to-experiment-self-awareness"><a class="header" href="#how-to-experiment-self-awareness">How to experiment self-awareness?</a></h3>
<p><em>In an experiment known as the &quot;rouge test,&quot; mothers wiped a bit of rouge on the noses of their children and placed them in front of a mirror. Before 15 months, children look at the reflection and see a red spot on the nose in the mirror, but they don't realize that the red spot is on their own nose. When children are between 15 and 24 months, they begin to realize that the reflection they see is their own, and they either point to the red nose or try to wipe away the rouge. In other words, they understand that the reflection in the mirror is more than a familiar face–it is their own face.</em></p>
<h3 id="last-step-abstract-thinking"><a class="header" href="#last-step-abstract-thinking">Last step, abstract thinking</a></h3>
<p>Your creature is now able to find food, escape from dangers, communicate with others and be self-aware. Congratulations! You just built a dog! So what's next? What makes homo-sapiens different with ordinary mammals? People say its our ability to think about things that do not exist. 
Abstract Thinking isn't a MUST in our world to survive (That's why most animals can't write poems or do math in order to survive), but having it happened to be extremely helpful. Abstract Thinking helped us to unite under the name of </p>
<h2 id="the-game-of-life"><a class="header" href="#the-game-of-life">The Game of Life</a></h2>
<p>The Game of Life is a very simple environment and set of rules in which creatures and evolve. It was created by the famous mathematician, John Horton Conway to demonstrate, as its name suggests, how a living creature can evolve in a simple environment with simple rules. The model is straightforward. It is a two-dimensional infinite plane of squares, in which each square can be either on or off. Conway's artificial world has 4 rules:</p>
<ol>
<li>Any live cell with fewer than two live neighbours dies, as if by underpopulation.</li>
<li>Any live cell with two or three live neighbours lives on to the next generation.</li>
<li>Any live cell with more than three live neighbours dies, as if by overpopulation.</li>
<li>Any dead cell with exactly three live neighbours becomes a live cell, as if by reproduction.</li>
</ol>
<p>The state of the world in each timestamp in Conway's Game of Life is purely dependent on previous state of the game.</p>
<h2 id="evolution-is-decentralized"><a class="header" href="#evolution-is-decentralized">Evolution is decentralized</a></h2>
<p>Humans have always had the dream of replicating themselves by building creatures that have the intellectualual abilities of a human (Or even beyond). You can see how much we fantasize about human-made intelligence in the books, paintings, movies and etc.</p>
<p>The struggles in building artificial creatures has a long story, but the very first recorded design of a humanoid robot was done in around 1495 by the famous italian polymath, Leonardo Da Vinci.</p>
<p>If you are here to learn about artificial intelligence algorithms, I’m afraid to say you are in the wrong place. We are mostly going to learn about biological inspired algorithms for reaching AGI, because I believe nature has the answers for most of the questions already.</p>
<p>Long story short, interesting things can emerge as a result of many things gathering together, making “complex” system. People have written many books in this matter, in order to amaze you by the fact that intelligence can evolve by connecting many simple things to each other, but here I assume that you are already amazed and want to know how to actually build those stuff? </p>
<p>I would like to remind you the first chapter, where we claimed that interesting things can happen when cause and effect chains of the same type are connected together. That's also the building block of a computer, a lot of logic gates connect together to cause desired behaviors. Interestingly, a human/biological brain is also similar to a logical circuits and digital computers in some ways. A lot of smaller units called neurons are connected together, leading to behaviors we typically call intelligence. There is a huge difference between a digital circuit and a biological brain though. A biological brain is made through the process of evolution, while a digital computer is carefully designed and made by a human, baked on pieces of silicone. When you design a digital computer, you exactly know what you want from it. You want it to make your life easier by running calculations and algorithms that take thousands of years when done by hand. When you do know what you exactly want from something, you can organize it into pieces, where each piece does one and only one independent thing very well, and then connect the solutions of subproblems together, solving the original problem. In case of a digital computer, the subproblems are:</p>
<ul>
<li>Storing data -&gt; FlipFlop circuits</li>
<li>Doing math -&gt; Adder circuits</li>
<li>Running instructions -&gt; Program Counters</li>
<li>...</li>
</ul>
<p>The fact that the original solution is a combination of solutions of subproblems, means that the solution does not have a symmetric structure. By symmetric, I mean you can't expect the part that solves problem A to be also able to solve problem B. You can't expect a memory-cell to be able to add two numbers. Although they both are logical circuits that accept electrical causes as inputs and produce electrical effects as outputs (And thus they can connect to each other), they have whole entirely different structures.</p>
<p>As humans, it is difficult for us to discover and design decentralized solutions for problems, while it is easy for us to break the problem into subproblems, and find solutions for the subproblems instead.</p>
<p>Interestingly, it's completely the way around for the nature. It's much easier for the nature to design decentralized solutions for the problems, but it's hard for it to break the problem into subproblems, and solve the original problem by solving the subproblems.</p>
<p>Perhaps these are all the reasons why biological brains have very solid, symmetrical structures with complex and magical behaviors and why digital computers are very organized and easy to analyze. I would like to call biological brains and digital computers as dynamic brains and static brains respectively.</p>
<p>Let's define a static brain as a network of gates that are static and do not change their behaviors over time. While a dynamic brain is a network of gates in which the gates themselves can change their behavior and turn into other gates. A static brain is a well organized brain designed by an intelligent creature, in which each part does exactly one thing and cannot change its original behavior when needed (E.g An AND gate cannot change into an OR gate), while a dynamic brain is a network of general-purpose gates evolved by the nature to solve more general problems (E.g. maximizing a goal, like survival, pleasure, etc).</p>
<p>An AND gate inside a computer can only act as an AND gate. It can't change itself to an OR gate when needed. A structure like this may seem boring in the first place, since it can only do one thing and can't change its behavior over time (The neurons/gates in a biological brain can transform, leading to different behaviors). But we can actually bring some flexibility and ability to learn by adding a separate concept known as a memory, which can contain a program and an state. The static circuit's only ability is to fetch an instruction from the memory, and change the state of the system from A to B, per clock cycle. The system's ability to learn comes from it's ability to store an state.</p>
<p>In a dynamic brain on the other hand, the learning can happen inside the connections. There isn't a separate module known as memory in a dynamic brain, but the learning happens when the connections between the neurons and the neurons themselves transform. If we are trying to build an artificial general intelligence, it might make more sense to try to mimick the brain instead of trying to fake intelligence by putting conditional codes that we ourselves have designed.</p>
<p>Unfortunately, we are not technologically advanced enough to build dynamic brains, but we can emulate a dynamic brain inside an algorithm that can run on a static brain. The dynamic gates will be imaginary entities inside a digital memory that can trigger other imaginary gates.</p>
<h2 id="tunable-gates"><a class="header" href="#tunable-gates">Tunable gates</a></h2>
<p>In order to have a solid and symmetric brain, which is able to learn without losing its uniform shape, we'll need cause/effect gates that are general purpose and can change their behavior.</p>
<p>We can model and-gate as a continuous function on floating point values! We can design a function such that returns 0 by default and approaches 1 only when both its input value are close to 1.</p>
<p><img src="assets/gpgate.png" alt="A general-purpose gate which can switch its behavior to AND and OR based on a parameter" /></p>
<p>Why modelling a gate as a floating point function is beneficial for us? Because we can take derivative of a continuous function!</p>
<p><img src="assets/neuron.png" alt="A more advanced and tunable general purpose gate, a neuron" /></p>
<p>Once upon a time, two nobel prize winners were studying brain cells 1873</p>
<h3 id="myserious-black-boxes"><a class="header" href="#myserious-black-boxes">Myserious black boxes</a></h3>
<p>Neural networks seem to be blackboxes that can learn anything. It has been proven that they can see, understand or even reason about stuff. Neural Network are known to be <em>universal function approximators</em>. Given some samples of inputs/outputs of a function, neural networks may learn that function and try to predict correct outputs, given <em><strong>new inputs</strong></em>, inputs they have never seen before.</p>
<p>Before feeding a neural network your input data, you have to convert it into numbers. You can encode them anyway you want, and then feed them to a neural network (Which will give you some other numbers), and you may again iterpret the numbers anyway you want, and you can make the network &quot;learn&quot; the way you encode/decode data and try to predict correct outputs given inputs.</p>
<p>Some example encodings:</p>
<ul>
<li>Given the location, area and age of a house, predict its price</li>
</ul>
<p>There are many ways you can encode a location into numbers:</p>
<ol>
<li>Convert it to two floating point numbers, longitude and latitude.</li>
<li>Assume there are \(n\) number of locations, feed the location as a \(n\) dimensional tuple, where \(i\)th elements shows how close the actual location is to the predefined locaiton.</li>
</ol>
<p>The area/age could also be fed:</p>
<ol>
<li>Directly as a number in \(mm^2\) or years</li>
<li>Interpolated between 0 to 1 (By calculating \(\frac{area}{area_{max}}\))</li>
</ol>
<p>And just like the way we design an encoding for the inputs, we may also design a decoding algorithm for our output. After that, the neural network itself will find a mapping between input/output data based on the way we encode/decode our data.</p>
<p>Now, one of the most important challenges in designing neural networks that actually work, is to find a good encode/decode strategy for our data. If you encode/decode your data poorly, the network may never learn the function, no matter how big or powerful it is. For example, in case of location, it's much easier for a neural network to learn the location of a house given a longitude/latitude!</p>
<h3 id="language"><a class="header" href="#language">Language</a></h3>
<p>Large Language Models are perhaps the most important invention of our decade (2020s). LLMs are impressive but they are still using a technology we have known and using for decades, so how we didn't have them before? There are 2 important</p>
<ol>
<li>We didn't know a perfect encoding/decoding strategy for text data</li>
<li>We didn't put enough hardware for training language models</li>
</ol>
<h2 id="gate-layers"><a class="header" href="#gate-layers">Gate layers</a></h2>
<h2 id="computation-graphs"><a class="header" href="#computation-graphs">Computation graphs</a></h2>
<h2 id="different-layers"><a class="header" href="#different-layers">Different layers</a></h2>
<p><strong>Embedding</strong></p>
<p>An embedding layer is basically a array which you can access its elements. It's often used for converting words/tokens into \(k\)-dimensional vector of numbers. An embedding layer is always put as the first layer in a network, since its inputs are integer indices to elements of a table.</p>
<ul>
<li>Propagation: <code>Y=T[X]</code></li>
<li>Backpropagation: <code>dT[X]/dX += delta</code></li>
</ul>
<p><strong>MatMul</strong></p>
<p>Let's say we have \(n\) neurons in a layer, each accepting the outputs of the \(m\) neurons in the previous layer. The neurons in the next layer are each calculating a weighed sum of all the neurons in the previous layer. Looking closely, you can see that the operation is not very different with a simple matrix multiplication!</p>
<p>Matrix multiplication is the most primitive layer used in neural networks. You use a matrix-multiplication layer when you have a layer of neurons where each neuron's input is the weighed sum of all outputs of previous neurons.</p>
<ul>
<li>Propagation: <code>Y=MX</code></li>
<li>Backpropagation: <code>dY/dM += X</code> and <code>dY/dX += M</code></li>
</ul>
<p><strong>ReLU</strong></p>
<p>ReLU is an activation function to provide non-linearty in a Neural-Network. It's a better alternative for vanilla sigmoid function, since the sigmoid function's closeness to zero can decrease the training speed a lot.</p>
<ul>
<li>Propagation: <code>Y=X if X &gt; 0 else 0</code></li>
<li>Backpropagation: <code>dY/dX += 1 if X &gt; 0 else 0</code></li>
</ul>
<p><strong>LayerNorm</strong></p>
<p>LayerNorm is a creative approach for fighting with a problem known as vanishing-gradients. Sometimes when you put plenty of layers in a network, a slight change in the first layers will have enormous impact in the output (Which causes the gradients of the early layers to be very small), or there are times when the early layers have very small impact on the outputs (The gradients will become very high, or explode, in this case). Layer-normalization is a technique by which you can decrease the probability of a vanishing/exploding gradients, by consistently keeping the output-ranges of your layers in a fixed range. This is done by normalizing the data flowing through the layers through a normalization function.</p>
<p>The layer accepts a vector of floating point numbers as input and gives out a vector with same size as output, where the outputs are the standardized version of inputs.</p>
<p><strong>Softmax</strong></p>
<p>Softmax layer is used to convert the outputs of a layer into a probability distribution (Making each output a number between 0 to 1, where sum of all outputs is equal with 1).</p>
<p>\(Y_i = \frac{e^{X_i}}{e^{X_0}+e^{X_1}+\dots+e^{X_{k-1}}}\)</p>
<p>In a softmax layer, each output element depends on the output of all neurons in the previous layer, therefore, the derivative of a softmax layer, is a matrix, so we have to calculate its Jacobian!</p>
<p><strong>Mask</strong></p>
<p><strong>CrossEntropy</strong></p>
<p>CrossEntropy is a strategy for calculating the error of a neural network, where. A CrossEntropy layer accepts a probability distribution as its input, therefore a cross-entropy layer comes after a Softmax layer. In a cross-entropy layer, error is minimized when the output probability of the desired output is 1 and all other outputs are zero. In this scheme, we expect the error of the network to be maximized when the output of the desired neuron is 0, and to be minimized when the output of that neuron is 1. Such behavior can be obtained with a function like \(\frac{1}{x}\) or \(-log(x)\)!</p>
<p>A cross-entropy layer accepts a probability distribution (A bunch of floating point numbers) as input, and produces a single floating point number, representing the error of the network, as its output. The error is defined as:</p>
<p>\(E=-log(X[t])\)</p>
<p>where \(T\) is the index of the desired class. When \(X[t]\) is 0, the error is \(\inf\), and when \(X[t]\) is 1, the error is \(0\). You might first think that we have to consider the outputs of other neurons too, when calculating the error of the network (E.g, we have to somehow increase the error, when the elements other than the one with index \(t\) are not zero, but this is not needed! Assuming that the input to an cross-entropy layer is a probability distribution, forcing the probability of the desired element to become 1, forces the probability of all other non-desired elements to become 0, <em>automatically</em>)</p>
<p>Such a strategy for calculating the error of the network forces the network to learn to select a single option among a set of options. Examples of such use cases are:</p>
<ul>
<li>Given a 2D array of pixels, decide if there is a cat, dog, or a human in the picture (An image classifier)</li>
<li>Given an array of words, decide what word is the next word (A language-model)</li>
</ul>
<h2 id="language-1"><a class="header" href="#language-1">Language</a></h2>
<h2 id="vision"><a class="header" href="#vision">Vision</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="trust"><a class="header" href="#trust">Trust!</a></h1>
<p>I want to tell you a fascination fact about baby humans. Until some age, they can’t distinguish between themselves and others. The concept of “me” is not evolved in their brains, and they might believe in singularity.
When they think of something, they are not aware that their mind is isolated from other minds. They think other humans know what they are thinking of. Months pass, and they start to see themselves, as a physical self, in the mirror or by looking at their organs. Babies don’t lie, because they are not aware of concept of lying and the fact that their mind is isolated and they can have “secrets”.</p>
<p>Humans have their own reasons to lie. Evolution has led us to learn lying, and hiding what we know from others. Because perhaps lying is sometimes vital for survival, and those humans who couldn’t lie, couldn’t survive as well. Evolution made us liars, and we should thank nature for that.</p>
<p>Despite its goodness, lying brings distrust. Humans can not build teams and do great stuff without having a solid foundation of trust. You might wonder why evolution has made humans untrustable, when civilization and progress can be made only in a trusted environment? Not completely sure about this, but this is my own personal guess: negative and unethical behaviors are very advanced forms of intelligence. Emergence of bad behavior is the first step of a huge intellectual progress. You can have a big group of animals (Or even stones), who happily live together, because bad behavior has not evolved in them. This might seem nice at first, but it will quickly get boring for the mother nature, because without distrust, there will be no need for more advanced forms of intelligence.</p>
<p>How do you trust someone as a human? The most naive way for us humans to trust other people is to remind ourselves of the history of their interactions with us. We can't read their minds, but we can at least predict and guess how they are going to treat us in the future by analyzing their past behaviors. In order to remember the history of someone, we need to recognize that person. As a human, we normally recognize others by looking at their face (Or hearing their voice, or even their smell).</p>
<p>Humans show different behaviors to different people. They may not talk to an stranger they way talk to their friend, as an example. It is some form of intelligence to show different behavior to different people. Not all of the species are able to to so. A bacteria for example, cannot recognize its sibling bacterias. Bacterias may have a common strategy to behave with other bacterias, either to trust all of them by default, or consider the worst case in its interactions.</p>
<p>Being able to recognize your friend is definitely something that helps the evolution of mind, so it now might seem obvious that why some species have started to be different with each other in terms of looks. Knowing that people recognize, predict and judge others' behaviors by their looks, speeches and the history they have with them, opens a lot of ways to hack it. Knowing all this, <em><strong>people started to take advantage of other people, by putting masks</strong></em>.</p>
<p>This chapter is all about secrets, honesty and trust, and also about facts, dishonesty and distrust.</p>
<p>One of the ingredients of a civilized nation, is the ability to send messages to people, even when they aren't near you. That's why humans invented writing. They started to send messages without speaking, by putting symbols on a piece of paper. That was the start of all of the problems, because now you can't see the face of the writer. How can you know that a message you have received on a letter, is really sent by your friend, or someone that has bad faith (E.g. your enemy)?</p>
<p><strong>Signatures</strong></p>
<p>I would like to define signature as a more general term: a signature is something that is special to someone/something. Your face, your voice, the way you speak, your fingerprint, your handwriting are all examples of signatures. They are special to you, and it's hard to find someone other than you that has the exact same handwriting or face or etc. Therefore, they are an important ingredient of trust. If you know your friend's handwriting well, you can catch a faker/pretender easily, because most probably he can't fake your friend's handwriting very well.</p>
<p>A signature doesn't solve all of the problems. Sometimes you might need to say something to a friend but do not want anybody else to hear it. In a face to face communication, this might be fixed easily (At some level!). You both can go into a private room, and make sure nobody else is nearby. But how can you do this when your message is on a piece of paper, and you don't want to carry the message yourself, but you want a middle man to send it for you. How can you be sure that someone won't read the letter in the middle of the way?</p>
<p>These questions are all discussed and answered in a vast field of science called Cryptography. Cryptography has a long history. Historians claim that the first use of cryptography started sometime around 1900 BC in ancient Egypt. Though the interesting thing is that, the use of cryptographic symbols back then was for people's own amusement (You know, it's fun to break codes and solve riddles). So it was somewhat a kind of art and literature, and not serious attempts in secret communication.</p>
<p>Substitution ciphers were probably the most popular way of coding the messages among ancient people. In a substituion cipher, there is a fixed one-to-one mapping that tells you which character to use instead of a character in the original message. As an example, let's say our mapping simply maps a character to its next character in the English alphabet (This is an example of a Caesar cipher). So the coded version of &quot;hello&quot; would be: &quot;ifmmp&quot;. Though this is a very simple mapping and can be easilly hacked (Someone can just try different number of character shifts until something meaningful comes out of the text).</p>
<p>A harder to crack version of a substitution cipher uses random character mappings. This method was sophisticated and seemingly-secure enough that people used it for thousands of years, until an Arab mathematician named Al-Kindi surprisingly showed that it's easy to crack (Sometime around AD 800). He invented a method called frequency analysis. In this method, we first count the number of times each letter happens in large amounts of text (From books and etc), and then build a frequency graph out of it, which shows us which letters are most/least used in the target alphabet. We then do the same thing with the cipher text, and then try to find the mapping with the help of frequency data. As an example, doing frequency analysis on the English alphabet shows us that the E (11.16%), A (8.49%) and R (7.58%) letters are the most widely used characters in English texts, while the Q (0.1962%), J (0.1965%) and Z (0.2722%) are the least used ones. By doing the frequency analysis on the target text (If the encrypted text is large enough!), if we figure out that the letter K is the most common encrypted letter, you can know with a high probability that K is the encoded version of E or A. His discovery is known to be the most important cryptanalytic advance until World War II.</p>
<p>Al-Kindi proposed that we can make frequency analysis methods less effective by using polyalphabetic substititutions. So far we have been describing monoalphabetic substitutions, which means, single characters are encrypted to single character. In a polyalplabetic substitution cipher, multiple letters are substituted with multiple letters. In order to apply frequency analysis attack on a 2-by-2 polyalphabetic substitution cipher, we have to calculate frequencies of aa, ab, ac, .., zx, zy, zz. Analysis gets much harder when the length of mappings is increased.</p>
<p>Discovering the fact that a polyalphabetic substitution cipher is hard to decode (Even with frequency analysis methods), was a huge progress in cryptography. But there is a problem: in order to encrypt and decrypt using n-character to n-character polyalphabetic substitution ciphers, we have to create a unique n-character to n-character mapping, and both the encryptor and decryptor should have a copy of it (Let's call this mapping the <em><strong>secret key</strong></em>). Assuming our target alphabet has \(\alpha\) letters, and we want to substitute \(n\) characters per block, our mapping should have \(\alpha^n\) entries. In case of English language (Without ponctuation marks), we have 26 character. Let's say we would like to use 5-character to 5-character ciphers for encryptions, then our code-book would need to have \(26^5 = 11881376\) entries, which is already a very giant secret key for a very weak encryption/decryption algorithm.</p>
<p>Let's analyze the problem by using more primitive pieces of data as our source texts. Imagine we are working with binary strings. In a binary string, smallest piece of information is stored inside a bit, which can be either 0 or 1. Our alphabet has 2 characters in a binary string so \(\alpha=2\). Now let's say we want to use a monoalphabetic cipher for encrypting/decrypting the string. so we should create a 1-bit to 1-bit mapping for our encryption algorithm. There are only two ways we can build such a mapping!</p>
<p>\(enc_1(0) = 0 \
enc_1(1) = 1\)</p>
<p>And:</p>
<p>\(enc_2(0) = 1 \
enc_2(1) = 0\)</p>
<p>This cipher is very easy to crack. All you have to do as an attacker is to read the cipher text, if it already means something, you have successfully decrypted it, otherwise just swap the bits (I.e change zeros to ones and vice versa), and then, if the source text has some meaningful information and a 1bit-to-1bit encryption algorithm is used, you will get the source text!</p>
<p>So far, we have seen that our secret keys in this scheme have 2 entries. Can we somehow compress this?</p>
<p>Instead of storing the entries for each bit (Which takes 2 bits), we can use a single bit, telling us if we should swap the bits or not!</p>
<p>Let's switch to a polyalphabetic cipher, mapping 2 character to 2 characters each time now. There exist 4 possible substitution mappings now:</p>
<p>\(enc_1(00) = 00 \
enc_1(01) = 01 \
enc_1(10) = 10 \
enc_1(11) = 11\)</p>
<p>Compressed version: \(00\)</p>
<p>\(enc_2(00) = 01 \
enc_2(01) = 00 \
enc_2(10) = 11 \
enc_2(11) = 10\)</p>
<p>Compressed version: \(01\)</p>
<p>\(enc_3(00) = 10 \
enc_3(01) = 11 \
enc_3(10) = 00 \
enc_3(11) = 01\)</p>
<p>Compressed version: \(10\)</p>
<p>\(enc_4(00) = 11 \
enc_4(01) = 10 \
enc_4(10) = 01 \
enc_4(11) = 00\)</p>
<p>Compressed version: \(11\)</p>
<p>Just like how we compressed the 1-char to 1-char mappings into a single bit, we can compress the 4 possible 2-char to 2-char mappings into two bits (Instead of passing all the 4 entries). For each bit of the compressed secret key, we just have to tell if the corresponding bit should be swapped or not.</p>
<h3 id="definition-of-secure"><a class="header" href="#definition-of-secure">Definition of secure</a></h3>
<p>The output of an encryption algorithm is known to be secure, when the output binary string looks rubbish, and totally random. Which means, there is no way you can recognize if the output is a string generated by uniformaly picking random letters, or something else.</p>
<p>Some properties of a random string:</p>
<ul>
<li>The number of each letter is equal with other letters (In case of a binary string, the number of 1s is equal with 0s)</li>
<li>...</li>
</ul>
<h3 id="xor-is-the-answer-to-everything"><a class="header" href="#xor-is-the-answer-to-everything">XOR is the answer to everything</a></h3>
<p>We can now conclude that, we don't need to store a mapping of size \(2^n\) (\(\alpha=2\) since we are working with binary strings) in order to encrypt/decrypt binary texts. We just need to store a key of size \(n\) bits, which shows us, for each bit, whether we should swap the corresponding bit or not.</p>
<p>Generating the an \(n\) bit key for a n-character to n-character encryption algorithm is as easy as throwing a coin for \(n\) times and fortunately, <strong>we all trust the coin flips already!</strong></p>
<p>Although this method can be mathematically proven to be secure (In fact, the method has a name: the one-time padding algorithm), it is not practical, and the reason is that, the keys are not reusable.
Suppose we have two messages \(m_1\) and \(m_2\), and a key \(k\) which we’ll use for encrypting both messages:</p>
<p>\(M_1 = m_1 \oplus k\)</p>
<p>\(M_2 = m_2 \oplus k\)</p>
<p>An eavesdropper cannot guess what \(m_1\) is by knowing \(M_1\), but in case he also has a second encrypted message \(M_2\), he can add these two messages together and an something interesting will happen:</p>
<p>\(M_1 \oplus M_2 = m_1 \oplus k \oplus m_2 \oplus k = (m_1 \oplus m_2) + (k \oplus k) = m_1 \oplus m_2\)</p>
<p>If you take the xor of a number with itself, they will cancel-out each other and you will get zero, so the \(k \oplus k\) part is removed from the equation and what you get is basically the sum of messages, which means: \(M_1 \oplus M_2 = m_1 \oplus m_2\), which is definitely a dangerous leak.</p>
<p>To show the importance of the leak, let’s say we want to encrypt two images using this method.</p>
<p>By adding the encrypted images together, you will get a new image which is leaking a lot of information on what the encrypted messages contain.</p>
<p>[IMG]</p>
<p>So, the obvious fact here is that, the one-time padding only works if both parties have access to an infinitely large shared random string, otherwise, they will have to exchange a new key every time they want to communicate, and the size of the key should be equal with the size of the message they want to send, which is impractical. In fact, the messages \(M_1\) and \(M_2\) are only obfuscated when the keys used to encrypt them are different:</p>
<p>\(M_1 = m_1 \oplus k_1\)</p>
<p>\(M_2 = m_2 \oplus k_2\)</p>
<p>\(M_1 + M_2 = (m_1 \oplus m_2) \oplus (k_1 \oplus k_1)\)</p>
<p>The summation of two random keys \(k_1\) and \(k_2\) (If both of the keys are totally random and independent with each other), is somehow like a new encryption key \(k_3 = k_1 \oplus k_2\) which has all the randomness properties of \(k_1\) and \(k_2\). This means that \(M_1 + M_2\) will remain encrypted:</p>
<p>\(M_1 + M_2 = (m_1 \oplus m_2) \oplus k_3\)</p>
<p>Unfortunately, our limited computer memory prevents the parties from storing inifinitely large keys, but what if we want to use the provable secure-ness of the one-time padding algorithm, by only having a single key with limited size? There are tricks we can achieve that! A very clever way is to define a function that gets a key \(k\) with a small, fixed-size, and try to expand the binary string to an arbitary length. There are several ways we can do that. A naive method (That just came to my mind while writing this, and has potentially critical security problems!) is to somehow concatenate a pseudo-random binary string to the current string, which is dependent on the current string. An obvious tool for generating such a thing (Based on what we learnt in previous section), is a hash function!</p>
<pre><code class="language-python">def expand(k, n):
    result = k
    while len(result) &lt; n:
        result += hash(result)
    return result
</code></pre>
<h2 id="signatures"><a class="header" href="#signatures">Signatures</a></h2>
<p>Finite-field elements that we just build are not the only strange kind of group elements besides regular numbers. Matrices exist too, you can define addition and multiplication operations on grids of numbers, and it will behave just as regular numbers.</p>
<p>There is also one very weird kind of group that mathematicians have discovered,</p>
<pre><code class="language-python">P = 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFEFFFFFC2F


def egcd(a, b):
    if a == 0:
        return (b, 0, 1)
    else:
        g, y, x = egcd(b % a, a)
        return (g, x - (b // a) * y, y)


def modinv(a):
    g, x, y = egcd(a, P)
    if g != 1:
        raise Exception(&quot;modular inverse does not exist&quot;)
    else:
        return x % P


class Point:
    def __init__(self, x, y):
        self.x = x
        self.y = y

    def is_zero(self):
        return (self.x is None) and (self.y is None)

    def is_valid(self):
        return self.is_zero() or (self.y**2) % P == (self.x**3 + 7) % P

    def __neg__(self):
        return Point(self.x, P - self.y)

    def __add__(self, other):
        if self.is_zero():
            return other
        elif other.is_zero():
            return self
        elif self.x == other.x and self.y != other.y:
            return Point(None, None)

        if self.x == other.x and self.y == other.y:
            m = (3 * self.x * self.x) * modinv((2 * self.y) % P)
        else:
            m = (self.y - other.y) * modinv((self.x - other.x) % P)

        x = m * m - self.x - other.x
        return Point(
            x % P,
            (-(self.y + m * (x - self.x))) % P,
        )

    def __str__(self):
        if self.is_zero():
            return &quot;Point(Inf)&quot;
        else:
            return f&quot;Point({self.x}, {self.y})&quot;

    def __repr__(self):
        return str(self)

    def __eq__(self, other):
        return self.x == other.x and self.y == other.y


G = Point(
    0x79BE667EF9DCBBAC55A06295CE870B07029BFCDB2DCE28D959F2815B16F81798,
    0x483ADA7726A3C4655DA4FBFC0E1108A8FD17B448A68554199C47D08FFB10D4B8,
)

print((G + G) + G == G + (G + G))
</code></pre>
<h2 id="electronic-cash-revolution"><a class="header" href="#electronic-cash-revolution">Electronic Cash revolution</a></h2>
<p>You may already know that I am from Iran, a mysterious country under plenty of sanctions, withholding me from doing any financial activity with people outside our isolated world. We don't have international credit-cards in Iran, and our banking system is completely isolated from the rest of the world (At least when I'm writing this book!). As a young, passionate programmer, spending his teenage years working on &quot;open-source&quot; projects, I was dreaming of getting donations for the work I was publishing online, but I couldn't find any way I could accept money from people on the internet. I couldn't even have something like a PayPal account, it was like a dead-end for me, but you know the end of the story, I found about Bitcoin. I don't remember exactly if I myself looked for an &quot;uncontrollable&quot; (Permissionless?) way of receiving money and found Bitcoin as a result, or a Bitcoin company popped onto my eyes while surfing the internet, anyways, Bitcoin was a saviour for me.</p>
<p>Cryptography was once all about encryption and authentication. It was until recently when mankind started to wonder if he can use computers to build some kind of currency that is not controlled by anyone. Many people might wonder why someone might need something like Bitcoin? Bitcoin helped me, a innocent boy, to escape the limitations I had in my country and transact money with people on the Internet. Bitcoin has been useful for me, and for me, this single usecase is enough to say that Bitcoin is awesome and is already solving problems. If you are a privileged person and have not ever faced problems like this, here might be some reasons why you might need a decentralized currency:</p>
<ul>
<li>Privacy - You don't want your government to track every small financial activity you are doing</li>
<li>Control over your money - You don't want your government to be able to block your money anytime it wants.</li>
<li>Transaction fees - You don't want to pay excessive transaction fees</li>
<li>Fault tolerance - You want a payment system that is stable and is available 24/7</li>
</ul>
<p>We need P2P technologies like Bitcoin to stay safe against governments that are (Or may become) evil (And of course, escape from limitations that are unfair!).</p>
<p>If you read about the history of electronic currencies, you already know that Bitcoin is not the first project that brought the concept on the table. There have been many different attempts by different people to build elecronic payment systems that do not rely on a centralized party. Why they failed and Bitcoin succeeded is that those prior projects were not able to solve a very important problem of such systems, and Bitcoin did. Instead of getting into the details, let's try to model a electronic currency from the ground up, given our limited knowledge, and discover the problem ourselves!</p>
<p>Since you already know some asymmetric cryptography and understand how digital signatures work, let's assume we have a few servers that are connected to each other in a network (Internet perhaps?), and are running the same software. The software is a simple key-value store, mapping public-keys to balances. If a public-key does not exist in the database, we assume the balance of that public-key is 0. Creating an account in such system does not need any interaction, you just need to generate a new private-key in your local machine, and whenever you want to know how much money you have (Which is 0 by default), you will just need to query one of those servers.</p>
<p>Transacting money in such system is as easy as creating a message, in which you clarify who you are (I.e. your public-key), how much and whome you are sending money to (I.e. destination public-key), and then signing the message with your private-key. When those servers receive and read your message, they'll try to validate and process your transaction, and update the balance sheet accordingly.</p>
<p>The transactions also include a unique identifier, so that the servers can recognize if a transatcion is already processed and should not be processed again.</p>
<p>The system works nicely, until someone tries to confuse the network by spending his money twice.</p>
<p>Let's say we have Alice, Bob and Charlie in the network, each having 5 coins according to the balance sheet. Charlie creates two transactions, sending 3 coins to Alice in one, and sending 3 coins to Bob in the other transactions. Obviously, the servers can only process one of those transaction and not both of them, since Charlie doesn't have sufficient fund.</p>
<p>This means the network will have two possible states after hearing those two transactions:</p>
<ul>
<li>State #1 Alice: 8 - Bob: 5 - Charlie: 2</li>
<li>State #2 Alice: 5 - Bob: 8 - Charlie: 2</li>
</ul>
<p>Charlie can buy a product from both Alice and Bob by sending the same 3 coins to them, effectively spending his coins twice. The problem arises due to the fact that the servers in our network can not agree on the state. Some servers may stop in the #1 state and some in #2, and both states are indeed valid. This problem is known as the Double-Spending problem, and the reason it happens is that the servers can't decide which transaction occurred first.</p>
<p>The classic approach in solving the double-spending problem is to have a central authority deciding the order of transactions. Imagine writing two cheques for Alice and Bob, spending 3 of your coins (While you only have 5). If they go to the bank and try to cash out the cheque at the exact same time, only one of the cheques will pass, since there is a single server somewhere, timestamping the transactions as they happen, disallowing a transaction to happen in case of insufficient balance.</p>
<p>The main innovation behind Bitcoin was its creative solution to the Double-Spending problem, which is called Proof-of-Work. Through Proof-of-Work, the servers in the network could agree only on a single state, without needing a centralized authority. As its inventor describe Bitcoin, Proof-of-Work is a decentralized method for &quot;timestamping&quot; transactions.</p>
<h2 id="the-most-precious-spam-fighter"><a class="header" href="#the-most-precious-spam-fighter">The most precious spam-fighter!</a></h2>
<p>Back in 1997, Adam Back, a british cryptographer and cypherpunk, invented something called HashCash. HashCash was a method people could use to fight with denial-of-service attacks (Excessive number of requests trying to get a service down). The idea was to require users to solve a moderately hard puzzle before allowing them to use the service. The solution could also be used as a spam filter (Imagine recipients only accept a mail in their inbox when a solved HashCash puzzle is attached to the mail). HashCash was assuming that we can make the life of attackers/spammers much harder, by requiring them to put significant computation resources for every request/email they make.</p>
<p>The puzzle was to find certain inputs for a hash function such that the output is below a threshold. I can't explain this better than a piece of Python code:</p>
<pre><code class="language-python">import hashlib


def h(inp):
    return int.from_bytes(hashlib.sha256(inp).digest(), byteorder=&quot;little&quot;)


MAX_VAL = 2 &lt;&lt; 256 - 1
THRESHOLD = MAX_VAL // 10000000

MY_EMAIL = b&quot;Hey, I'm not trying to spam you! :)&quot;

i = 0
while True:
    if h(MY_EMAIL + i.to_bytes(8, &quot;little&quot;)) &lt; THRESHOLD:
        print(&quot;Nonce:&quot;, i)
        break
    i += 1

</code></pre>
<p>Imagine a fair dice with 6 sides.</p>
<ul>
<li>If you want to get a 1, you must approximately roll the dice for \(\frac{6}{1}=6\) timess.</li>
<li>If you want to get a \(\leq 2\), you must approximately roll the dice for \(\frac{6}{2}=3\) timess.</li>
<li>If you want to get a \(\leq 3\), you must approximately roll the dice for \(\frac{6}{3}=2\) timess.</li>
<li>If you want to get a \(\leq 6\), you must approximately roll the dice for \(\frac{6}{3}=1\) timess.</li>
</ul>
<p>The same is true with hash functions. Hash functions are analogous to giant dices. As an exmaple the SHA-256 hash function generates outputs between \(0\) to \(2^{256}-1\). In order to get an output below \(\theta\), you will need to try different inputs (Roll the dice) for \(\frac{2^{256}}{\theta}\) times. You can roll a hash-function by &quot;slightly&quot; changing its input (In the HashCash example, we append a small piece of data to the original data and randomly change it until we get our desired output).</p>
<p>In our HashCash example, we require the email sender to &quot;work&quot; approximately as much as running SHA-256 for 1 million times!</p>
<h2 id="chaining-proofs-of-work"><a class="header" href="#chaining-proofs-of-work">Chaining proofs of work!</a></h2>
<p>Satoshi Nakamoto discovered a interesting fact about proof-of-work puzzles. After solving a proof-of-work puzzle, you can append some more data to the whole thing and try to solve the proof of work puzzle again for the new data.</p>
<p>Suppose we first find \(nonce_0\) such that: \(H(data_0 | nonce_0) &lt; \theta\). We then append \(data_1\) to the hash of old data and find \(nonce_1\) such that \(H(H(data_0 | nonce_0) | data_1 | nonce_1) &lt; \theta\)</p>
<p>Solving a proof-of-work puzzle on \(H(data_0 | nonce_0) | data_1\), not only proves that you have worked hard on commiting to \(data_1\), but also shows that you have put equal amount of work to also commit on \(data_0\), for one more time, and that is because altering \(data_0\) not only invalidates the first proof-of-work, but also the second proof-of-work. Assuming that it takes 1 minute to find an appropriate nonce for a piece of data, altering \(data_0\) would invalidate both \(nonce_0\) and \(nonce_1\), meaning that you should find the values for \(nonce_0\) and \(nonce_1\) again, requiring you two solve 2 proof-of-work puzzles, spending two minutes of your CPU time. The longer the chain is, the harder it becomes to alter older data.</p>
<h2 id="proof-of-work-on-financial-transactions"><a class="header" href="#proof-of-work-on-financial-transactions">Proof-of-Work on financial transactions</a></h2>
<p>Here is the main innovation of Bitcoin: Let's solve proof-of-work puzzles on batches of transactions, and give more priority to those transactions that more work has been done on them! If we apply the chaining trick here too, the older transactions will become harder and harder to be reverted.</p>
<h2 id="its-time-to-commit"><a class="header" href="#its-time-to-commit">It's time to commit</a></h2>
<p>Now you probably have an accurate intitution on how cryptographic hash functions work (If you are convinced that the Proof-of-Work algorithm really works). But it's also good to know the formal definition of a cryptographic hash function. A cryptographic hash function is a function that is:</p>
<ol>
<li>Collision-resistant: It's hard to find a pair of \(x\) and \(y\) where \(H(x)=H(y)\).</li>
<li>Preimage-resistant: Given \(y\), it's hard to find \(x\) where \(H(x)=y\).</li>
<li>Second-perimage-resistant: Given \(H(x_1)=y\), it's hard to find \(x_2\) where \(H(x_2)=y\).</li>
</ol>
<p>Besides generating proofs of work, there are other interesting things you can do with hash functions. In general, cryptographic hash functions let you to commit to a secret value, and reveal it later.</p>
<h3 id="cryptographic-games"><a class="header" href="#cryptographic-games">Cryptographic games</a></h3>
<p>A useful example is when you want to play the Rock/Paper/Scissors with your friend over phone. You can agree to shout out your choice simulatanously, but there is always the chance that your friend may hear your choice and make his choice based on that, always winning the game. What if you guys want to play Rock/Paper/Scissors over physical letters? It'll become much harder to prevent cheatings! Cryptographic hash functions come handy here:</p>
<ol>
<li>Alice chooses his option \(a\), but instead of revealing \(a \in {R, P, S}\), she reveals \(H(a)\).</li>
<li>Just like Alice, Bob chooses \(b \in {R, P, S}\), and reveals \(H(b)\).</li>
<li>Now both Alice and Bob know that their opponent has made his choice and commited to it, so they can reveal their choices.</li>
<li>They both will check if their opponent's choice matches with their commited value (If it doesn't, it means the opponent is cheating).</li>
<li>If everything is alright, winner is determined according to \(a\) and \(b\).</li>
</ol>
<p>There is a hack to this approach. Since the options are very limited, both Alice and Bob can pre-compute a table of all possible choices and their respective hashes. Then they'll be able to know their opponent's movement based on their commited value. We can prevent this by introducing an extra random value appended to the input of the hash function, known as a <em>salt</em>. (It's dangerous to directly store the passwords of the users in a web-application's database. It's also dangerous to store hashes of the passwords, since many users choose weak passwords and attackers may build pre-computed tables by trying many different popular passwords, just like what an attacker can do in the Rock/Paper/Scissors game we just designed, so you have probably seen that a random salt is added to the user's password before applying the hash function. The salt is stored on the database for later verifications).</p>
<p>It's nice to remember: Whenever you are designing a cryptographic protocol and would like to prevent attacks based on precomputed-tables, adding a salt is a efficient and good solution.</p>
<p>The following Python code will let you to generate commitments for participating in a cryptographic Rock/Paper/Scissors game:</p>
<pre><code class="language-python">import random, hashlib

choice = input(&quot;Choice? (R/P/S)&quot;)
assert choice in [&quot;R&quot;, &quot;P&quot;, &quot;S&quot;]

# Generate a random 16 letter alphanumeric salt
salt = &quot;&quot;.join(random.choice(&quot;0123456789ABCDEF&quot;) for i in range(16))

commit = hashlib.sha256((choice + salt).encode(&quot;ascii&quot;)).hexdigest()

print(&quot;Salt (Reveal it later!):&quot;, salt)
print(&quot;Commit:&quot;, commit)

# Reveal choice and salt later
</code></pre>
<p>After both you and your opponent have got the commitments of each other, you may now reveal your choices and respective salts. The following Python3 program may be used for finding the winner:</p>
<pre><code class="language-python">import hashlib

alice_choice = input(&quot;Alice choice? &quot;)
alice_salt = input(&quot;Alice salt? &quot;)
alice_commit = input(&quot;Alice commitment? &quot;)

if alice_choice not in [&quot;R&quot;, &quot;P&quot;, &quot;S&quot;]:
    print(&quot;Alice has made an invalid move!&quot;)

if (
    alice_commit
    != hashlib.sha256((alice_choice + alice_salt).encode(&quot;ascii&quot;)).hexdigest()
):
    print(&quot;Alice is cheating!&quot;)

bob_choice = input(&quot;Bob choice? &quot;)
bob_salt = input(&quot;Bob salt? &quot;)
bob_commit = input(&quot;Bob commitment? &quot;)

if bob_choice not in [&quot;R&quot;, &quot;P&quot;, &quot;S&quot;]:
    print(&quot;Bob has made an invalid move!&quot;)

if bob_commit != hashlib.sha256((bob_choice + bob_salt).encode(&quot;ascii&quot;)).hexdigest():
    print(&quot;Bob is cheating!&quot;)

# Winner may now be determined based on alice_choice and bob_choice!
print(&quot;Alice:&quot;, alice_choice)
print(&quot;Bob:&quot;, bob_choice)
</code></pre>
<h3 id="commiting-to-a-set-of-values"><a class="header" href="#commiting-to-a-set-of-values">Commiting to a set of values</a></h3>
<p>Not only you can commit to a single value, but you can commit to multiple values, and later prove and reveal the existence of a certain value in the set. Here is a silly cryptographic game where commiting to a set of values might be useful. Imagine I have chosen a number between 0 to 1000, and I want you to make 20 guesses on what my number is. You may take 20 random guesses and commit to it by taking the hash of a comma seperated string, containing all of your guesses. You can then reveal your guesses and I can check:</p>
<ol>
<li>If you really have only chosen 20 numbers, and not more (Just split the comma-seperated string by <code>,</code> and check its length)</li>
<li>If your guess list includes my number</li>
</ol>
<p>Now, there is problem. What if the guess list is very large? (Imagine millions of numbers). You have to reveal all of my guesses, otherwise I can't check if your commitment matches your numbers. Is there any way I can prove existence of a certain number in my list, without revealing all other numbers I have in the list? (Both for privacy and performance reasons). There is!</p>
<p>Binary trees are your best friend, any time you want to optimize the space-efficiency or computation-efficiency of something related to computer science!</p>
<p><img src="assets/merkle.png" alt="Making a tree out of the values you want to commit on!" /></p>
<h2 id="inventing-a-new-math"><a class="header" href="#inventing-a-new-math">Inventing a new math</a></h2>
<p>The math we are used to, is all about different operations you can perform on numbers. You can add them, subtract them, multiply them or divide them by each other. These operations (If you are not really into math) only make sense if the operands are number. For example, you can't add an apple to an orange, it's meaningless, because the definition of addition is meaningless in case of fruits. But let's assume it's possible, and try to invent some new kind of math for fruits. Imagine the fruits we are working with in our new math are: Apple, Orange and Banana. There are 9 different possibilies when fruits are added together (\(3 \times 3\)), and since the result of adding two fruits is also a fruit, there will be a total of \(3^9\) ways we can invent the \(+\) operation on fruits. Here is an example:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A + B</th></tr></thead><tbody>
<tr><td>Apple</td><td>Apple</td><td>Orange</td></tr>
<tr><td>Apple</td><td>Orange</td><td>Orange</td></tr>
<tr><td>Apple</td><td>Banana</td><td>Apple</td></tr>
<tr><td>Orange</td><td>Apple</td><td>Banana</td></tr>
<tr><td>Orange</td><td>Orange</td><td>Orange</td></tr>
<tr><td>Orange</td><td>Banana</td><td>Banana</td></tr>
<tr><td>Banana</td><td>Apple</td><td>Apple</td></tr>
<tr><td>Banana</td><td>Orange</td><td>Orange</td></tr>
<tr><td>Banana</td><td>Banana</td><td>Banana</td></tr>
</tbody></table>
</div>
<p>Unfortunately, the math we have just invented on fruits does not obey some of the properties we are used to when adding numbers. For example, you might expect that \(Orange + Banana\) is equal with \(Banana + Orange\), but in our new, randomly invented math, that's not the case. There are other missing features too, for example: \((Apple + Orange) + Banana\) is not equal with \(Apple + (Orange + Banana)\)! Try to redesign the \(+\) operation, so that we have the mentioned properties in our fruit-math too.</p>
<p>Here is an example of a fruit-math that perfectly obeys the mentioned laws:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A + B</th></tr></thead><tbody>
<tr><td>Apple</td><td>Apple</td><td>Apple</td></tr>
<tr><td>Apple</td><td>Orange</td><td>Orange</td></tr>
<tr><td>Apple</td><td>Banana</td><td>Banana</td></tr>
<tr><td>Orange</td><td>Apple</td><td>Orange</td></tr>
<tr><td>Orange</td><td>Orange</td><td>Banana</td></tr>
<tr><td>Orange</td><td>Banana</td><td>Apple</td></tr>
<tr><td>Banana</td><td>Apple</td><td>Banana</td></tr>
<tr><td>Banana</td><td>Orange</td><td>Apple</td></tr>
<tr><td>Banana</td><td>Banana</td><td>Orange</td></tr>
</tbody></table>
</div>
<p>Let's make our fruit-math more interesting. Addition is not the only operation we can do on numbers. We can do multiplications too. Just like additions, multiplication of fruits is also meaningless (Even more meaningless than addition!), but that's ok, just like what we did with the addition operator, we can also design a table for multiplication. There will be \(3^9\) different possible defintions for \(\times\). If we start with a random table, we will lose some of the properties \(\times\) operator has on regular numbers. In case of regular numbers, we know that \(a \times b\) is equal with \(b \times a\). There is also one very unique and important property that we have on regular numbers. \(a \times (b + c)\) is equal with \(a \times b + a \times c\). Try to design \(\times\) operator on fruits so that it obeys these properties too. You will probably reach to a table like this: </p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A * B</th></tr></thead><tbody>
<tr><td>Apple</td><td>Apple</td><td>Apple</td></tr>
<tr><td>Apple</td><td>Orange</td><td>Apple</td></tr>
<tr><td>Apple</td><td>Banana</td><td>Apple</td></tr>
<tr><td>Orange</td><td>Apple</td><td>Apple</td></tr>
<tr><td>Orange</td><td>Orange</td><td>Orange</td></tr>
<tr><td>Orange</td><td>Banana</td><td>Banana</td></tr>
<tr><td>Banana</td><td>Apple</td><td>Apple</td></tr>
<tr><td>Banana</td><td>Orange</td><td>Banana</td></tr>
<tr><td>Banana</td><td>Banana</td><td>Orange</td></tr>
</tbody></table>
</div>
<p>Since there are limited number of addition/multiplication tables that obey math rules we are used to, we can conclude that there are very few varities of math we can design for Apples, Bananas and Oranges. One clever way to easily extract new fruit-maths is to use substitute the fruits in our current tables with another permutation of fruits (E.g. change Apple-&gt;Banana, Banana-&gt;Orange and Orange-&gt;Apple). But who are we going to fool! These tables are still somehow equal with the first table, and we haven't really invented a new math! There is even a scientific word for it, the tables generated this way are actually isomorph with each other, or in other words, there exists a mapping for the elements in the first table, that migrates us to the second table!</p>
<p>Strangely, out of \(3^9.3^9\) possible ways we can invent a math for fruits (Assuming we want to fill the addition and multiplication tables), only few of them are valid and behave as expected, and all of those valid maths are isomorph with each other, meaning that effectively, we only have a single kind of math, in case we have 3 number of elements! Mathematicians refer these kind of maths as: <em><strong>Finite-fields</strong></em></p>
<p>Now imagine we use substitute Apples, Oranges and Bananas with numbers under 3 (0, 1, 2), respectively (Obviously, we will get an isomorph). Here is how the addition and multiplication tables will look like:</p>
<div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A + B</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>1</td></tr>
<tr><td>0</td><td>2</td><td>2</td></tr>
<tr><td>1</td><td>0</td><td>1</td></tr>
<tr><td>1</td><td>1</td><td>2</td></tr>
<tr><td>1</td><td>2</td><td>0</td></tr>
<tr><td>2</td><td>0</td><td>2</td></tr>
<tr><td>2</td><td>1</td><td>0</td></tr>
<tr><td>2</td><td>2</td><td>1</td></tr>
</tbody></table>
</div><div class="table-wrapper"><table><thead><tr><th>A</th><th>B</th><th>A * B</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>0</td></tr>
<tr><td>0</td><td>2</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>1</td></tr>
<tr><td>1</td><td>2</td><td>2</td></tr>
<tr><td>2</td><td>0</td><td>0</td></tr>
<tr><td>2</td><td>1</td><td>2</td></tr>
<tr><td>2</td><td>2</td><td>1</td></tr>
</tbody></table>
</div>
<p>Strangely, we can see that the addition/multiplication tables are basically just modular addition/multiplication! (I.e addition and multiplication modulo 3).</p>
<h2 id="diffie-hellman"><a class="header" href="#diffie-hellman">Diffie-Hellman</a></h2>
<p>We have two people who want to send a physical letter to each other. They can send their letters through a postman (Who unfortunately is very nosy!). They don't want the postman to read the letter. Sender and receiver both have a lock and its key that can put on the box. They can't send their keys to each other! How can the sender send privately send the letter?</p>
<ol>
<li>The sender puts the letter in the box and locks it and sends it to the receiver.</li>
<li>The receiver locks the box with his key too, and sends it back to the sender.</li>
<li>The sender opens his own lock and sends it back to the receiver.</li>
<li>The receiver may now open the box and read the letter.</li>
</ol>
<p><img src="assets/lock.png" alt="The box can be locked with two locks at the same time, needed both parties to remove their locks in order to open the box" /></p>
<h3 id="stealth-addresses"><a class="header" href="#stealth-addresses">Stealth addresses!</a></h3>
<p>The Diffie-Hellman key-exchange algorithm allows you to calculate a shared-secret between two parties, even when someone is eavesdropping your communication line. Now instead of two people, imagine there are many people participating in a similar scheme, each having their own public-key. Assume on of them wants to send a message to another one in the network, but doesn't want other people in the network to know who he wants to talk with. As a first step, the sender should broadcast his message to everyone, instead of routing it to his desired destination (Because others will know with whom the sender is communicating, even though the messages are all encrypted and private). </p>
<ul>
<li>Bob generates a key \(m\) (Master private key), and computes \(M = g^m\) (Master public key), where \(g\) is a commonly-agreed generator point for the elliptic curve.</li>
<li>Alice generates an ephemeral key \(r\), and publishes the ephemeral public key \(R = g^r\).</li>
<li>Alice can compute a shared secret \(S = M^r\), and Bob can compute the same shared secret \(S = m^R\) (Very similar to Diffie–Hellman key exchange we just discussed).</li>
<li>A new public-key can be derived for Bob: \(P = M + g^{hash(S)}\) (Elliptic-curve point addition).</li>
<li>Bob (and Bob alone, since he only knows the value of \(m\)) can compute corresponding private-key \(p = m + hash(S)\) (Scalar addition).</li>
</ul>
<p>Now, the receiver may listen to all ephemeral points broadcasted in the network and will try to see if any message is being sent to the corresponding derived public-keys, and see if someone was meaning to communicate with him. In this scheme, only the receiver is able to know that someone is communicating with him, and not anyone else.</p>
<p>[TODO]</p>
<h2 id="do-my-computation"><a class="header" href="#do-my-computation">Do my computation!</a></h2>
<p>I have always been very curious about different ways we can write programs. Object Oriented, Functional, imperative and etc, all require different kinds of thinking, and it was always exciting for me to learn new languages that introduces a new kind of thinking. Years I have been out of languages that were truly introducing a conpletely new concept, but R1CS is one of the most interesting ways you can program stuff.</p>
<p>R1CS doesn’t actually give you a set of instructions to write your program with, it is not a language at all. It’s a way you can force someone to perform the computation you desire, by solving math equations.</p>
<p>R1CS, short for Rank-1 Constraint System, is a form of math equation which has only a single multiplication among its variables.</p>
<p>Imagine I give you the following equations and ask you to find all possible x, y and z values that satisfy all the equations at the same time.</p>
<ol>
<li>\(a \times (1-a)=0\)</li>
<li>\(b \times (1-b)=0\)</li>
<li>\(a \times b=c\)</li>
</ol>
<p>Obviously, since the first and second equations are just quadratic equations, they have two roots, which are zero and one. Knowing the different possible values for a and b we can write a table for it.</p>
<div class="table-wrapper"><table><thead><tr><th>a</th><th>b</th><th>c</th></tr></thead><tbody>
<tr><td>0</td><td>0</td><td>0</td></tr>
<tr><td>1</td><td>0</td><td>0</td></tr>
<tr><td>0</td><td>1</td><td>0</td></tr>
<tr><td>1</td><td>1</td><td>1</td></tr>
</tbody></table>
</div>
<p>You can see that the table is identical with a logical and gate. We can do OR gates too, the last constraint needs to be:</p>
<p>\((1-a) \times (1-b)=(1-c)\)</p>
<p>You might think that you can’t do much by simply just multiplying and adding variables with each other, but the truth is, this particular way of representing programs is actually able to represent any program you can ever imagine. The fact that you can emulate logical gates is enough for concluding that the representation is able to emulate any kind of hardware!</p>
<h3 id="migrating-to-bit-representations"><a class="header" href="#migrating-to-bit-representations">Migrating to bit representations</a></h3>
<p>Obviously, since we can emulate logical operators through plain math operations, we can do pretty amazing stuff too, but the variables in our circuits are normally holding numerical values, and not bits. Fortunately, there are ways we can migrate a numerical variable into its bit representation, by putting constraints like this:</p>
<ul>
<li>\(a_0 \times (1-a_0) = 0\)</li>
<li>\(a_1 \times (1-a_1) = 0\)</li>
<li>\(a_2 \times (1-a_2) = 0\)</li>
<li>\(\vdots\)</li>
<li>\(a_{n-1} \times (1-a_{n-1}) = 0\)</li>
<li>\(2^0a_0 + 2^1a_1 + 2^2a_2 + \dots + 2^{n-1}a_{n-1} = a\)</li>
</ul>
<p>Assuming the original value is in the variable \(a\), given these constraints, the solver has no way but to put the bit representation of \(a\) into the variables \(a_0, a_1, \dots, a_{n-1}\).</p>
<h3 id="checking-zeroness"><a class="header" href="#checking-zeroness">Checking zeroness</a></h3>
<p>Given three two variables \(a\) and \(z\) (And a auxiallary variable \(tmp\)), we would like to check if the value of \(a\) is zero, by enforcing the value of \(z\) to be 1 in case \(a=0\) and make it \(0\) otherwise.</p>
<ul>
<li>\(z = -tmp * a + 1\)</li>
<li>\(z * a = 0\)</li>
</ul>
<p>Now, if \(a\) is not zero, \(z\) has no choice but to be zero in order to satisfy the second constraint. If \(z\) is 0, then \(tmp\) should be set to inverse of \(a\) in order to satisfy the first constraint. Inverse of \(a\) exists, since \(a\) is not zero. If \(a\) is zero, then the first constraint is reduced to \(z=1\).</p>
<h2 id="computer-programs-inside-polynomials"><a class="header" href="#computer-programs-inside-polynomials">Computer programs inside polynomials</a></h2>
<div style="break-before: page; page-break-before: always;"></div><h1 id="fly"><a class="header" href="#fly">Fly!</a></h1>
<h2 id="skip-if-you-are-poor"><a class="header" href="#skip-if-you-are-poor">Skip if you are poor</a></h2>
<p>Throughout my career in software-engineering, I had always avoided topics which involved any interactions with the Physical world (Except a short period of time when I was working on line-following robots as a high-school student). That's partly because I live in an economically poor country, where there aren't a lot of companies building cyber-physical systems (Systems composed of a software, controlling/sensing a physical thing), except when politics is involved, if you know what I mean.</p>
<p>Unlike pure software engineering, where you can never run out of characters, building software that interacts with the real-world, involves physical objects, things that you can touch and feel, and the unfortunate truth about non-imaginary objects is that, they cost money, and they can break, which means, you can't experiment as much as a software with them (Unless you are a rich engineer, having a giant laboratory inside your house, with plenty of money)</p>
<p>I have never been that rich, and I also couldn't find any company doing respectful cyberphysical projects in my country either. Therefore I have never been a real fan of a section in computer science, known as <em><strong>embedded engineering</strong></em>. You can see in this book that I'm a great fan of computer simulations though!</p>
<h2 id="new-is-always-better"><a class="header" href="#new-is-always-better">New is always better</a></h2>
<p>I named this chapter of the book as &quot;Fly&quot;, because flying is probably one of the most amazing and spiritual dreams of humans that has come to reality, and computers are one of the most important components of the flying-machines we have today. Humans could never land on moon without computers.</p>
<p>I would like to start this chapter by mentioning two of the most ambitious companies, created by the American multi-billionaire entrepreneur, Elon Musk, at the time this book is written. Tesla and SpaceX, are companies that are producing cyberphysical products, one is building self-driving cars and the other is building rockets, aiming to make humans multi-planetary species.</p>
<p>When Elon Musk started those companies, it wasn't obvious at all that they'll become successful. Who could think that a private rocket-building company could beat the government funded NASA that once put humans on the moon? That's also true for Tesla, there were plenty of automobile companies with decades of experience, even in designing electric cars, but Tesla beat them all. Besides the reason that Elon himself is one of the most ambitious people of our time, which is enough for making a risky business successful, there is a more important reason why those two companies become insanely successful: <em><strong>It's much easier to experiment new stuff when your business is still small!</strong></em></p>
<p>It's too risky for an already giant business to switch and explore new ways of building things. When companies grow, they start to become heavily beurocratical, which slows things down by a lot. That's why startups are so fast, they are small, and there is plenty of room for making mistakes. SpaceX didn't have all those boring stuff, it only had a few bright-minded people, exploring new ways of building rockets, without being scared too much of the outcomes.</p>
<p>My point is, old technology isn't always taking the best approach in doing stuff, in fact, old technology is pretty bad, because when engineers were designing the old technology, they didn't have the knowledge and experience they have right now. So it makes sense a lot to get brave and try to redesign things that were working correctly and stabely even for a long time!</p>
<h2 id="life-in-a-newtonian-world"><a class="header" href="#life-in-a-newtonian-world">Life in a Newtonian world</a></h2>
<p>Building and experimenting cyber-physical systems is going to cost you a lot, and it makes sense to check if everything is going to work as expected, before building your prototype. Since your brand-new cars/airplanes/rockets/etc are going to live in our world, they are going to obey the laws of Physics of our world. So if you are willing to simulate them before doing serious experiments, you will have to apply the laws of physics on them, in a simulated environment.</p>
<h3 id="physics-before-apple-hit-the-the-newtons-head"><a class="header" href="#physics-before-apple-hit-the-the-newtons-head">Physics before apple hit the the Newton's head</a></h3>
<p>Students nag that they would have much less to study if that damn apple never hit Newton's head, but the truth is, the science of Physics existed even before Newton formulate it in his precious works. Even if Newton never figured gravity, sooner or later, someone else would do it! So, what were the statements of &quot;Physicists&quot; before Newton, when you asked them to explain the mechanical phenomena we experience everyday?</p>
<p>Aristotle, the Greek scientist and philosopher who were living in 4th century B.C., was of the first famous scientists trying to explain the laws of motion. Surprisingly, Aristotle's laws of motion was left untouched and continued to rule physics for more than 2000 years. Galileo Galilei, the Italian polymath, was of the first people who was brave enough to make new statements about motion and to break the Aristotle's empire that ruled for so long.</p>
<p>Aristotle's law of motion states that:</p>
<ul>
<li>External forces are needed to keep an object moving</li>
</ul>
<p>Although this statement seems funny and so wrong nowadays (It's the friction that stops objects moving), it was convincing people and scientists for more than two centuries! Put yourself in the shoes of people back then, how would you formulate physics, if you had never heard the laws of physics written by Newton?</p>
<p>Another remark of Aristotle's law of motion is that, heavier objects fall faster than light objects. Nowadays we know that's not the case too, and the reason a feather falls slower than a book is merely because of air friction.</p>
<p>Although Aristotle's opinion <strong>seem</strong> right, they are <strong>not</strong> right. Aristotle's biggest mistake is that, he wasn't aware of friction forces and he was ignoring air resistance. This is known as the Aristotle's Fallacy.</p>
<p>Galielo Galilei's law of inertia states that:</p>
<ul>
<li>If you put an object in the state of motion, it will move forever if no external forces are applied on it</li>
</ul>
<p>And lastly we will reach to Newton's formulation of motion and gravity, which although is proven to be incorrect by legends like Albert Einstein, is still accurate enough to explain and predict most of the macroscopic motions happening in our universe. The physics of motions discovered by Newton is still a fundamental guide for us to build cars, airplanes and rockets that can bring humans on the moon and put satellites in the space.</p>
<p>Newton was a legend. Not only he discovered a very accurate theory for motion, he also invented (Co-invented?) a fresh mathematical tool that has made significant contributions to the other fields of science too. This field of mathermatics is known as Calculus. We explained the basica of differentiation and integration in the previous chapters, so let's jump to the Newton's laws:</p>
<p>[TODO]</p>
<p>Perhaps the most important discovery of Newton is his famous formula \(F=ma\) which explains how the force applied to an object, the mass and its acceleration are related to each other.</p>
<p>\(v=\frac{dx}{dt}\)</p>
<p>\(a=\frac{dv}{dt}\)</p>
<p>\(x=\int{\int{a.dt}}=\frac{1}{2}at^2+v_0t+x_0\)</p>
<h2 id="exciting-electronics"><a class="header" href="#exciting-electronics">Exciting Electronics</a></h2>
<p>I started to admire the joy of programming computer in very young ages, but even before that, I was a fan of toy electorical kits. I used to buy ans solder them back then. I always wanted to know how the circuit of a blinking LED works for example. Why? Because understanding them was the first step to my dream of designing the circuits of my own. Unfortunately, I couldn't find appropriate resources that could convince a kid why a circuit like that works, and how he can get creative and build circuits of his own, by putting the right components in the right places.</p>
<p>So, electronics, and the way it works, remained a secret to me for years, and one of the reasons I gave up and switched my focus on building software was that, computer programming is much easier. Even after 15 years, and multiple tries in reading different books on electronics, I'm still afraid to say that I'm still not capable of designing a circuit as simple as a blinker all by myself, without cheating from other circuits, and that's one of the reasons I decided to write this chapter; to finally break the curse and learn this complciated, yet fascinating field of science.</p>
<p>How did I do it? Well I tried reading books in this topic, but I didn't find many of them useful. All books written in this matter (Even the good ones!) were starting explaining the laws of electricity and then describing different electronical components and their usecases in separate chapters. I'm not really a fan of learning things this way.</p>
<p>Here, I'm going to explain electronic circuit design with a bottom-up approach (Just like the way we discussed other fields of computer science). We will start by learning the history of electricity and how was the first experience of humans of electricity, and then describing the ways we can generate electricty, and then we will try to build useful stuff out of electricity. (From things as simple as light bulbs to comptuer!)</p>
<p>Along the way, we will also learn about different electronic components!</p>
<hr />
<p>I would say that studying electricity is one of the most important foundations of human modernity, and just like the history of mechanical physics, electricity also has its own fascinating stories.</p>
<p>[TODO]</p>
<p>Here is one of the reasons I don't like some of the electronics tutorials out there: they will tell you exactly, what a resistor is, how it works and why it works, but they'll never tell you when and where you should put a resistor in your circuit, and how you should calculate the resistance needed, in practical examples! E.g. by only knowing the Ohm's law \(V=RI\), calculate the resistance needed to connect a 2V LED to a 5V battery!</p>
<p>Here is the golden fact many resources do not directly tell you (Or do not emphasize as much as I'm going to do!), you can assume that any electronical component (Including LEDs) that consume electricity are acting like resistors (Even a piece of wire is a resistor). If they weren't resistors, they could consume infinite electrical current, even with very low voltages.</p>
<h2 id="how-to-push-the-electrons"><a class="header" href="#how-to-push-the-electrons">How to push the electrons?</a></h2>
<p>Before jumping straight to the things you can do with electricity, it's good to know how electricity is generated. There are various ways you can get a steady stream of electrons in your circuit. Batteries for example, they give you a potential difference on their poles using chemical reactions, and unfortunately, they will run out of energy after sometime. Unlike batteries, the source of electricity we get in our homes isn't generated by chemical reactions, but is the result of spinning a magnet inside a coil of wire. You can try it yourself at home! Humans have discovered somehow that, if you move/spin a magnet inside a wire coil, you will push the electrons in the wire and will have electrical current, which is able to turn a light-source on!</p>
<p>Now, you don't need to spin that magnet by hand, you can let the nature do it for you. You can connect a propeller to the magnet, causing it to spin when wind is blown. That's in fact how wind turbines convert wind into electricity!</p>
<p>Even if you don't have wind, you can use artificially-generated wind (By burning fuel or even doing nuclear reaction, to make water hot and vapourize it, leading to a high-pressure steam of water vapour) to spin the coil for you.</p>
<p>Unfortunately, the voltage/current generated using this technique alternates like a sine function, and although we can still directly use such a current for heating things (E.g light-bulbs), it can't be used for driving anything digital. Such a power supply is known as an AC supply (AC stants for, alternating current!)</p>
<p>If you plot the output voltage of the two ends of a AC power source, you will get something like this (Negative voltage means that the poles are reversed and the current will flow in the reversed direction):</p>
<p>[TODO]</p>
<p>The best thing we can do right now is to try to limit the voltage/current to only one direction (Our digital circuits may handle frequent drops and increases in the input voltage, but they may not tolerate when the voltage/current is completely reversed).</p>
<p>There is an electronic component, named Diode, which allows the flow of electrons in a single direction. Let's not bother ourselves on how/why it works, but instead, focus on its application and see if we can use it for something practical, such as converting an AC voltage to a DC one.</p>
<p>By connecting a diode to a AC source, we will get an output like this:</p>
<p>[TODO]</p>
<p>Although it's a good step towards our goal, you can see that half of the energy is being unused. Now let's reverse the direction of the diode and see what happens:</p>
<p>[TODO]</p>
<p>Is there any way we can add these two signals to get an output like this?</p>
<p>[TODO]</p>
<p>Before reading the answer, try to design such a circuit yourself! (Hint: you will need 4 diodes) You will probably reach to a circuit like this:</p>
<p>These specific combination of diodes is called a &quot;bridge&quot;, and although it looks different from what we drew, it actually is the same!</p>
<p>So far, we have been able to allow an AC voltage to flow on only a single direction, but the output voltage we are getting is not yet stable. It alternates between 0 and the voltage of the AC supply. Is there any way we can convert an unstable/alternating DC to a stable one? If you look closed to the output voltage, you will see that there are &quot;gaps&quot; in the voltage that need to be filled. It would be good of there was an electronic component that could temporarily store the unused voltage of an alternating DC and release an smoother voltage when the energy is actually being consumed. Fortunately, there is such a component! It is called a &quot;capacitor&quot; and is able to store the energy for you like a battery.</p>
<p>The output voltage is not much better and smoother than the version without a capacitor. Though it's still not completely flat, as you can still see some gaps in the voltage, but it still is much better than the previous version!</p>
<p>In case you use capacitors with higher capacitance (The unit used for capactitors is Farad), the capacitor will be able to store more energy in it, and keep the voltage up for you for a longer time, leading to smaller gaps.</p>
<p>You just saw that capacitors have obvious use cases, here we used them as a temporary storage of energy, in order to fill the voltage gaps in the process of converting an AC voltage to a DC one, but they have other usecases too! Before examining them, let's get a deeper undestanding on what a capacitor is and how it is made!</p>
<p>Capacitors are simple two conductor plates that are very close to each other (You can see that from the symbol of a capacitor too!). They are very close, but not connected! If you connect a voltage source to a capacitor, you might think that no current will flow (As the plates are not connected to each other), but surprisingly, current will flow! The voltage source will slowly grab electrons from one side and put it on the other side of the plate, effectively making a potential difference between the plates. The process will eventually make the potential difference between the plates equal with the potential difference of the voltage source, and after that, the battery and capacitor will cancel each other and current will stop flowing! The capacitor is charged!</p>
<p>If you plot the current flowing in a circuit containing a battery to a capacitor, you will see that in the very first moment, the capacitor will act like a wire, it allows the current as if there is no capacitor, and as time passes, the potential difference between the plates will slowly increase, slowly cancelling out the potential difference of the battery, leading to less and less current flowing, and finally, the current will completely stop flowing!</p>
<p>There is one very important fact when analyzing capacitors: analyzing them is not possible if you do not assume there is a resistor in the way! Even wires have some amount of resistance, so you may never find a capacitor connected to a battery wihtout a resistor in between! In fact, such a circuit is meaningless, as it does not exist:</p>
<p>Now what happens if the resistance of the resistor along the way increases? The capacitor will get charged/discharged with higher delay! You can either increase the resistor in the way, or the capacity of the capacitor itself, in order to make this charging/discharging delay higher. So the amount of time needed for a pair of resistor and capacitor getting charged is directly proportional to both the resistance and capacitance of the components, and that's why we refer pairs of resistors and capacitors as RC circuits!</p>
<p>We saw that capacitors can also help you to have some kind of &quot;delayed&quot; voltage source, which can sometimes become handy. As an example, imagine you want to turn an LED on, with a delay. If you connect the LED directly to the pins of the capacitor, the LED will slowly become bright and brighter, until the capacitor is fully charged. Here, although the LED got its maximum brightness with a delay, it isn't exactly what we wanted. We want the LED to stay off for some time, and then suddenly become lit!.</p>
<h2 id="revisting-transistors"><a class="header" href="#revisting-transistors">Revisting transistors</a></h2>
<p>Remember transistors we discussed in the first chapter? Transistors might come handy here! A transistor is a electrically controlled switch. It has a &quot;base&quot; pin, that when become enough voltage to pass a threshold, will suddenly allow current to flow between in emitter an collector wire. Now let's connect the delayed voltage-source we made out of a resistor-capacitor, to the base pin of a transistor. The delayed voltage will eventually reach the transistor's threshold and then will suddenly turn the LED on!</p>
<h2 id="breaking-the-curse"><a class="header" href="#breaking-the-curse">Breaking the curse</a></h2>
<p>Ok, we just saw four of the most useful electronical components so far, and we also saw some of the very obvious usecases of these components. Now it's a good time to explore the &quot;Hello World!&quot; circuit of the world of electronics! A Astable Vibrator!</p>
<p>While the name of this circuit seems scary, the circuit itself doesn't do anything extraordinary. It's basically a 2 LED blinker! Unfortunately, although the circuit does such a simple thing, it's surprisingly complicated for those just started to learn electronics! You have to have a very accurate understanding of resistors, capacitors and transistors in order to understand how a Astable Vibrator. Fortunately, since we now understand how we can turn an LED on with a delay, it's not super hard to understand this new circuit.</p>
<p>Our approach in studying a blinker circuit is very similar with how we learned other things in this book. Instead of looking at a astable vibrator's circuit and trying to understand it, we will go through a bottom-up approach, and will try to build a blinker circuit from scratch, using our current knowledge!</p>
<h2 id="ohm-and-kirchhoffs-laws"><a class="header" href="#ohm-and-kirchhoffs-laws">Ohm and Kirchhoff's Laws</a></h2>
<p>When analyzing circuits, there are two important laws in electricity that can help you to calculate the potential difference between any two points, or the amount of current flowing in any point, and these master laws are:</p>
<ol>
<li>The Ohm's law</li>
<li>The Kirchhoff's law</li>
</ol>
<p>The Ohm's law, as previously discussed, describes the relation between the voltage, resistance and current.</p>
<p>\(V=RI\)</p>
<p>The Kirchhoff's law on the other hand, states that the sum of incoming and outgoing current to/from a point in a circuit is always equal. Assuming that we state an outgoing current as an incoming current that is negative, we can define Kirchhoff's current law: the algebraic sum of currents that meet at a point is zero.</p>
<p>Now let's see how these laws can help us analyze a circuit.</p>
<h3 id="analyzing-circuits"><a class="header" href="#analyzing-circuits">Analyzing circuits</a></h3>
<p>Analyzing an electronic circuit is all about predicting and calculating the amount of current and voltage of every point in the circuiy. Obviously, the voltage of every two points directly connected through a wire is always equal. Electronic components are connected together through wires, and your circuit consists of junctions where 2 or more components meet. Since the voltage value of all the points in a junction are equal, there is only one voltage to be calculated. Let's refer to this intersection points of components as <em><strong>nodes</strong></em>. In the example circuit in figure X, there are X nodes. Our goal is to calculate the voltage of all the nodes in any given time.</p>
<p>An electronic component can be defined by the amount of current it allows to pass given the voltages applied on its pins. For example, a resistor's ability to pass electrons is linearly dependent to the amount of voltage difference applied on its pins.</p>
<p>\(i=\frac{V_a - V_b}{R}\)</p>
<p>There are components that have non-linear behaviors too! For example, a diode has a exponential behavior. The more voltage difference applied in correct direction, it allows exponentially more current to pass, and apply the voltage difference in reverse direction, and it will become like a resistor with infinite resistance.</p>
<p>\(i=ae^{b(V_a - V_b)}\)</p>
<p>(The coefficients \(a\) and \(b\) depends on the diode)</p>
<p>There are also some electronic components with time-dependent behaviors. Their current output depends on the input applied to them in the past too. A capactitor for example. If the capacitor is already charged, it allows no current, while an uncharged capacitor allows infinite current. We can also define a capacitor's behavior through a formula:</p>
<p>\(i=C\frac{d(V_a-V_b)}{dt}\)</p>
<p>I would like to introduce you a new, imaginary source of electricity, referred as a current source. As opposed to voltage sources which try to keep the potential difference between two points on a specific number, current sources try to keep the current stable on a chosen number. Current sources are imaginary and do not exist in the real world. You can somehow emulate them though! Imagine building a &quot;smart&quot; voltage source that can measure the current and increase/decrease its voltage accordingly to keep the current on a specific number. As opposed to a voltage source where short circuits are not permitted, in current sources, you have to make sure that electrons coming out of the source will eventualy get back to the source. Otherwise, the zeroness of current will cause the ovltage to become infinity which definitely is not what we want!</p>
<p>The reason I'm introducing current sources is that, it's much easier to analyze circuits that use current-sources instead of voltage sources (For now!).</p>
<p>\(i = I\)</p>
<p>By summing all of currents flowing into each node, we will get a set of equations. Given Kirchhoff's law, we know that these functions must be equal to zero. This puts a constraint on the voltages of the nodes in out system, helping us to find the correct voltage of each node.</p>
<p>In other words, the problem of solving the circuit is reduced to finding the solution of a system of equations.</p>
<h3 id="newton-newton-verywhere"><a class="header" href="#newton-newton-verywhere">Newton, Newton verywhere</a></h3>
<p>Finding the roots of arbitrary functions has always been an interesting problem for ancient mathematicians. It's interesting to know that it took almost X years to find a general method for calculating the roots of a simple quadratic equation, let alone more complicated function!</p>
<p>Newton, besides doing Physics, has always been a pioneer in mathematics and one of his discoveries, was a numerical method for finding the roots of any arbitrary function (With known derivative). The method, which is known as Newton-Raphson nowadays (Thanks to the simplification Raphson did to the algorithm), is an iterative algorithm which tries to guess the root of the function, and make its guess better and better through iterations, until reaching to a final answer!</p>
<p>\(x_{n+1} = x_n - \frac{f(x_n)}{f'(x_n)}\)</p>
<p>Here is a Python code that tries to find the root of simple single-input/single-output function through this method:</p>
<p>\(f(x) = x^3 - 4x^2 - x + 5\)</p>
<p>\(f'(x) = 3x^2 - 8x - 1\)</p>
<pre><code class="language-python=">def f(x):
    return x**3 - 4 * x**2 - x + 5


def f_prime(x):
    return 3 * x**2 - 8 * x - 1


guess = 0.5

for _ in range(10):
    guess = guess - f(guess) / f_prime(guess)

print(guess, f(guess))
</code></pre>
<p>And the output is: <code>1.16296185677753 0.0</code></p>
<p>Fortunately, a very similar approach can be applied for finding the root of a multi-input/multi-output function. (Here, a electronic circuit can be mapped into a multi-input/multi-output function, where the inputs are voltages of the nodes, and the outputs are the sum of currents flowing into the nodes)</p>
<p>The derivative of a multi-input/multi-output function is known as the <strong>Jacobian</strong> of that function. We have been working with Jacobians while training neural-networks too!</p>
<p>Assuming that our function accepts \(3\) inputs and gives out \(3\) outputs, the Jacobian of that function will be a \(3 \times 3\) matrix:</p>
<p>\[F'(X) = \begin{bmatrix}
\frac{\partial f_0(X)}{\partial x_0} &amp; 
\frac{\partial f_0(X)}{\partial x_1} &amp; 
\frac{\partial f_0(X)}{\partial x_2} \\
\frac{\partial f_1(X)}{\partial x_0} &amp; 
\frac{\partial f_1(X)}{\partial x_1} &amp; 
\frac{\partial f_1(X)}{\partial x_2} \\
\frac{\partial f_2(X)}{\partial x_0} &amp; 
\frac{\partial f_2(X)}{\partial x_1} &amp; 
\frac{\partial f_2(X)}{\partial x_2}
\end{bmatrix}\]</p>
<p>Where: \(X = (x_0, x_1, x_2)\) and \(F(X) = (f_0(X), f_1(X), f_2(X))\)</p>
<p>In the Newton Raphson method, in each iteration, we were dividing the result of the function at previous guess, by the result of the derivative of the function at that guess. Since the derivative of our function is now a matrix, we have to find the inverse of the Jacobian matrix in order to perform the formula. The iteration formula becomes:</p>
<p>\[X_{n+1} = X_n - F'(X_n)^{-1}.F(X_n)\]</p>
<p>Now, the only remaining challenge is coverting a circuit to a multi-input/multi-output function, and then, by finding the root of that function through the Newton-Raphson method, the circuit is solved!</p>
<p>Let's dive into the implementation:</p>
<p>[TODO]</p>
<p>Let's assume we have \(n\) nodes. Applying the Kirchhoff's law will give us \(n\) equations that need to be zeroed (See the number of inputs and outputs in our multi-input/multi-output function is equal).</p>
<p>Each function is in fact the sum of contribution of different components connected to it. So a first step could be creating a framework in which components may add their contributions to the node functions.</p>
<p>Let's assume each function is represented as a sum of sub-functions (If there are \(k\) components connected to the \(i\)th node, the corresponding node function will be the sum of \(k\) sub-functions: \(f_i(X) = f_{i,0}(X) + f_{i,1}(X) + \dots + f_{i,k-1}(X)\))</p>
<p>Since the nodes are simple variables that need to be calculated by a solver, it might make more sense to instantiate <code>Var</code> instances when introducing new nodes.</p>
<pre><code class="language-python=">class Var:
    def __init__(self, index):
        self.index = index # Keep track of the index of variable
        self.value = 0
</code></pre>
<h3 id="when-stables-and-unstables-meet"><a class="header" href="#when-stables-and-unstables-meet">When stables and unstables meet!</a></h3>
<p>Revisiting capacitors, we know they are elements that resist against <code>stability</code> of the voltage applied to them. (E.g if you connect a DC voltage-source to them, they will slowly get charged and cancel out the voltage of the DC voltage source, resisting against flow of electrons)</p>
<p>On the other hand, inductors are components that resist against <code>unstability</code> of the current flowing in them. If you suddenly connect a voltage source to them, you may not see a sharp change in the current flowing in an inductor (As opposed to a capacitor, or even a simple resistor), but the current will go up slowly, and if you disconnect the voltage source, current will not get zero instantly, but it will slowly approach zero (Very similar to law of intertia in mechanics!)</p>
<p>In fact, both capacitors and inductors somehow store energy, but in different ways. A capacitor stores energy as a potential difference between its plates, but an inductor stores energy as a magnetic field inside a coil.</p>
<p>Both capacitors and inductors are kind of <em><strong>resistors</strong></em>. The capacitor's resistance is higher when the input voltage is stable (Infinite resistance on a DC voltage source and lower resistance in a AC voltage source or any form of alternationing voltages). On the other hand, an inductor's resistance is 0 when the voltage applied to it is stable, and it's resistance increases as it's input voltage source alternates faster (E.g a high-frequency AC voltage source)</p>
<p>In the circuit shown in figure X, if you apply DC voltages, the voltage of \(V_1\) in the circuit with capacitor will eventually become zero, while the voltage in the circuit with inductor will slowly increase and become \(V\). Now, replace the DC voltage source with a AC one and slowly increase its frequency, the situation will be reversed! You will see higher voltages in the capacitor circuit and lower voltages in the inductor circuit.</p>
<p>We can somehow claim that, capacitors are <em><strong>high-pass filters</strong></em>. They pass current better when their input alternates faster (I.e with higher frequency), whereas inductors are <em><strong>low-pass filters</strong></em>, since they allow better flow of electrons when the input signal is alternating slowly (Or no alternation at all).</p>
<p>Now, here is a fascinating idea: by combining a capacitor and an inductor together, we'll have a circuit that has minimum resistance in certain frequency! This magical frequency can be calculated using this formula:</p>
<p>\(f = \frac{1}{2 \pi \sqrt{LC}}\)</p>
<p>where \(C\) is the capacitor's capacitance in Farads and \(L\) is inductor's inductance in Henries.</p>
<p>Remember both capacitors and inductors could be used for storing energy? Not only you use a pair of capacitor and inductor for creating a dynamic resistor with minimized resistance in a certain frequency, but also you can trap energy in them, and that energy will oscillate between the capacitor and inductor with the same frequency! This means, you can build an alternating source of voltage with this magical pair, and that oscillation is something that has effects on the space around it. It makes disturbances that propagates in the space! (Recall the second chapter where we discussed waves)</p>
<p>The oscillation made by this loop can be routed to a long piece of metal, amplifying the impact it has in the space. A bigger surprise is that, if you have another capacitor-inductor loop (With same frequency) somewhere else, a slight oscillation will also be induced on the second loop. This revolutionary idea was first proposed by the German physicist, Heinrich Hertz.</p>
<p><img src="assets/rlc.png" alt="RLC circuit current" />{ width=300px }</p>
<h3 id="lets-teleport"><a class="header" href="#lets-teleport">Let's teleport</a></h3>
<p>Now that we've been able to recognize presence of some frequency in the space through an antenna, a good next step might be to turn an LED one when the frequency is present. Unfortunately, as an electromagnetic wave propagates through the space (Assume the energy is on the surface of a sphere that is getting bigger linearly, the energy on the sphere is constant but the area is increasing, so the density of the energy per area will decrease, that's why a light-source will look less bright as you get farther from it), it loses its energy. So, the amplitude of the signal you receive on the other side is much smaller, so we have to somehow amplify it and retrieve the original, high-amplitude signal back, in order to make the signal large enough for turning an LED on.</p>
<p>What we are receiving in a RLC loop that is connected to an antenna, is a voltage resonance. This means that the loop will have a very small AC voltage when an electromagnetic wave (With the same frequency as the loop's resonant frequency) is present in the air. In order to turn an LED on, we need a DC voltage source. Remember how we were able to convert AC to DC in previous sections? Using the same ideas as before, we can limit the flow of current to a single direction with a diode, and fill the voltage gaps using a capacitor. This way, the presence of a wave is converted to a very small DC voltage source which can be detected, by a transistor! (Note: you might think that the capacitor will store the energy and keep it even when the signal is not present anymore, that is somehow true, but in practice, the output of the circuit is connected to some other element, consuming the energy stored in the capacitor, eventually zeroing the energy of the capacitor when the signal is not present anymore)</p>
<p>[IMG, rlc loop connected to a diode and capacitor]</p>
<p>The DC voltage source we receive from such a circuit is not enough at all for doing anything useful, but there is a powerful electronic component, transistor, which can detect a voltage as small as what you'll receive from a RLC loop, and let a much higher current flow from its collector to the emitter pin.</p>
<p>[IMG, RLC loop, with a transistor]</p>
<p>Transistors usually need a small, initial voltage on their base pin in order to get sensitive to voltage changes. (E.g the impact of increasing the voltage of the base pin from 1V to 1.1V is much higher than the impact of increasing it from 0V to 0.1V and that's because transistors allow exponentially more current to flow when their base voltage increase). So in order to make our circuit more sensitive to voltage changes, it might make sense to add some extra voltage to the base pin, using a pair of resistors (For voltage splitting).</p>
<p>[IMG: Biasing the transistor]</p>
<p>This simple can be used for sending binary data in distances, a morse-code for example!</p>
<h3 id="telephone-revolution-1"><a class="header" href="#telephone-revolution-1">Telephone revolution</a></h3>
<p>Morse codes can be used for sending bit infomation. What if we want to send something like audio through space? Audio itself is a wave contatining many frequencies, and our circuit was able to recognize the presence of a wave with a certain frequency in the space.</p>
<p>Let's get back to our previous circuit. We were able to control the flow of electrons by a radio wave, but there is more to that circuit! By playing with our transmitter a bit, we will soon figure out that the more strong (Higher amplitude) the source signal is, the brighter the LED will get, which means, not only we can prevent/allow the flow of electrons, we can also control the amount of current flows per time! This means that the data we are sending through our transmitter doesn't necessarilly have to be single bits (On/offs), but they can also be floating-point values!</p>
<p>Waves themselves can be represented as streams of values, where each value shows the amplitude of the signal over time. Now, let's suppose the voice we are going to transfer is encoded as the strength of the retrieved signal. This kind of encoding is known as Amplitude Modulation or AM. This is exactly the same thing that happens in a AM radio receiver/transmitter, and our wave-recognizer circuit can actually receive AM signals already. If we connect the collector wire of the transistor to a speaker, you'll be able to hear the Amplitude Modulated sounds transmitted on that specific frequency. If we want to allow the user to listen to arbitrary frequencies, we'll need a RLC loop with variable resonant-frequency. The resonant-frequency can become variable if either the capacitor or the inductor becomes variable. A variable inductor is pretty straightforward: since an inductor is a wire coil, you can select how long of the coil you want to use in the circuit, as shown in the figure X.</p>
<p>[IMG: AM radio receiver]</p>
<p>[IMG: variable coil]</p>
<p>So far we have been able to detect signals and we didn't discussed much on how we can generate those signals. One easy way of generating such a signal is to charge a RLC loop with a voltage source and then disconnect it (You won't have alternations if you keep the voltage-source connected forever), so that the energy can swing in it. Unfortunately, the signal generated using this method is not a steady one and needs someone/something persistently connecting/disconnecting the voltage source to/from the RLC loop, otherwise the swing will not happen!</p>
<p>We have to think of a circuit which is able to oscillate for us forever, without needing someone to connect/disconnect the voltage-source, or at-least make the process automated. An example of such a circuit is the Astable Multivibrator circuit we discussed in the previous sections. An astable multivibrator generates a square-wave instead of a sine-wave, but that's ok! You can still detect the oscillations of an Astable Multivibrators in the space. In fact, if you take the FFT of a square-wave, you will see that the a sine wave of frequency \(f\) is presented in a square-wave of frequency \(f\), and the only problem is that, there are also other signals present. Those extra signals are harmonies of \(f\) (\(\dots,\frac{f}{8},\frac{f}{4},\frac{f}{2},2f,4f,8f,\dots\)).</p>
<p>Using square-waves as a medium for transmitting data, although works in practice, might cause you legal problems! That's because not all frequencies are allowed to be sent since they can interfere with the signals sent by other entities. A square wave is in fact composed of inifinitely many different sine-frequencies, an many of those are restricted by the governments! The police might might come and arrest you when sending square-waves powerful enough to interfere with the national radio/television for example!</p>
<p>There are more complicated circuits for generating sine-waves too, but for sake of simplicity, let's ignore the government for now (Hopefully this doesn't make governments angry) and use Astable Multivibrators as wave-generators.</p>
<p>We can model an antenna component in our simulator. Our antenna can be modeled as a component with an input and output. It'll just add some noise to the weakened version of the input and put it on the output:</p>
<p>[TODO: Antenna code]</p>
<p>Now, let's see if an RLC loop can detect the signal generated by a Astable Multivibrator:</p>
<p>[TODO: code]</p>
<h3 id="hello-world"><a class="header" href="#hello-world">Hello World!</a></h3>
<p><img src="assets/astable.png" alt="Astable Multivibrator's output" />{ width=300px }</p>
<h3 id="alternating-vs-direct-current"><a class="header" href="#alternating-vs-direct-current">Alternating vs Direct current</a></h3>
<p>How diodes can convert AC to DC</p>
<h3 id="when-capacitors-finally-become-useful"><a class="header" href="#when-capacitors-finally-become-useful">When capacitors finally become useful</a></h3>
<p>If electrical current is analogous to a ball falling from a higher height, then capacitors are like springs on the ground. When the ball hits the spring, in the very first seconds, you won’t see a fast change in the speed of the ball (capacitor acts like a wire, in the very first milliseconds ). As time passes and the ball pushes the string, the string will get potential energy, slowly preventing the ball to squeeze the spring further. There is a moment where the potential energy of the ball  gets equal with potential energy of the spring (capacitor), and that’s when the ball (current!) stops moving. The longer and stronger the spring is, the more it takes to fully squeeze it.</p>
<p>In this fancy, not fully accurate analogy, we can also assume that air-resistance is pretty similar to a resistor. It will slow down the ball. Together, the air resistance and the spring will make a mechanical RC circuit, higher air resistance will also increase the time needed for the spring to get fully squeezed.</p>
<p>Now, imagine we suddenly remove the gravity from the equation, the energy stored in the spring will be released and will push the ball to higher heights, just like when we disconnect the batter from the capacitor and let it load a LED!</p>
<p>Capacitors are DC blockers!</p>
<h2 id="controlling-the-world"><a class="header" href="#controlling-the-world">Controlling the world</a></h2>
<p>\(u(t)=K_pe(t)+K_i\int_0^t{e(\tau)d\tau}+K_d\frac{de(t)}{dt}\)</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
